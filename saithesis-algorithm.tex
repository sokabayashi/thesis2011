\section{Long range search algorithm} \label{S:Algorithm}
We now present our basic line search algorithm, which will converge to the MLE for any 
regular exponential family if the MLE exists.  When the MLE does not exist, the log
likelihood is strictly increasingly but is bounded above by the log likelihood of the LCM
as described by \eqref{E:LCM ll bound}, which itself has a maximum.  In such a case,
this algorithm will climb the log likelihood until the gradient is sufficiently close to zero.
The algorithm and requirements are presented in Theorem~\ref{Thm:log like max} and \ref{Thm:Line Search works}.  The theory is divided into two parts: the first
guarantees that the log likelihood gradient converges to zero, the second shows that when the MLE exists, this is equivalent to finding the MLE.  
%Proofs are in Appendix~\ref{Section:Proofs}. 

%We apply the algorithm described in Theorem~\ref{Thm:Line Search works} to the specific setting of finding the MLE in a regular 
%exponential family when the MLE is known to exist and be unique and the gradient can 
%be calculated exactly.
In order to be consistent with the general optimization literature \citep{Fletcher,NW}, 
we state our algorithm in this 
section from the perspective of a minimization problem: we wish to minimize a 
real-valued objective function $-\ell(\eta)$ 
defined on $\RR^d$.  

%%%%%%%%%%%% BEGIN THEOREM %%%%%%%%%%%%%%
%\begin{theorem}[Convex function root search] \label{Thm:Line Search}
%Consider any line search of the form 
%\begin{align}
%	x_{k+1} &= x_k + \alpha_k p_k \label{E:x_update}
%\end{align}
%used to minimize the objective function $f$, which satisfies the following 
%assumptions:
%\begin{enumerate}
%	\item The objective function $f$ is bounded below in $\RR^d$. \label{ass:one}
%	\item The objective function $f$ is proper, lower semicontinuous, and strictly 
%convex.
%	\item The objective function $f$ is differentiable in an open set $\NN$ containing 
%the level set $\lev_{\leq f
%(x_0)} f$, which is bounded, where $x_0$ is the starting point of the iteration.
%%\item The \emph{step length} $\alpha_k$ is greater than $0$ unless $\nabla f(x_k) = 0$, 
%% in which case $x_k$ is already the solution and the search is complete.
%\item The \emph{search direction} $p_k$ is a non-zero \emph{descent direction} \label
%{ass:four}
%such that the angle $\theta_k$ between the search direction $p_k$ and steepest descent 
%direction $-\nabla f(x_k)$ is 
%restricted to be less than 90 degrees by
%\begin{align*}
%\cos \theta_k \geq \delta > 0
%\end{align*}
% for some fixed $\delta > 0$.  
%\end{enumerate}
%
%Then, unless $\nabla f(x_k) = 0$, in which case $x_k$ is already the solution and the 
%search is complete, it is 
%possible to find a step length $\alpha_k$ that satisfies the \emph{curvature 
%condition}
%\begin{align}
%	c \nabla f(x_k)^T p_k &\leq \nabla f( x_k + \alpha_k p_k)^T p_k \leq 0 \label
%{E:Wolfe-mod}
%\end{align}
%for some fixed $0 < c < 1$.
%
%Furthermore, repeated iterations of \eqref{E:x_update} satisfying assumptions~\ref
%{ass:one} through~\ref{ass:four} and \eqref{E:Wolfe-mod} will produce 
%a sequence, $x_1, x_2, \ldots$ such that
%\begin{align*}
%	\lim_{k \to \infty} || \nabla f(x_k) || = 0.
%\end{align*}
%\end{theorem}

%\section{Line search for MLE estimation}
\begin{theorem}[Exponential family zero gradient attainment] \label{Thm:log like 
max}
Consider any line search of the form 
\begin{align}
	\eta_{k+1} &= \eta_k + \alpha_k p_k \label{E:eta_update}
\end{align}
used to minimize the negative log likelihood function $-\ell(\cdot)$ of a regular 
exponential family on a finite sample space, where the \emph{search direction} $p_k$ 
is a non-zero \emph{descent direction}
such that the angle $\theta_k$ between the search direction $p_k$ and steepest descent 
direction $-\nabla \ell(\eta_k)$ is 
restricted to be less than 90 degrees by
\begin{align*}
\cos \theta_k \geq \delta > 0
\end{align*}
 for some fixed $\delta > 0$.  

Then, unless $\nabla \ell(\eta_k) = 0$, in which case $\eta_k$ is already the solution 
and the search is complete, it is 
possible to find a step length $\alpha_k$ that satisfies the \emph{curvature 
condition}
\begin{align}
	0 \leq \nabla \ell( \eta_k + \alpha_k p_k)^T p_k  \leq c \nabla \ell(\eta_k)^T p_k  
\label{E:Wolfe-ll}
\end{align}
for some fixed $0 < c < 1$.

Furthermore, repeated iterations of \eqref{E:eta_update} along a descent direction 
satisfying \eqref{E:Wolfe-ll} will produce a sequence, $\eta_1, \eta_2, \ldots$ such 
that
\begin{align*}
	\lim_{k \to \infty} || \nabla \ell(\eta_k) || = 0.
\end{align*}
\end{theorem}

Before getting to the proof of this theorem, we need the 
following lemma to transfer global properties of the objective function to the 
objective function restricted to a 
search direction.

%%%%%%%%%%% BEGIN LEMMA %%%%%%%%%%%%%%
\begin{lemma} \label{Lemma:f min} 
Suppose a function $f:\RR^d \to \RR$ is proper, lower semicontinuous, and strictly 
convex.  Then the minimum for $f$ 
exists and is unique if and only if every nonempty level set $\lev_{\leq \alpha} f$ is 
bounded.
\end{lemma}

%%%%%%%%%%% PROOF - LEMMA %%%%%%%%%%%%%%

\begin{proof}[Proof of Lemma~\ref{Lemma:f min}]
Assume every non-empty level set is bounded.  Then by Theorem~1.9 in \citet
{Rockafellar}, the minimum of $f$ is finite 
and thus exists.  By strict convexity, this minimum is also unique.

Now assume the minimum for $f$ exists, denoted by $\min f$.  By assumption, the level 
set $\lev_{\leq \min f} f$ 
contains exactly one point.  By Corollary~8.7.1 in \citet{Rockafellar:1970}, the level 
sets $\lev_{\leq \alpha} f$ are 
bounded for every $\alpha$.  
\end{proof}


\begin{proof}[Proof of Theorem~\ref{Thm:log like max}]
Let $f(\cdot)$ represent the negative log likelihood $- \ell(\cdot)$, the objective 
function to be minimized.  We proceed from the perspective of a minimization of a 
function $f(\cdot)$ since this is the convention in the optimization literature \citep
{NW,Rockafellar}.  %\citet{Okabayashi:longrange} prove a special case when the minimum exists, and this proof mimics that one with 

The negative log likelihood function $-\ell(\cdot)$ is strictly convex by 
\eqref{E:nabla2 ell}, and continuous since it is infinitely differentiable by Theorem~5.8 in \citet{TPE2}.
It is bounded below by the negative LCM log likelihood as described by \eqref{E:LCM ll bound}.

The objective function $f$ is bounded below, strictly convex, and lower semicontinuous 
by assumption, and so by Lemma~\ref{Lemma:f min}, the global minimum exists.  
Then by Lemma~\ref{Lemma:f min}, all level sets of type $\lev_{\leq a} f$, $a \in \RR$ are bounded in $\RR^d$.  Restricting the set to be along a search 
direction $p_k$ maintains the 
boundedness of these sets.  By Lemma~\ref{Lemma:f min} again, the minimum in this 
restriction exists and is unique.     

Then, unless $\nabla f( x_k ) = 0$ in which case $x_k$ is already the solution, for 
each $k$, we can uniquely define $
\alpha_{c_k}$ and $\alpha_{min_k}$ as follows: 
\begin{align}
%	\theta_k &= \cos^{-1} \left( \frac{ -\nabla f_k^T p_k }{ ||\nabla f_k|| \, ||
%p_k||} \right) \label{E:cosine} \\
	\nabla f( x_k + \alpha_{c_k} p_k)^T p_k &= c \nabla f(x_k)^T p_k \label{E:alphac} 
\\
	\nabla f( x_k + \alpha_{min_k} p_k)^T p_k &= 0. \label{E:alphamin} 
\end{align}
The point $\alpha_{c_k}$ is uniquely defined because it is the minimizer of $\alpha 
\mapsto f( x_k + \alpha p_k) - 
\alpha c \nabla f( x_k )^T p_k$.
These values appear on the $\alpha$-axis in Figure \ref{F:Wolfe-mod}.
%%%%%%%%%%% FIGURE %%%%%%%%%%%%%%
\begin{figure}[h!]
\centering
\scalebox{.5}{\input{Figures/Wolfe-mod.pdf_t}}
\caption{Acceptable region for $\alpha$ according to curvature condition 
\eqref{E:Wolfe-ll} when restricting to direction $p_k$.}
\label{F:Wolfe-mod}
\end{figure}

%These values are illustrated on the $\alpha$-axis in Figure \ref{F:Wolfe-mod}.  
%Equation \eqref{E:alphamin} defines $\alpha_{min_k}$ to be the step size that would 
%make the 
%gradient at $x_{k+1}$ equal to zero and hence minimizes $f(x_{k+1})$, equation \eqref
%{E:alphac} 
%defines \alpha_{c_k} to be the step size that would make the gradient at $x_{k+1}$ 
%equal to 

By the strict convexity of $f$ and Theorem~2.14 in \citet{Rockafellar}, 
\begin{align}
	f( x_k + \alpha_{c_k} p_k ) &< f(x_k) +  \bigl[ \nabla f(x_k + \alpha_{c_k} p_k) 
\bigr]^T \alpha_{c_k} p_k. \notag 
\\
	\intertext{Applying \eqref{E:alphac} to the right hand side of the above gives}
	f( x_k + \alpha_{c_k} p_k ) &< f(x_k) + \alpha_{c_k} c \nabla f(x_k)^T p_k. 
	\label{E:b-less-a}
	\end{align}	
(See points $a$ and $b$ in Figure \ref{F:Wolfe-mod}).

The subproblem $\alpha \mapsto f(x_k + \alpha p_k)$ is strictly convex and hence 
monotonically decreasing at $\alpha_k$ 
such that $\alpha_{c_k} \leq \alpha_k \leq \alpha_{min_k}$ (in Figure \ref{F:Wolfe-mod}, see points $b$ and $c$).  That is,
\begin{align}
	f( x_k + \alpha_{min}p_k) &\leq f( x_k + \alpha_k p_k) \leq f( x_k + \alpha_{c_k} p_k). \label{E:f-sandwich}
\end{align}
	
Combining the second inequality of \eqref{E:f-sandwich} with \eqref{E:b-less-a}, we 
have	
\begin{align}
	f( x_k + \alpha_k p_k ) &< f(x_k) + \alpha_{c_k} c \nabla f(x_k)^T p_k,  
	\label{E:decrease}
	\intertext{which can be rearranged as}
	f(x_k)-f( x_k + \alpha_k p_k ) &>  -\alpha_{c_k} c \nabla f(x_k)^T p_k. 
	\label{E:f-lb}
\end{align}
This last inequality \eqref{E:f-lb} expresses a lower bound for the amount of decrease 
in our objective function at 
each step (the right-hand side is positive since $\nabla f(x_k)^T p_k < 0$ by 
assumption that $p_k$ is a descent 
direction).  It is this lower bound that we will use to cover the distance to the 
minimum of the objective function.  

We now turn our attention to \eqref{E:alphac}.  Define $x_{c_k} = x_k + \alpha_{c_k} p_k$.  Then
\begin{align}
	\nabla f( x_{c_k} )^T p_k &= c \nabla f(x_k)^T p_k. \notag
\end{align}
Subtracting $\nabla f(x_k)^T p_k$ from both sides gives
\begin{align}
	\left( \nabla f( {x_{c_k}} ) - \nabla f(x_k) \right )^T p_k &= ( c - 1 ) 
	\nabla f(x_k)^T p_k.  \label{E:c-1}
\end{align}

%\textbf{NEW: SAI 1/17/11}\\
By \eqref{E:nabla2 ell}, $\nabla^2 \ell(\eta)$ is bounded for finite state space $g(\YY)$, which is true by assumption.  Thus $| \nabla^2 f(x) | \leq K$ for some 
constant K for all $x$. 
Then by Theorems 9.2 and 9.7 in \citet{Rockafellar}, 
%since $\nabla^2 f(x)$ is assumed to be finite, 
$\nabla f(x)$ is Lipschitz continuous relative to the convex set $\RR^d$.

%By Corollary~25.5.1 in \citet{Rockafellar:1970}, since $f$ is convex and 
%differentiable on the open convex set $\NN$, 
%it is actually continuously differentiable on $\NN$.  It is then Lipschitz 
%continuously differentiable relative to any 
%compact subset of $\NN$. 

%Applying this to the compact level set $\lev_{\leq f(x_k)} f$, 
%which is contained in $\NN$ by assumption, 
Thus there exists a constant $L < \infty$ such that
	\begin{align}
		|| \nabla f(x) - \nabla f(\tilde{x}) || \leq L || x - \tilde{x} || 
		\quad \text
{for all $x, \tilde{x} \in \RR^d$}. 
%{for all $x, \tilde{x} \in \lev_{\leq f(x_0)} f$}. 
\label{E:Lipschitz}
	\end{align} 

Applying \eqref{E:Lipschitz} to $x_{c_k}$ and $x_k$, we have
\begin{align}
|| \nabla f(x_{c_k}) - \nabla f(x_k) || &\leq L || x_{c_k} - x_k || \notag
\intertext{or}
|| \nabla f(x_{c_k}) - \nabla f(x_k) || &\leq L || \alpha_{c_k} p_k ||. \notag	
\end{align}

Multiplying both sides by $\lVert p_k \rVert$ gives
\begin{align}
	|| \nabla f(x_{c_k}) - \nabla f(x_k) || \cdot ||p_k || &\leq \alpha_{c_k} L || p_k ||^2 
	\notag \\
\intertext{and by Cauchy-Schwarz this implies}
	( \nabla f(x_{c_k}) - \nabla f(x_k) )^T p_k & \leq || 
	\nabla f(x_{c_k}) - \nabla f(x_k) || \cdot ||p_k || \label{E:from-Lipschitz} \\ 
	&\leq \alpha_{c_k} L || p_k ||^2. \notag
\end{align}
Substituting \eqref{E:c-1} into the left-hand side of this last inequality 
\eqref{E:from-Lipschitz} gives
\begin{align}
( c - 1 ) \nabla f(x_k)^T p_k &\leq \alpha_{c_k} L || p_k ||^2 \notag\\
\intertext{or}
-\alpha_{c_k} &\leq \frac{( 1 - c )}{L} \frac{ \nabla f(x_k)^T p_k}{ || p_k ||^2}. 
\label{E:-alpha}
\end{align}

%%%%%%
%%%%%%
Write out the first $k+1$ inequalities of \eqref{E:f-lb}:
\begin{align}
\begin{split}
	f( x_1 ) &< f(x_0) + \alpha_{c_0} c \nabla f(x_0)^T p_0 \\
	f( x_2 ) &< f(x_1) + \alpha_{c_1} c \nabla f(x_1)^T p_1  \\
	\ldots  \\
	f( x_{k} ) &< f(x_{k-1}) + \alpha_{c_{k-1}} c \nabla f(x_{k-1})^T p_{k-1}  \\
	f( x_{k+1} ) &< f(x_k) + \alpha_{c_k} c \nabla f(x_k)^T p_k 
\end{split}
	\label{E:to telescope}
\end{align}
Telescoping the right-hand side of \eqref{E:to telescope},
\begin{align*}
	f( x_{k+1} ) &< f(x_0) + c \sum_{j=0}^{k} \alpha_{c_j} \nabla f(x_j)^T p_j. \notag
\end{align*}
Noting that $\nabla f(x_j)^T p_j < 0$, we can substitute our upper bound 
\eqref{E:-alpha} for $-\alpha_{c_j}$ in the right-hand side above,
\begin{align}
	f( x_{k+1} ) &< f(x_0) - c \sum_{j=0}^{k} \frac{( 1 - c )}{L} 
	\frac{\nabla f(x_j)^T p_j}{ || p_j ||^2 } \nabla f(x_j)^T p_j \notag \\
	\intertext{which simplifies to}
	f( x_{k+1} ) &< f(x_0) - c \sum_{j=0}^{k} \frac{( 1 - c )}{L} 
	\frac{ (\nabla f(x_j)^T p_j)^2}{ || p_j ||^2 }. 
\notag
\end{align}

Because $f(x)$ is bounded below by assumption, there exists some $M < \infty$ such 
that $f(x_0) - f(x_{k+1}) < M$ for 
all $k$. Then rearranging the above yields,

\begin{align*}
	\frac{c( 1 - c )}{L} \sum_{j=0}^{k}   
	\frac{ ( \nabla f(x_j)^T p_j )^2}{ || p_j ||^2 } &< M < \infty.
 \end{align*}
The angle $\theta_j$ between the search direction $p_k$ and steepest descent direction 
$-\nabla f_k$ can be expressed 
by $\cos \theta_j = \frac{ -\nabla f(x_j)^T p_j}{||\nabla f_j|| \cdot || p_j||}$.  
Substituting this into the equation 
above and taking $k \to \infty$,
\begin{align*}
	\frac{c( 1 - c )}{L} \sum_{j=0}^{\infty}  \cos^2 \theta_j ||\nabla f(x_j)||^2 &< \infty.
\end{align*}
Since $0 < c < 1$,
\begin{align}
	\sum_{j=0}^{\infty}  \cos^2 \theta_j ||\nabla f(x_j)||^2 &< \infty. \label{E:Z's}
\end{align}

The convergent series in \eqref{E:Z's} implies that 
\begin{align*}
	\cos^2 \theta_k || \nabla f(x_k) ||^2 &\to 0 \text{ as } k \to \infty.
\end{align*}
With the additional restriction on the search direction $p_k$ such that $\cos \theta_k 
\geq \delta > 0$ for some choice 
of $\delta$, for all choices of $k$, we get the desired convergence result of
\begin{align*}
	\lim_{k \to \infty} || \nabla f(x_k) || &= 0.
\end{align*}

\end{proof}




In fact, Theorem~\ref{Thm:log like max} and its proof can be adapted to the more
general setting
of optimizing any proper, lower semi-continuous function with an added assumption of 
bounded level sets of the function, as done in \citep{Okabayashi:longrange}.  Because 
we wish to apply this to the specific setting of exponential families where the MLE 
might not exist, however, we cannot
assume bounded level sets.  Instead we rely on other properties of the exponential
family log likelihood that guarantee us the necessary Lipschitz continuous gradient.  

We now apply Theorem~\ref{Thm:log like max} to find the MLE when it is known to exist:  

\begin{theorem}[MLE convergence] \label{Thm:Line Search works}
For a regular exponential family with minimal representation where the MLE exists, the 
line search described in 
Theorem~\ref{Thm:log like max} can be applied to the negative log likelihood function 
$-\ell(\eta)$ so that a search 
starting at any $\eta_0 \in \Xi$ will converge to the MLE of $\eta$.
\end{theorem}

Theorem 3.1 shows that the gradient of the objective function converges to 0.  The 
proof for Theorem 3.2 is concerned 
with the conditions for mapping this convergence to the convergence of the iterated 
parameter estimates $\eta_k$ to the 
unique MLE.  In particular, the mapping from $\eta_k$ to the gradient must be globally 
invertible.


\begin{proof}[Proof of Theorem~\ref{Thm:Line Search works}]

The Fisher information for a regular exponential family is non-singular by 
\eqref{E:FI} and thus invertible.  If we consider the map defined by
\begin{align*}
	h(\eta) = \nabla c(\eta)
\end{align*}
where $c(\eta) = \log \kappa(\eta)$ is the cumulant function introduced in Section~\ref{S:ERGM setup}, its first derivative matrix is
\begin{align}
	\nabla h(\eta) = \nabla^2 c(\eta) = I(\eta) \label{E:nabla h eta}
\end{align}
which is again non-singular.  Since this is true for any $\eta$, by the inverse 
function theorem, $h$ is everywhere 
locally invertible.

In fact, $h$ is globally invertible. For any $\mu$ in the range of $h$, consider the 
function
\begin{align*}
	q(\eta) = \mu^T\eta - c(\eta).
\end{align*}
Since $\nabla^2 q(\eta) = - I(\eta)$ by \eqref{E:nabla h eta}, $q$ is strictly 
concave.  Therefore, a maximizer for $q$, call it $\hat{\eta}$, is unique if it exists and satisfies the first-order condition
\begin{align*}
	\nabla q( \hat{\eta} ) = 0.
\end{align*}
This in turn implies that
\begin{align*}
	\mu - h(\hat{\eta}) = 0
\end{align*} 
or
\begin{align*}
	\mu = h( \hat{\eta} ). %\label{E:mu eta hat}
\end{align*}
Because of the assumption that $\mu$ is in the range of $h$, this means that 
$\hat{\eta}$ in fact exists, and by the 
strict concavity of $q$, is unique.  This implies that $h$ must be one-to-one and 
hence globally invertible.


Since $c$ is infinitely differentiable by Theorem~2.7.1 in \citet{TSH}, so is $h$, and 
by the inverse function theorem, 
so is $h^{-1}$ (even if we do not know the form of $h^{-1}$).  The first derivative of 
$h^{-1}$ can be expressed as
\begin{align*}
	\nabla h^{-1}(\mu) = \left [ \nabla h(\eta) \right ]^{-1} 
		= \left [ I(\eta) \right ]^{-1}
\end{align*}
when $\mu = h(\eta)$ and is thus non-singular everywhere, including at the MLE of 
$\eta$, $\etaMLE$.

Thus our algorithm, which concludes that 
$|| \nabla \ell( \eta_k) ||  = || g(y) - h(\eta_k) || \to 0$, implies that 
\begin{align*}
	\mu_k = h(\eta_k) \to g(y), 
\end{align*}
or
\begin{align*}
	h^{-1}(\mu_k)  \to h^{-1}\left (g(y) \right),
\end{align*}
or
\begin{align*}
	\eta_k  \to  \etaMLE.
\end{align*}

\end{proof}




\section{Refinements of algorithm}

In Theorem~\ref{Thm:log like max}, we restricted our search direction $p_k$ to be a 
descent direction, so that $\nabla f
(x_k)^T p_k < 0$ or, alternatively, the angle $\theta_k$ between the search direction 
$p_k$ and steepest descent 
direction $-\nabla f(x_k)$ is less than 90 degrees.  However, this still leaves many 
possibilities for the choice of 
$p_k$ other than steepest descent.  In addition, we have specified restrictions on the 
step size $\alpha_k$ in the 
curvature condition \eqref{E:Wolfe-ll} with $0 < c < 1$, but it would be useful to 
know if certain values of $c$ are 
better than others.

\section{Search directions} \label{S:Search directions}
In our examples in Chapter~\ref{S:Examples}, we default to steepest descent directions 
in our implementation for 
transparency.  Although often effective in early steps, steepest descent directions 
can result in an inefficient zigzagging 
trajectory of the sequence $x_k$ \citep{Sun:2006}  as 
illustrated in Figure 
\ref{F:zigzag} (left).  This is especially problematic when the MLE does not exist in the 
conventional sense---the MLE is actually off at infinity and a zig-zagging route may 
make it especially difficult to realize this.

Conjugate gradient methods may partially address 
this phenomena and cover the 
sample space more efficiently \citep{NW}.  It is easy to implement a variant of the 
Polak-Ribi\`{e}re method
\citep[pp.~120--122]{NW} here, requiring little more in terms of calculation or 
storage.  The search direction $p_k$ would update 
with an extra intermediate step as follows:
\begin{align*}
	\gamma_{k+1}^{PR} &= \max \left( 0, \frac{ [ \nabla \ell( \eta_{k+1}) ]^T( \nabla \ell( \eta_{k+1} ) - \nabla \ell( \eta_k) )  }
{ \lVert \nabla \ell( \eta_k) \rVert^2 } \right )\\
	p_{k+1} &= -\nabla \ell( \eta_{k+1}) + \gamma_{k+1}^{PR} \, p_k.
\end{align*}
Note that when $\gamma_{k+1}^{PR} = 0$, $p_{k+1}$ will be just $-\nabla \ell( \eta_{k+1})$, 
the direction of steepest 
descent, and thus serves as a ``reset''.  The curvature condition \eqref{E:Wolfe-ll} 
guarantees that this method always 
yields a descent direction for $p_{k+1}$ and thus Theorem~\ref{Thm:log like max} still 
holds.  

Another pragmatic approach may be to use a search direction resulting from a regression
through the previous few updates (See Figure \ref{F:zigzag} (right)).

%For ERGMs where the MLE may not exist, we have found a particularly useful approach is 
%to use the average normal cone vector.  This will only occur if the algorithm 
%has generated 
%Another alternative that is useful for ERGMs when the convex support is not known
%and it appears the MLE 
%may not exist is to use  
%(the observed statistic fall on the boundary of the convex support.  Because our 
%algorithm computes the normal cone when it finds an empirical face, we suggest using 
%the average normal cone vector as a search direction, checking first that it is an 
%ascent direction to ensure the algorithm proceeds uphill.  As theory in the previous 
%sections show, a GDOR, if it exists, is any vector in the relative interior of the 
%normal cone at the observed statistic.  So, the search direction chosen in this manner 
%may in fact be a GDOR of the original model and hence result in large steps when 
%meeting the curvature condition.  Alternatively, we also consider using search 
%directions resulting from a regression through the previous few parameter values to 
%break the zig-zagging pattern.

\begin{figure}[!ht]
\centering
\includegraphics[height=2.6in,width=2.6in]{Figures/zigzag-eta}
\includegraphics[height=2.6in,width=2.6in]{Figures/zagplusnorm-eta}
\caption[Contour plots of ERGM log likelihood when MLE does not exist]{Contour plots of an ERGM log likelihood when the MLE does not exist.  The surface 
tends to flatten, though technically it is still concave.  This can cause 
the steepest descent 
algorithms to zigzag, which is inefficient (left).  However, by periodically using 
search directions 
determined by 
%normal vectors  derived from the empirical face or 
a regression through 
previous points, the algorithm can make much larger steps (right).}
\label{F:zigzag}
\end{figure}


\section{Step size} \label{S:Step size}
We now turn our attention to the optimal step size $\alpha_k$ when our objective 
function is the log likelihood of an 
exponential family.  Taking the derivative of $\ell( \eta_k + \alpha_k p_k)$ with 
respect to $\alpha_k$ shows that the 
log likelihood is maximized as a function of $\alpha_k$ along the direction $p_k$  
when 
\begin{align*}
	\nabla \ell( \eta_{k+1} )^T p_k = 0.
\end{align*}

By choosing $c$ to be small, say 0.2, we ensure that the step taken is close to 
maximizing the log likelihood along the 
search direction.  This is also apparent in Figure~\ref{F:alpha_region}. 

Making $c$ too small, however, may make it difficult to find an $\alpha_k$ that meets 
the curvature condition \eqref
{E:Wolfe-ll} since this search must be done numerically.  In fact, as the line 
search nears the MLE and $\nabla \ell( \eta_k)$ gets smaller, the rightmost term in \eqref{E:Wolfe-ll} gets 
smaller in magnitude (it equals $c \lVert \nabla \ell(\eta_k) \rVert^2$ if using steepest ascent directions), making a 
numerical search for $\alpha_k$ 
more challenging.  This issues is exacerbated when the quantities are 
noisily approximated via MCMC, as discussed in the next section.
We currently construct a spline to approximate 
$\nabla \ell( \eta_k + \alpha_k p_k)^T p_k$ as a function of $\alpha_k$ based on 
previous guesses using the \texttt{gam} function in the \texttt{mgcv}
package \citep{mgcv:R} in R.  However, this approach does not use the fact that
we have a strictly concave function of $\alpha_k$ and thus a more effective
approximation should be possible.


%Finally, while the choice of 0.2 for $c$ worked well in the problems we explored 
%regardless of search 
%directions used, it follows from our discussion in the previous section that it may 
%make sense to use slightly larger 
%values of $c$ when using steepest ascent directions, thereby reducing the zigzagging 
%phenomenon, but smaller values for 
%$c$ when using conjugate gradient methods.


\section{MCMC approximations} \label{S:MCMC approx}
Our algorithm requires us to be able to calculate $\nabla \ell(\eta)$ using 
\eqref{E:nabla ell}.  For many 
applications, we will need to approximate $\E_{\eta}g(Y)$ using MCMC.  That is,
\begin{align} \label{E:nabla ell approx}
 	\nabla \ell (\eta) = g(y) - \E_\eta g(Y) \approx g(y) 
	- \frac{1}{m}\sum_{i=1}^m g(Y_i), 
\end{align}

where $Y_1, \ldots, Y_m$ are MCMC draws from the distribution with parameter $\eta$.  
There are many MCMC algorithms 
such as Metropolis-Hastings or Swensen-Wang (used for the Ising model example in 
Section~\ref{S:Example:Ising}); see \citep{Brooks} and references cited therein.
We show examples in the next section where $\nabla \ell(\eta)$ can be calculated 
exactly and where it must be 
approximated.

The accuracy of the approximation in \eqref{E:nabla ell approx} increases with Monte 
Carlo sample size $m$. 
When the current estimate is far away from the MLE, we can use smaller $m$ to save 
time and work with a 
fairly noisy approximation of the gradient.  However, when the current estimate 
approaches the MLE, larger $m$ are necessary.

Our algorithm relies on the computed values of $\nabla \ell(\eta)$ in the curvature 
condition \eqref{E:Wolfe-ll}, 
as well as the stop condition for the algorithm, $\lVert \nabla \ell( \eta_k ) \rVert 
< \epsilon$.  Given that we may 
only have approximations of $\nabla \ell(\eta)$, we cannot know for certain if either 
of these conditions are truly 
met.  We can ameliorate this by constructing confidence intervals for each of the 
inequalities.  

For the inequalities in \eqref{E:Wolfe-ll}, we can estimate asymptotic standard 
errors of $\nabla \ell( \eta_k + 
\alpha_k p_k)^T p_k$  and $c \nabla \ell(\eta_k)^T p_k - \nabla \ell( \eta_k + 
\alpha_k p_k)^T p_k$ by appealing to the 
Markov chain Central limit theorem 
\citep{Chan:1994,Jones:2004,Roberts:1997,Roberts:2004}.
The \texttt{initseq} function from the R package \texttt{mcmc} \citep{mcmc:R} can be 
used to estimate asymptotic 
standard errors for univariate functionals of reversible Markov chains: given an MCMC 
sample for a univariate 
quantity, \texttt{initseq}
returns a value (divided by sample size) that is an estimate of the asymptotic 
variance in the Markov chain central 
limit theorem.  Both of the quantities in \eqref{E:Wolfe-ll} are univariate.  In 
the second expression, $c \nabla \ell(\eta_k)^T 
p_k - \nabla \ell( \eta_k + \alpha_k p_k)^T p_k$, the MCMC sample generated for $
\nabla \ell( \eta_k + \alpha_k p_k)^T 
p_k$ is independent of the sample generated for $c \nabla \ell(\eta_k)^T p_k$.  Thus 
\texttt{initseq} can be applied 
to each sample separately and the results summed for an estimated variance.  
We can then be approximately 95\% confident (non-simultaneously) that $\alpha_k$ 
satisfies \eqref{E:curvature 
mod} if
\begin{align*}
	 \nabla \ell( \eta_k + \alpha_k p_k)^T p_k - 1.645 \cdot \text{se}_1 > 0 \\
	 c \nabla \ell(\eta_k)^T p_k - \nabla \ell( \eta_k + \alpha_k p_k)^T p_k - 1.645 
\cdot \text{se}_2 > 0 
\end{align*}
where $\text{se}_1$ and $\text{se}_2$ are the asymptotic standard errors for $\nabla 
\ell( \eta_k + \alpha_k p_k)^T p_k
$  and $c \nabla \ell(\eta_k)^T p_k - \nabla \ell( \eta_k + \alpha_k p_k)^T p_k$, 
respectively, calculated as described.

The delta method can be applied to estimate a standard error for $\lVert \nabla \ell
( \eta_k ) \rVert$. 
%%%%%%%%%%%%% 1/25/11 -Newly added from Algorithm.tex
The multivariate version of the delta method states that for a sequence of r.v. $B_n$ 
such that
\begin{align*}
	\sqrt{n} ( B_n - \beta) \stackrel{\DD}{\longrightarrow} N( 0, \Sigma ),
\end{align*}
then for a function $h(B)$, where $h$ such that $\nabla h$ is defined and non-zero,
\begin{align*}
	\sqrt{n} \left ( h(B_n) - h(\beta) \right ) \stackrel{\DD}{\longrightarrow} N 
\left ( 0, \nabla h( \beta)^T \Sigma\nabla h( \beta)  \right ).
\end{align*}

We set $B_n = \nabla \ell_n( \theta)$ and $\beta =\nabla \ell( \theta)$, where we 
know that $B_n \stackrel{a.s.}{\longrightarrow} B$ by SLLN.  
We also do not know $\Sigma$, the variance of $\nabla \ell( \theta)$, but this we will 
approximate with $
\hat{\Sigma}$, the scaled sample variance-covariance matrix of our MCMC batches of 
the canonical statistic (the \texttt{initseq} function 
requires a univariate vector and so cannot be used here).  That is,
\begin{align*}
	\hat{\Sigma} = \frac{1}{\text{nbatch}}\frac{1}{m-1}\sum_{i=1}^{m} (g(Y_i) - \overline{g
(Y)})( g(Y_i) - 
\overline{g(Y)})^T.
\end{align*}

%%%%%%%%%%%%%%%
Thus the asymptotic variance is calculated by
\begin{align*}
	V \left( \lVert \nabla \ell( \eta_k ) \rVert \right )= \frac{1}{\lVert \nabla \ell
( \eta_k ) \rVert^2} \nabla \ell
( \eta_k )^T \, \hat{\Sigma} \,  \nabla \ell( \eta_k ),
\end{align*}% added hat to Sigma
%where $\Sigma$ is the variance matrix of $\nabla \ell( \eta_k )$ and can be estimated 
%by the sample variance matrix of 
%the batch mean vectors of $g(Y_1), \ldots, g(Y_n)$ divided by the number of batches 
%(the \texttt{initseq} function 
%requires a univariate vector and so cannot be used here).  
We can be approximately 95\% confident that $\lVert 
\nabla \ell( \eta_k ) \rVert > \epsilon$ if 
\begin{align*}
	\lVert \nabla \ell( \eta_k ) \rVert - 1.645 \sqrt{ V \left( \lVert \nabla \ell
( \eta_k ) \rVert \right )} > 
\epsilon.
\end{align*}
%To be conservative, we suggest using a larger quantile, say 2, 
%in the confidence intervals instead of the 1.645 used above.

In practice, however, use of confidence intervals does not appear necessary with  
Monte Carlo sample sizes that are set 
large enough so that these standard errors are initially small relative to the point 
estimates.  The ratio of point 
estimate to standard error of course decreases as the algorithm progresses and the 
estimate of the parameter nears the 
MLE, reflected in $\nabla \ell( \eta_k )$ nearing 0.  Thus these confidence intervals 
are most useful as a guide for
when to increase the MCMC sample size, or when to switch methods, or when to terminate 
the algorithm.



\section{Combining with other algorithms} \label{S:Combine}
We believe the best use of this algorithm is in combination with other faster methods 
like MCMC-MLE \citep{Geyer:1992}
or Newton-Raphson safeguarded by our line search algorithm.  Our algorithm with 
steepest ascent or conjugate gradient search direction
should be used initially from ``long range'', when one has no good intuition for an 
initial value.

It is well known that when the objective function is quadratic, the conjugate gradient 
method with exact arithmetic converges to the solution
in at most $d$ steps, where $d$ is the dimension of the problem \citep[Chapter 5]{NW}.  As a rule 
of thumb then, we think using our 
algorithm for $2d$ steps before switching seems reasonable when using conjugate
gradient directions.  Determining when we are inside the ``radius of convergence"
for algorithms like Newton-Raphson or MCMC-MLE is an area for further research.

In the case of MCMC-MLE, it was shown in Section~\ref{S:MCMC-MLE} that getting 
a distribution close enough to $g(\yobs)$ in mean value parameterization 
so that it is within the convex hull of the MCMC samples is a 
necessary condition for this algorithm to converge (in fact, this appears to be the
impetus for the steplength MCMC-MLE approach of \citet{Hummel}).  However, this is not
sufficient.  An effective approach may be to examine the importance sampling weights
used in \eqref{E:r_hat} in the previous iteration, and look for them to stabilize.
This ``rearview" approach should inform us if the previous value for $\eta_k$ 
was close enough to apply MCMC-MLE; applying MCMC-MLE to the current distribution
should then converge.
%\section{Estimating standard error} \label{S:SE}
%The methods to estimate Monte Carlo standard errors described in 
%Section~\ref{S:MCMC approx} pertain to estimates of functions of $\nabla \ell(\eta)$.
%However, the we are primarily interested in estimating the MLE of $\eta$ and thus
%want standard errors of our estimates of this MLE.
%%These cannot be obtained with our application of our algorithm, since we can
%%only evaluate the accuracy of our estimate by how small $\lVert \nabla \ell(\eta) \rVert$ is.  Here again the switch to another algorithm seems most appropriate.
%
%Approach of \citet{Geyer:1994}, explained in detail in the context of ERGMs by \citet{Hunter:2006},
