\documentclass[12pt]{article}

\usepackage{amsbsy,amsmath,amsthm,amssymb,verbatim,color}

\usepackage{geometry,graphicx,subfigure}
\graphicspath{{../Figures/}}

\geometry{hmargin=1in,vmargin={1in,1in},footskip=.5in}
\usepackage{natbib}
\usepackage{setspace}
%\usepackage{hyperref}
\usepackage{fancyhdr,lastpage}
\pagestyle{fancy}
\fancyhead{}
\rhead{Saisuke Okabayashi}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{center}
{\large{\textbf{Parameter Estimation in Social Network Models}}} 

\vspace{0.15in}
{Saisuke Okabayashi} \\
%\href{http://www.stat.umn.edu/~sai}{www.stat.umn.edu/\textasciitilde sai}\\
{Department of Statistics}\\
www.stat.umn.edu/\textasciitilde sai
%\vspace{0.05in}
\end{center}

\setstretch{2}

\section{Background}
Decisions in society today are rarely made in isolation.  Which classmate 
to befriend, company to acquire, and 
country to ally with are all decisions that depend not just on the 
attributes of the potential target, but also on the decisions of others 
in the same realm.  Analyzing
data from such settings then necessitates a model that incorporate 
this interdependent behavior of participants.  
In my dissertation, I describe a recent class of statistical network models 
that are specifically designed to capture such dependence.
These enable a researcher to identify the 
factors that shape the overall structure 
of outcomes.  However, current methodologies to fit these models to datasets
are still unreliable. 
The goal of my research is to address some fundamental gaps of 
the current approaches and ultimately make network models more useable for a practitioner.

%{\color{red} Why do people want to be able to model this behavior?  Who uses these models (in the social sciences and beyond)?}
%{\color{red} State the goal of your research here: provide tools for practitioners looking to study such relationships (or perhaps at the end of the next sentence).}

\subsection{Motivating example}
\begin{figure}[h!]
\centering
\includegraphics[width=4.7in]{fmh-gradesex2}
\caption{A friendship network of 1,461 students in grades 7--12 derived 
from the National Longitudinal Study of Adolescent Health \citep{Resnick:1997}.  
Individuals, represented by nodes, are colored by grade, and boys
are depicted by squares, girls by circles.  An edge (line) is only present between a pair of 
nodes if a friendship exists.  The data is available in the 
\texttt{statnet} package \citep{statnet:R} on the R platform \citep{R}.}
\label{F:fmh}
\end{figure}

%Studies of social networks such as the high school friendship network depicted 
%in Figure~\ref{F:fmh} typically look to identify gender, age, ethnicity, and 
%other individual-specific attributes to explain which relationships form.  
The friendship network of 1,461 students in grades 7--12 is depicted
in Figure~\ref{F:fmh}.  Studies of such networks typically look to 
identify gender, grade, ethnicity, and 
other individual-specific attributes to explain which relationships form.
However, friendships form in an interdependent manner---for example, Alicia 
and Christina are more likely to become friends if separately Alicia and Christina 
are each friends with Brad. Indeed, sociologists have long observed that people 
exhibit a strong tendency to form such triangular structures in their relationships.
%This complicates any statistical analysis that attempts to explain which
%relationships form.   
Is gender still an important factor then in determining whether or not 
Alicia and Christina become friends if they also share a common friend in Brad? 
The issue necessitates a perspective 
that does not treat the relationships between pairs of individuals as independent events.

%; rather, this positive dependence between friendships 
%should appear as a factor in the analysis.
%, captured in 
%relationship structures such as triangles, and include them as factors in the analysis. 
%{\color{red} Replace previous sentence: Instead the analysis must take 
%the positive dependence between friendships into consideration. }

A statistical network model can be constructed for exactly this setting.
When properly fit to the observed data, such a model can 
simulate new random networks which retain essential characteristics of 
the original network.  These simulated networks enable a researcher to 
 test hypotheses about the mechanism of relationship formation.
For instance, in the friendship network example, we might test if
gender is an important factor even after controlling for people's tendency to 
form triangular friendships.
% and 
%clarify which of the underlying forces are important in shaping the 
%overall structure of the network.
%{\color{red} For instance, in the friendship network example, we might test that gender is an important factor even after controlling
%for people's tendency to form triangles.}

\subsection{Overview of our research}

Our research is in the methodology of \emph{fitting} statistical network models to observed datasets.  
In fact, postulating a network model with factors of interest
has become 
relatively straightforward \citep{Wasserman:1996,Morris:2008}; it is fitting
the network model to datasets that is difficult.  This entails calibrating 
the model \emph{parameters}, the values which control how a model's predictions 
are affected by changes in the factors.  
%The parameter values that ``best" fit a network model to data are akin
% to the precise quantities of each ingredient in a recipe for the perfect 
% chocolate cake: simply knowing the ingredients does not achieve the
% desired result.  In statistical models, 
Without these values properly set,
 no inference about which factors are important can be performed sensibly.
The science of finding the ``best" parameter values for network models 
is a research problem that is still in its infancy.  
We focus on two particular areas in the current approaches that are 
problematic:
\begin{enumerate}
\item Short range.  Most methodologies rely on iterated estimates of the parameter
values, where the model is repeatedly fit and evaluated.  
However, when the initial guesses for the parameters are far from the 
``best" values (which are not known in advance), current 
methodologies perform poorly and fail to arrive at satisfactory values.
\item Non-existent ``best" values.  For particular models and datasets, it is 
in fact possible that the ``best" parameter values do not exist \citep{Handcock:degeneracy,Rinaldo:2009}.  
This has been cause for considerable concern in the network literature 
\citep{Handcock:2006,advancesp*,recentp*}.  In such a case, current 
methodologies may return nonsensical parameter values that lead to a model which generates 
random networks showing no resemblance to the observed network.  
%This makes hypothesis testing impossible.
\end{enumerate}
In my dissertation, I propose a new algorithm that addresses both of these 
issues.  Our algorithm is designed to work well when initial 
guesses for parameter values are far from the ``best" parameter values.  In addition, it 
utilizes computer simulations in such a way as 
to detect the conditions that lead to non-existent ``best"  parameter values.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Statistical network models}
A statistical model assigns probabilities to outcomes of an event.  For example, 
the model for flipping a coin that is possibly unfair assigns some 
probability to getting a head, and one minus that probability to getting a tail.  
In the case of a network model, this concept is  
extended to assign a probability to each network that could 
arise for the given number of individuals.
The most commonly used statistical model for networks is the 
\textit{exponential random graph model} (ERGM) 
\citep{Wasserman:1996,Pattison:1999,logit,Snijders:2002,introp*,ergm} and 
is the focus of our research.  It has a simple and flexible form:
to specify an ERGM, a researcher need only input a list of 
individual-specific factors like gender and age, and also \textit{network statistics}, 
which are the relationship structures of interest.  Examples of possible network statistics are the triangles described earlier that capture
transitivity, and edges, which capture the basic tendency of an individual to
 form a relationship with another individual.  The possibility for network statistics
 is almost unlimited, 
though they must be countable on a dataset. 
In the example of the high school friendship network in Figure~\ref{F:fmh},
there are 974 edges (friendships) and 169 triangles.
%There is no restriction on the factors one chooses to include,
%though one should not specify more factors than there are pairs of individuals.

%This is analogous to picking the predictors for a linear regression model, with the difference being that although we may think of a relationship structure such as a triangle as a predictor in our model, it is in fact a function of the very response variable that we are trying to model.
%In the example of the high school friendship network 
%depicted in Figure~\ref{F:fmh} with 1,461 students in grades 7--12, 
A researcher studying this friendship dataset may be interested in whether being of the same grade and gender
 are important factors in friendship formation.
To control for the interdependency of friendships, the 
researcher should also include network statistics for edges and triangles.
The ERGM then is specified by these four factors.
The inclusion of the triangle factor
prevents a researcher from erroneously concluding
that a factor, say gender, is important in friendship formation when in 
fact the true driver was the tendency of individuals to form
triangular friendships.  In order to arrive at 
such conclusions, however, the model needs to be fit the observed dataset.


\subsection{Parameter estimation}
The goal in parameter estimation is to find the 
parameter values called \textit{maximum likelihood 
estimates} (MLE) that ``best" fit the dataset.  
These values, as their name indicates, maximize
the \emph{likelihood function} associated with a model, which is the function 
that assigns probability to the observed network for specified parameter values.
Thus a model fit with these values assigns the highest probability to the observed data of 
all possible models.  The randomly simulated networks from this model 
 retain essential characteristics of the observed network.

%The MLEs are what we earlier referred to as the ``best fit" model parameters.

\subsection{Our algorithm}
%We pursue a simple iterated approach for finding the MLEs for the model parameters: 
We present a simple iterated algorithm for finding the MLEs for network models.
From any initial guess of values (we typically used zeroes), 
our algorithm repeatedly takes steps in a direction that 
yields parameter values that increase the likelihood function---that is, the model 
fit with these new values assigns higher probability to the observed data.    
When no higher probability can be found, the MLEs have been attained.  

The complication for network models is that 
calculating a probability with an ERGM is in general not possible, 
even with advances in computing.
It requires a summation over all possible networks which could arise, 
an astronomical number when there are even 40 individuals in the network 
(there are 6.36$\times10^{234}$ different networks in that case).  
The inability to calculate probabilities with a statistical model may seem 
like a colossal shortcoming, but in fact the analysis of interest---the 
hypothesis testing of factors---relies only on simulating 
networks from the ``best" fit model and not actually on the probabilities 
themselves.  Thus this is only an issue in finding the MLEs and not in 
the subsequent inference.

In our implementation, we avoid this obstacle by using only the slope of 
the likelihood function, which can be well-approximated by 
a computer simulation technique called \emph{Markov chain Monte Carlo} (MCMC).  
By making sure that
\begin{enumerate}
\item the direction of steps is always uphill on the likelihood function
\item the steps taken in that direction are sufficiently large,
\end{enumerate}
our algorithm will arrive at the MLE.  The first requirement can be met 
easily by using directions that have a positive slope.  The second requirement
is more complicated. 
Figure~\ref{F:curvature} illustrates the likelihood function values 
for different step sizes along an uphill direction.  
If we think of the likelihood function as a hill, this 
figure illustrates a cross sectional slice of this hill.

\begin{figure}[h!]
\centering
\includegraphics[width=4.7in]{curvature-layman}
\caption{A cross section of the likelihood function along a specified search direction.
Our curvature condition forces a step size in the 
acceptable region marked, which guarantees significant progress up the likelihood.
The end points of this region correspond to particular slope values.  
The tangent lines associated with these slopes are the dotted lines.
%The smoothness of this function and absence of more than one maximum is guaranteed 
%by theoretical properties of the model.
}
\label{F:curvature}
\end{figure}

We devised a \emph{curvature condition} which, using only the slope, ensures 
that the steps taken are large enough to make significant progress up this 
slice of the likelihood function.  Because the cross sectional slice will generally
not go exactly through the peak, this process may need to be repeated several times.

Our approach is simple.  By only using the slope in our algorithm, our approach avoids 
the issues related to initial guesses far from the peak that plague other 
more complicated methodologies.  These other approaches attempt to extract
finer, more detailed information, of which little is available when the initial guess is far
from the peak.
%We have called our algorithm a ``long range" algorithm.
The tradeoff of our ``long range" methodology is computational efficiency:
it may require millions of MCMC simulated samples 
which may take a few hours (two hours for our friendship example). In
addition, our algorithm is particularly inefficient when the peak 
is close, but this is exactly the region
where current methodologies excel.  Thus we advocate combining methodologies, 
using our algorithm at the outset and switching 
to a faster approach once the peak is closer.  It would 
be akin to combining busing and walking to get to one's office on campus---the 
bus covers longer distances faster, but walking is much more effective for getting
to the exact destination once we are in its vicinity.

\subsection{Model degeneracy}
The setting described so far assumes the ``best" model parameters---the 
maximizers of the likelihood function---exist.  All methodologies we know of
for ERGMs assume this to be the case.
But it is possible that the likelihood function increases in perpetuity;
that is, unlike the case depicted in Figure~\ref{F:curvature} where 
the likelihood function bends back downward, it can instead 
increase to infinity.  This situation, known as model \emph{degeneracy}, 
causes significant problems for any parameter estimation method since 
no maximizer of the likelihood function exists---the MLE
is ``at infinity".  It is a common enough occurrence to be an impediment to 
researchers using ERGMs.
As a countermeasure, network researchers have developed
 new network statistics such as more sophisticated forms of triangles that are 
less prone to degeneracy \citep{advancesp*,recentp*}.
In our research, we take a different approach, adapting our algorithm to detect 
 degeneracy when it occurs.

\subsection{Extending our algorithm to degeneracy}
The theoretical underpinnings for why these instances occur has been 
understood for many years \citep[Chapter 9]{Barndorff}; it relates to the
boundary of the space defined by the 
possible combinations of factors included in a model.
Figure~\ref{F:g9-hull} illustrates the possible combinations and boundary
for a nine-individual network model with only two factors, edges and triangles.  
Probability theory dictates that degeneracy occurs when 
the network statistics for the observed dataset 
falls exactly on this boundary \citep{Handcock:degeneracy,Rinaldo:2009,Geyer:gdor},
which in Figure~\ref{F:g9-hull} is the six-sided polygon.  For example,
the network depicted in Figure~\ref{F:g9-29-47} has 29 edges and 47 triangles, putting 
its count in the
interior of this polygon.  If this network was observed, the MLEs exist.  However, if
the network in Figure~\ref{F:g9-31-50} is observed, though visibly similar, 
it has 31 edges and 50 triangles, putting its count on 
the boundary of this polygon, so the MLEs do not exist.   
The geometry of this polygon quickly becomes 
complicated as the number of individuals and factors increases.  Thus in general it is unknown,
making it seemingly impossible to determine MLE existence.

In our research, we show a way to discover portions of this polygon
in the neighborhood of the observed network's statistics.  
The very MCMC simulations used to estimate the 
slope described earlier can in fact be used to discover this boundary.  
Figure~\ref{F:g9-sample} depicts the network statistics
for 10,000 MCMC simulated networks for fixed parameter values.
Although the polygon marking the boundary is unknown to the algorithm, portions of the sample cloud
are getting pressed into one side of the polygon.
That is, with strategic simulation,
we can determine ``on the fly"
portions of the boundary.
Ultimately then, we are able to conclude whether or not the ``best" parameter values exist.
We know of no other general methodology that deals with this situation.

\section{Summary}
In my dissertation, we present a new algorithm for finding the ``best" parameter values for a
network model, which can be used to test hypotheses about the process of relationship formation.  
Our algorithm fills a gap in the existing parameter estimation toolbox, 
working particularly well in situations where others do not.   In addition, unlike existing approaches, our algorithm can
detect if the ``best" values do not exist for the posited model and dataset.

 

We have motivated this discussion with a friendship network example.  However, a network is
a more general concept: it can be thought of as a conduit for flow in a complex dependent setting.  That flow
may be e-mails or diseases between individuals, association between
terrorists,  negotiations between politicians,
transactions between companies,
trade between nations,
or binding between proteins.
A ``best" fit network model can be used to understand the mechanism of this flow.

%Furthermore, the methodology we have developed to find ``best fit" parameter 
%values for ERGMs and detect when they do not exist can be applied to a 
%broader class of finite \emph{exponential family models}.  These
%can be applied to more general settings of dependency, such as the geographic 
%variation in crop yields \citep{Besag:1974,Besag:1975},
%DNA fingerprint data \citep{Geyer:1992}, or the spin of neighboring 
%atoms in a ferromagnetic model \citep{Ising,Potts}.

\newpage
\begin{figure}[ht!]
\centering
\includegraphics[height=3.6in]{g9-hull-bw2}
\caption{The different edge-triangle combinations that can occur in a 9-individual network.  
There are 69 billion possible networks that could arise, but only 444 edge-triangle 
combinations are possible.  For example, it is impossible for a network to have five 
triangles but only two edges present.}
\label{F:g9-hull}

\includegraphics[height=3.4in]{g9-explore-BW}
\caption{The edge-triangle combinations for 10,000 simulated networks for fixed
parameter values.  In a general problem, we do not know the actual boundary of the 
space (the polygon is drawn here for reference), but can discover it through repeated simulation.}
\label{F:g9-sample}
\end{figure}

\newpage
\begin{figure}[ht!]
\centering
\includegraphics[height=3.3in]{g9-29-47}
\caption{A 9-node network with 29 edges and 47 triangles.}
\label{F:g9-29-47}

\includegraphics[height=3.3in]{g9-31-50}
\caption{A 9-node network with 31 edges and 50 triangles.}
\label{F:g9-31-50}
\end{figure}

\newpage
%\bibliographystyle{apalike}
\bibliographystyle{/Users/saipuck/Tako/THESIS/ims}
\bibliography{/Users/saipuck/Tako/THESIS/References}

%\begin{thebibliography}{77}

%
%\bibitem{kend}
%Kendall, W. S. 2004.
%\newblock Geometric ergodicity and perfect simulation,
%\newblock {\sl Electronic Communications in Probability}, 9:140--151.

%

%\bibitem{jones}
%Jones, G. L. (2004)
%\newblock On the {M}arkov chain central limit theorem,
%\newblock {\sl Probability Surveys}, 1:299--320.

%
%\bibitem{jone:hobe:2004}
%Jones, G. L. and Hobert, J. P. (2004).
%\newblock Sufficient burn-in for {G}ibbs samplers for a hierarchical random effects model, 
%\newblock {\sl The Annals of Statistics}, 32:784--817.

%\bibitem{prop:wils:1996} 
%Propp, J. G. and Wilson, D. B. (1996).
%\newblock Exact sampling with coupled {M}arkov chains and applications to statistical mechanics,
%\newblock {\sl Random Structures and Algorithms}, 9:223--252.
% 
%\end{thebibliography}




\end{document}
%:
