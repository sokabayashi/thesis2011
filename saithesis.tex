\documentclass[oneside]{myumnStatThesis}
%\usepackage{epsfig}
\graphicspath{{Figures/}}
\usepackage{graphicx}
\usepackage{epsfig,color}
\usepackage{algpseudocode}

\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\I}{I}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\logit}{logit}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\bd}{bd}
\DeclareMathOperator{\intr}{int}
\DeclareMathOperator{\rint}{rint}
\DeclareMathOperator{\con}{con}
\DeclareMathOperator{\pos}{pos}
\DeclareMathOperator{\aff}{aff}
\DeclareMathOperator{\epi}{epi}
\DeclareMathOperator{\lev}{lev}

\def\RR{{\mathbb R}}
\def\ZZ{{\mathbb Z}}
\def\DD{{\mathcal D}}
\def\XX{{\mathcal X}}
\def\YY{{\mathcal Y}}
\def\TT{{\mathcal T}}
\def\NN{{\mathcal N}}
\newcommand{\deriv}[2]{\frac{d #1}{d #2}}
\newcommand{\dderiv}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\pderiv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\ppderiv}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\ppmderiv}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\fatdot}{\,\cdot\,}
\newcommand{\inner}[1]{\langle #1 \rangle}
\newcommand{\set}[1]{\{\, #1 \,\}}
\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\norm}[1]{\lVert #1 \rVert}
\newcommand{\etaMLE}{\hat{\eta}_{\textrm{MLE}}}
\newcommand{\betaMLE}{\hat{\beta}_{\textrm{MLE}}}
\newcommand{\thetaLCM}{\hat{\theta}_{\textrm{LCM}}}
\newcommand{\etaLCM}{\hat{\eta}_{\textrm{LCM}}}
\newcommand{\yobs}{y_{\textrm{obs}}}
\newcommand{\Gammalim}{\Gamma_{\textrm{lim}}}
\newcommand{\CLCM}{C_{\textrm{LCM}}}



\author{Saisuke Okabayashi}
\adviser{Charles J. Geyer}
%\coadviser{Co-Adviser Name Here}
\title{Maximum Likelihood in Exponential Family Models \\
for Social Networks}
\month{April}
\year{2011}
% Month and Year of Degree Clearance, NOT necessarily when you defended

\begin{document}

%\makesignaturepage % required
\maketitlepage % required
%\makecopyrightpage % recommended, required if registering copyright
%\frontmatter
%\begin{acknowledgementspage} % optional
%I owe all of my success to Alicia who is awesome.
%\end{acknowledgementspage}

\begin{abstract}
\input{abstract}
\end{abstract}

\tableofcontents % required

\newpage
\chapter*{List of Tables}
\addcontentsline{toc}{chapter}{List of Tables}
{\def\chapter*#1{}
\listoftables}

\newpage
\chapter*{List of Figures}
\addcontentsline{toc}{chapter}{List of Figures}
{\def\chapter*#1{}
\listoffigures}


\mainmatter
\onehalfspacing % SAI - REMOVE WHEN DONE EDITING
\chapter{Introduction}
%\input{Introduction}
\section{Motivation: social network models}
Is it possible to build a mathematical model that captures the behavioral tendencies 
of individuals in how they form relationships?\\  % in a group?

This is the question that led us to study parameter estimation methods for exponential 
families, with a particular interest in models used to describe social network data.  
Formally, a \emph{social network} is the collection of \emph{actors} and the 
\emph{relations} between each pair of actors.
Social scientists have studied social networks as a discipline since as early as the 
1930s when Moreno introduced the sociogram, a diagram that denotes individuals in a 
group as points and the presence of a relation, or tie, between individuals by lines 
\citep{Wasserman:1994}.  A sociogram depicting the marriage network data among sixteen 
important families in Renaissance Florence \citep{Padgett} is depicted in 
Figure~\ref{F:Florentine} and a sociogram depicting the affinity, or ``liking" relation, among 18 
monks in a monastery in New England in the late 1960s \citep{Sampson} is depicted in 
Figure~\ref{F:Sampson}.  In such settings, a social scientist is often interested in 
understanding whether relations arise out of friendliness or a strategy for alliance 
building, that is, driven by actor-specific attributes or by the structure of 
surrounding relations.
\begin{figure}
\begin{center}
%\includegraphics[width=4.5in]{florentine} %,keepaspectratio
\end{center}
\caption{\citeauthor{Padgett}'s \citeyearpar{Padgett} marriage network among 16 
Florentine families around 1430.  At the time, two factions, one revolving around the 
Medicis and the other around the Strozzis, vied for political control of the city.   
Data is available through and plotted using the \texttt{ergm} package \citep{ergm} in 
R.}
\label{F:Florentine}
\end{figure}

\begin{figure}
\begin{center}
%\includegraphics[width=4.5in]{samplike}
\end{center}
\caption{\citeauthor{Sampson}'s \citeyearpar{Sampson} ``liking" network among 18 monks 
in a New England monastery in the late 1960s.  Since ``liking" is a directional 
relation, the presence of a relation is depicted by an arrow rather than a line.  Data 
is available through and plotted using the \texttt{ergm} package \citep{ergm} in R.}
\label{F:Sampson}
\end{figure}

Stochastic network models were developed as early as 1959 in the seminal works of 
\citet{Gilbert} and \citet{Erdos}, resulting in a simple probabilistic model that is 
now referred to as the Bernoulli model or the Erd\"{o}s-R\'{e}nyi-Gilbert model.  Over 
the last forty years, more sophisticated stochastic network models have flourished;  
notable landmarks include the $p_1$ model of \citet{Holland:1981} which captures the 
reciprocal tendency of relationships in directed networks, and the $p^*$ model of 
\citet{Frank:1986} which describes the transitive tendency of relationships in 
undirected networks.  These models laid the foundation for the more general 
\emph{exponential family random graph models (ERGM)}, a class of exponential family models that 
are now routinely used to model network data.  They are now commonly referred
to as ``exponential random graph models" and are presented in detail in 
Section~\ref{S:ERGM examples}.
% \citep{logit,Pattison:1999,Handcock:2006,introp*,advancesp*,recentp*,ergm,Morris:
%2008,Goodreau:2009,Goldenberg:2009}.

%\subsection{THE ISSUE -- DEPENDENCE}
At their core, stochastic network models attempt to describe whether or not a relation 
forms between each pair of actors in a group.
%  In the Florentine marriage network depicted in Figure~\ref{Padgett}, a model fit  
It has long been observed that relations, especially those involving humans, do not 
form in isolation; rather, they form in an interdependent manner.  Whether or not a 
relation forms between individuals $A$ and $B$ may very well depend on whether or not 
relations form between $B$ and $C$ and $C$ and $A$.  This has profound implications 
for the social scientist, necessitating a new ``network" perspective that recognizes 
the relational structures, such as a triangle of relations between actors $A$, $B$, 
and $C$, as factors in the analysis \citep{Wasserman:1994}.  This perspective has 
garnered increasing attention across different social and behavioral science 
disciplines over the last forty years, as evidenced by the rapid growth in publication 
of social network related papers \citep{Knoke:2008}.
% in the social science literature 
  
For the statistician, the network perspective means that the model should not break the 
network down into independent components with each containing two actors.
Instead, a good model will consider important relational structures in the observed network 
and clarify their contribution in shaping the global outcome.   
Accompanying the model must also be a computational algorithm to calibrate the model 
parameters to the network data.  
%In fact, this is the focus of our research.
In fact, writing down the expression for an uncalibrated ERGM turns out to be quite
straightforward; it is fitting the model
to data that is an open research problem and the focus of our paper.

Typically, parameter estimation is done through the method of 
\emph{maximum likelihood} in which values for the parameters called \emph{maximum 
likelihood estimators (MLE)} that index the model to make the observed data most likely 
are calculated.
Many methodologies have been developed over the years to address the difficulties
in this process
including Besag's \emph{pseudolikelihood} approach \citep{Besag:1974,Strauss:1990}, 
\citeauthor{Geyer:1992}'s \citeyearpar{Geyer:1992}
\emph{Markov chain Monte Carlo Maximum Likelihood} (MCMC-ML) approach, and 
\emph{stochastic approximation}\footnote{Actually, stochastic approximation has more general
applications in root finding, but has been frequently used for parameter estimation}.  
In fact, it was the absence of usable methodologies in parameter estimation that 
restricted earlier models like $p_1$ and $p^*$ to their simpler modeling capabilities.

%the simple expression belies the difficulties involved in fitting the model to data.
%In this paper, we describe further advances to these methodologies that address some of the
%pathologies researchers have encountered with these approaches.

Once model parameters are properly estimated, the completed model can be used to simulate 
new random networks whose distributions retain essential characteristics of 
the observed network.  Researchers can then use these 
to further test hypotheses about the process of relationship formation.  
In this paper, we consider the ability to simulate such networks as the end goal of parameter
estimation rather than the parameter values themselves.  That is, the goal in maximum 
likelihood is to obtain the maximum likelihood distribution rather than the values that index
the distribution.

%it is analogous to writing the expression $y=mx+b$ as the equation of a line with 
%slope parameter $m$ and $y$-intercept parameter $b$.  
%However, just as finding the values for the parameters $m$ and $b$ that result 
%in a line that best characterizes the data is a much more involved mathematical 
%exercise, 

%
%Similarly, exponential random graph models have a deceptively simple form \eqref
%{E:ERGM} that belies the challenges involved in estimating the model parameters.  

%Network researchers have developed many descriptive statistics to capture 
%characteristics of a network.  For example, the number of ties going to a particular 
%actor is one measure of that actor's prestige in that network \citep{Wasserman:1994}.  
%\subsection{WHAT MAKES A GOOD MODEL?}
%%%%%% STATISTICAL MODEL $$$$$$$
%A good statistical model provides clarity of the underlying forces that shape the 
%structure of an observed network.   
%For example, an alternative theory to transitivity is that the frequency of triangles 
%reflects the tendency of individuals to form relationships with others of the same 
%gender.  A good statistical model can see past the noise in the data to identify if 
%one or both of these forces are important.   
%\subsection{MICRO -- MACRO}

Finally, it should be noted that although problems from the social sciences provide much of the 
motivation for social network analysis and our research here, network models can in 
fact be applied to problems in a broad range of disciplines including political 
science, biology, epidemiology, and business.  Actors often represent individuals but 
they may also represent entities like nation-states, protein molecules, or 
corporations.  The relation that connects actors is often friendship or actor $A$ 
``liking'' actor $B$, as in Sampson's monk data depicted in Figure~\ref{F:Sampson}, 
but the relation can be any kind of relation such as a business transaction or the 
Internet connectedness between computers.  Figure~\ref{F:ecoli} depicts the 
\textit{Escherichia Coli} transcriptional regulation network among 423 operons produced by 
\citet{Salgado,Shen-Orr} and modeled with ERGMs by \citet{Saul:2007,Hummel}.

\begin{figure}[h]
\begin{center}
\includegraphics[width=4.5in]{ecoli}
\end{center}
\caption{\textit{E. coli} transcriptional regulation network of \citet{Salgado,Shen-Orr}.  Each node is an operon and a directed edge from one node to another indicates 
that the first encodes the transcription factor that regulates the second.
Data is available through and plotted using the \texttt{ergm} package \citep{ergm} in 
R.}
\label{F:ecoli}
\end{figure}



\subsection{Why model?}
RETURN TO THIS SECTION.\\
Before we step into a lengthy of discussion of \emph{how} we model network data, it is 
worth reflecting upon the question of \emph{why} network models are desirable.  We 
have already given one answer to this question in the case of social scientist trying 
to differentiate between completing underlying forces that can shape the global 
structure; a network model will allow the researcher to identify if one or more actor 
specific variables and network structures contribute to the characteristic of the 
overall network.
protein-binding;

Framingham Heart Study.

Harvard flu study.


Limited!


%In this paper, we present a simple line search algorithm to find the MLE of a regular 
%exponential 
%family when the MLE exists and is unique; it is most useful in cases where standard 
%algorithms fail.  
%We show convergence of the algorithm for the case where the gradient can be 
%calculated exactly.  When it cannot, it has a particularly convenient form that is 
%easily estimable with \emph{Markov chain Monte Carlo (MCMC)}, making the algorithm 
%still useful to a practitioner.  
%
%The MLE may not exist for an exponential family, however, with positive probability.  
%In such a case, the MLE 
%is actually off ``at infinity" in some direction in the parameter space.  
%\citet
%{Geyer:gdor} illustrated an algorithm to detect non-existent MLEs and construct one-
%sided confidence intervals for the parameters in the case of generalized linear 
%models.  
%Here we describe a more general 
%approach to handle discrete state space exponential families with complex dependence 
%where the convex support may not be known initially.  We apply the approach to 
%exponential random graph models (ERGM) which are used to model networks.  Our 
%approach finds the MLE if it exists and constructs one-sided confidence intervals 
%when it does not.


%In accordance with this perspective, sociologists have developed descriptive 
%statistics of network structures to correspond to social theory.  For example, the 
%frequency of triangles, 
%%One of the simplest relationship structure is a triangle, 
%in which each individual in a group of three individuals has relationships with the 
%other two,
%may reflect the tendency of individuals to form \textit{transitive} relationships, 
%where because $A$ is friends with $B$ and $B$ is friends with $C$, $A$ is friends with 
%$C$.  %These measures can be used to characterize an observed network data set, 
%capturing qualities beyond the individual specific attributes.







\section{Exponential random graph model setup}
Networks can be modeled as a random matrix $Y$, an $n \times n$ matrix where $n$ is 
the number of actors.
Each entry $Y_{ij}$ in the random matrix $Y$ is itself a random variable representing 
a relation from actor $i$ to actor $j$, such that:
\[
	Y_{ij} = 
	\begin{cases}
		1 & \text{if a relation exists \textit{from} actor $i$ \textit{to} actor 
$j$ (notation: $i \to j$)}\\
		0 & \text{otherwise}
	\end{cases}
	\
\]
where $i$ and $j$ take values in $1, \ldots, n$, $i \neq j$, for a network with $n$ 
actors.  Note that $Y_{ij}$ take only values of $0$ or $1$, reflecting our restriction 
on networks to those with dichotomous relations, that is, the relation between a pair 
of actors is either present or absent.  In addition, we do not allow the possibility 
of $i \to i$ and always denote $Y_{ii} = 0$.  In the special case that 
$Y_{ij} = Y_{ji}$ and thus the matrix $Y$ is symmetric, the network is referred to as a \textit
{undirected} network or graph, such as in the case of the Florentine marriage network 
depicted in Figure~\ref{F:Florentine}.  A network is \textit{directed} if it is not 
undirected, as in the case of monastery affinity network depicted in 
Figure~\ref{F:Sampson}.  

The exponential family random graph model (ERGM) commonly used in the network 
literature for $Y$ has probability mass function of the following form:
\begin{align}
	f_\eta(y) = P_{\eta}(Y=y) = \frac{1}{ \kappa( \eta) } e^{ \inner{ \eta, g(y)}  } \qquad y \in \YY, \label{E:ERGM}
\end{align}
where $g(y)$ is a $d$-vector of statistics, $\eta$ is a $d$-vector of parameters, 
$\inner{\fatdot,\fatdot}$ denotes the bilinear form
\begin{align*}
	\inner{ \eta, g } = \sum_{i=1}^d g_i \eta_i,
\end{align*}
and $\YY$ is the sample space of all possible networks.
So that \eqref{E:ERGM} integrates to 1, $\kappa(\eta)$ is a normalizing constant such that
\begin{align}
   \kappa(\eta) &= \int e^{ \inner{ \eta, g(y)}  } \, d \mu(y) \label{E:kappa}
\end{align}
where $\mu$ is a measure on $\YY$.  In fact, \eqref{E:ERGM} is the exactly form of 
an exponential family distribution in \emph{canonical form} \citep{tpe}.  The only distinction that makes this an ERGM is that $\YY$ is on the discrete state space 
of possible network configurations.

We rely on many properties of exponential families.  Define 
\begin{align}
   \Xi &= \{ \eta \in \RR^d : \kappa(\eta) < \infty \}.  \label{E:paramspace}
\end{align}
The exponential family is \emph{full} if the natural parameter  space is 
\eqref{E:paramspace}, and \emph{regular} if, in in addition, $\Xi$ is an open set.
%The exponential family is \emph{full} if the natural parameter space is \eqref
%{E:fullparam}, and \emph{regular} if, in 
%addition, $\Xi$ is an open set.  
We say an exponential family is \emph{minimal} if $g(y)$ is not concentrated on a 
hyperplane. Minimality guarantees that if an MLE exists, it is unique \citep{Geyer:gdor}.


Defining the \emph{cumulant} function as $c(\eta) = \log \kappa(\eta)$, we can express 
the log likelihood of \eqref{E:ERGM} as
\begin{align}
	\ell( \eta ) = \inner{ \eta, g(y)} - c( \eta). \label{E:loglike}
\end{align}

The appeal of exponential families in the setting of complex dependence phenomena such 
as networks stems from their simplicity and maximum entropy property 
\citep{Jaynes:1978,Geyer:1992}.
By choosing statistics of interest on the data, one fully specifies a model that gives 
the 
most reasonable inference possible derived solely from those statistics.  
Furthermore, exponential families have been 
well-studied \citep{Barndorff,Brown:1986} and utilized over the decades and have 
desirable properties such as the MLE uniqueness noted above.


%%%%%%%%% NETWORK STATISTICS
Ideally then, a network researcher need only specify relational structures of interest 
to define an ERGM.  
\citet{Wasserman:1996, Pattison:1999, logit, introp*} describe many of 
the classical network statistics that one might include in the vector $g(y)$.  
In these works, the researchers' primary 
consideration in defining a network statistic is to find a relational structure 
with scientific interpretability.  
For example, in a directed affinity network, a sociologist may be 
interested in the propensity for individuals to form \emph{reciprocal} relations, where 
ties exist $i \to j$ and $j \to i$, or \emph{transitive} relations, where 
ties exist $i \to j$, $j \to k$, $i \to k$.  The vector $g(y)$ can then be defined 
\begin{align*}
	g(y) = \left ( \sum_{i<j} Y_{ij}Y_{ji}, \sum_{i \neq j \neq k} Y_{ij}Y_{jk}Y_{ik} 
			\right )  
\end{align*}
where its components count the number of reciprocal and transitive relational structures, 
respectively.  
Such a model, with parameters appropriately calibrated to the affinity network, should then 
generate networks that exhibit significantly more reciprocal and transitive relations 
than would be expected in a uniformly random network.
We will not discuss the merits or purpose of all the different network statistics 
here; what is important is that these statistics can be transparently calculated for a 
given network and the inclusion of them in $g(y)$, paired with their parameter 
component in $\eta$, allows the model \eqref{E:ERGM} to calculate probabilities of 
different global network outcomes.  

%\begin{figure}[!h]
%\centering
%\scalebox{1}{\includegraphics{tableofstats.eps}}
%\caption{Table of some commonly used basic network statistics.}
%\label{fig2} 
%\end{figure}
%%%%%% TABLE OF COMMONLY USED NETWORK STATISTICS

  \citet{Handcock:2006, Hunter:2006, recentp*} developed new network statistics with 
particular emphasis on the sensibility of the distributions generated from the specified models.  
These came about in response to the repeated discovery that poorly behaving models can
result when a researcher only considers the scientific significance of network
statistics without worrying about any ``overlap" in role of the network structures.
A fairly 
complete description of network statistics including these is in \citet{Morris:2008}.  
We will explore this issue in much more detail.
%In addition, the issue of model selection between competing models has not been 
%addressed though \citet{GOF} have begun making strides in this area.  Both of these 
%areas are active area of research.

\subsection{Intractable normalizing constant} \label{S:intractable}
We now return the issue of why parameter estimation for ERGMs and 
similar exponential family models on discrete state spaces can be challenging.
Despite the tremendous appeal of the exponential family framework, one 
immediate and sizable problem is that the summation in the expression for  the 
normalizing constant $\kappa(\eta)$ in \eqref{E:kappa}
is over all possible networks in the sample space $\YY$ and can be prohibitively expensive to 
evaluate for networks of even moderate size.
For an undirected network with $n$ actors, there are $N=2^{{n\choose 2} }$ 
different possible networks in $\YY$.  Table~\ref{T:number graphs} shows how rapidly this number grows; 
\emph{unless dealing with networks of 9 actors or less, the likelihood function 
should not be evaluated.}  Software packages like R cannot even cast $2^{31}$ as an integer,
necessitating alternative approaches.

\begin{table}[h] \label{T:number graphs}
\caption{Sample space size for networks with different number of actors.}
\begin{tabular}{ccl}
\hline 
Nodes & Possible Edges & Total Graphs \\ [1ex]
\hline
5 & ${5 \choose 2} = 10$ & $2^{10} = 1024$ \\ [1ex]
6 & ${6 \choose 2} = 15$ & $2^{15} = 32,768$ \\ [1ex]
7 & ${7 \choose 2} = 21$ & $2^{21} = 2,097,152$ \\ [1ex]
8 & ${8 \choose 2} = 28$ & $2^{28} = 268,435,456$ \\ [1ex]
9 & ${9 \choose 2} = 36$ & $2^{36} = 68,719,476,736$ \\ [1ex]
10 & ${10 \choose 2} = 45$ & $2^{45} = 3.518437\times10^{13}$ \\ [1ex]
\hline 
\end{tabular}
\end{table}
%%%%%%

\subsection{Covariate data}
Information about a particular actor, say gender, can be incorporated as 
\textit{covariate} data into the model with little difficulty.
Often, a social scientist looks to include such information because she is interested in
whether or not there is a \emph{homophily} effect, that is, whether individuals of the 
same ``type" tend to make more relations with others of that type \citep{Wasserman:1994}.  
Suppose we wish to incorporate $p$ such exogenous attributes for our $n$-actor network.  
This information can be represented by an $n \times n \times p$ matrix $X$, whose 
$ijk$th element is the value of the $k$th attribute in the potential relation from actor
$i$ to $j$ \citep{Fienberg:1981,ergm}.  

Like the other network statistics discussed, the statistics that comprise $X$ can 
be transparently calculated from the data and hence included in a new canonical 
statistics vector, $g(y, X)$,
and the corresponding canonical parameter vector $\eta$ lengthened accordingly.
The parameter estimation methodology is unchanged from before (so long as $p$ is not
excessively large), and while this greatly expands the
usefulness of ERGMs to the researcher, there are no new issues for us to consider
from a statistical modeling perspective.
Thus we will continue to use $g(y)$ instead of $g(y,X)$ for simplicity.



\section{Examples of ERGMs} \label{S:ERGM examples}
We now review the classical Erd\H{o}s-R\'{e}nyi-Gilbert, $p_1$, and $p^*$ models to give both a sense of possible network structures as well as parameter estimation methodologies.

\subsection{Erd\H{o}s-R\'{e}nyi-Gilbert model} \label{S:Erdos}
The simplest example of an exponential random graph is the Erd\H{o}s-R\'{e}nyi-Gilbert 
model \citep{Erdos,Gilbert}, also referred to as a Bernoulli network model, which 
assumes that each actor forms a relation to every other actor independently with the 
same probability $p$ \citep{Wasserman:1994, ergm}.  The ERGM can be expressed as
\begin{align*}
	P_{\eta}(Y=y) &= \frac{1}{\kappa( \eta) }e^{\eta g(y)}  \qquad y \in \YY, 
\end{align*}
where the only network statistic is a count of the number of edges for the directed network
\begin{align*}
%	g(y) = \frac{1}{N}\sum_{i \neq j} y_{ij},
	g(y) = \sum_{i \neq j} y_{ij}
\end{align*}
and the probability of a tie formation between any pair of actors is the constant
\begin{align*}
	p = \frac{e^{\eta}}{1+e^{\eta}}.
\end{align*}
%and thus the $Y_{ij}$ are mutually independent of one another.  
The MLE of $\eta$ can be found analytically to be the logit of the 
fraction of ties that are present in the data set, 
\begin{align*}
	\etaMLE = \logit \left ( \frac{\sum_{i \neq j} y_{ij}}{ N } \right )
\end{align*}
where $N = n(n-1)$, the number of possible ties in a directed network with $n$ actors.  
The MLE 
for $\eta$ is thus easily calculated from the observed data but the independence 
assumption is too unrealistic for all but the simplest of cases; usually, a researcher is 
interested in the different probabilities of tie formations between actors.

\subsection{The $p_1$ Model} \label{S:p1}
\citet{Holland:1981} made advances in relaxing this independence assumption  with 
their $p_1$ model.  They focused on two empirical observations from sociometric 
studies:
\begin{itemize}
\item Reciprocation: there tend to be a ``surplus" of mutual relationships in network 
data sets compared to a uniform distribution of directed relationships.
\item Stars: some individuals attract a surplus of choices compared to a uniform 
distribution of directed relationships.
\end{itemize}
\citeauthor{Holland:1981} then constructed a family of distributions with parameters 
to control the probability of observing different numbers of mutual relationships and 
stars.  
Focusing on the \textit{dyad}, the set of a pair of actors and the possible relations 
between them, as the basic building block, they proposed the following model:
\[
	P( Y = y ) = \frac{1}{ K( \rho, \theta, \{ \alpha_i \}, \{\beta_j \} )}\exp \left 
\{  \rho m(y) + \theta y_{++} + \sum_i \alpha_i y_{i+} +  \sum_j \beta_j y_{+j}\right 
\}
\]
subject to $\sum_i \alpha_i = \sum_j \beta_j = 0$, where
\begin{align*}
	\rho &= \text{``force of reciprocation" or mutuality parameter}\\
	m(y) &= \sum_{i \neq j} y_{ij}y_{ji}, \quad \text{number of mutual relationships 
in $y$}\\
	\theta &= \text{``density" or overall choice effect parameter}\\
	y_{++} &= \sum_{i \neq j} y_{ij}, \quad  \text{total number of relations in $y$}\\
	\alpha_i &= \text{``productivity" or ``expansiveness" effect parameter for node $i
$}\\
	y_{i+} &= \sum_{j} y_{ij}, \quad  \text{``out-degree" for node $i$ in $y$}\\
	\beta_j &= \text{``attractiveness" or ``popularity" effect parameter for node $j$} 
\\
	y_{+j} &= \sum_{i} y_{ij}, \quad  \text{``in-degree" for node $j$ in $y$}\\
	K &= \text{normalizing constant}
\end{align*}

By defining new dyad random variables, $D_{ij} = (Y_{ij}, Y_{ji} )$, \citeauthor
{Holland:1981}  show that with some algebraic manipulation the form of the model above 
can be viewed as a log-linear model with independent dyad random variables, $D_{ij}$.  
This makes it possible to use a logistic regression to calculate MLEs of the 
parameters.

The statistical independence at the dyad level, however, means that this model will 
not capture triangular tie configurations in which dyads are dependent.  Also, to 
reduce the number of parameters, the model assume $\rho_{ij} = \rho$ and $\theta_{ij} = \theta$, meaning that the 
tendency towards reciprocity and forming relations is assumed to be the same across all actors.  This example 
illustrates how the parameter estimation methodology limits the scope of the model and 
what types of behavior it can capture.  

\subsection{Markov Graph Model}
\citet{Frank:1986} relaxed the independence assumption further with the implementation 
of \textit{Markov dependence} in which two dyads are independent, conditional on the 
rest of the graph, when they do not share a node.  The model uses only three 
configurations in an undirected network, expressed as:
\[
	P( Y = y ) = \frac{1}{K( \theta, \sigma, \tau)}\exp 
				\left \{ \theta L + \sigma S + \tau T	\right \} 
	\]
where
\begin{align*}
	\theta &= 		\text{Edge parameter} \\
	L &= 		\text{Number of edges} \\
	\sigma &= \text{2-Star parameter, propensity for individuals to have connections 
with two actors} \\
	S &= \text{Number of 2-stars ($i \leftrightarrow j$, $i \leftrightarrow k$) }\\
	\tau	&= \text{Triangle parameter, represents clustering} \\
	T &= \text{Number of triangles ($i \leftrightarrow j$, $j \leftrightarrow k$, $i 
\leftrightarrow k$)}
\end{align*}
None of the above parameters have subscript indices, reflecting the simplification 
from a \textit{homogeneity} assumption where parameters are equated if the 
network structures are the same ignoring the labels on the nodes (also called \textit
{isomorphic} configurations.  In fact, this is the same simplification \citeauthor{Holland:1981} employ for the $\rho$ and $\theta$ parameters in their $p_1$ model.)  

The model is the first to break dyad independence, made possible by \citeauthor{Frank:1986}' methods of parameter estimation.  In particular, \citeauthor{Frank:1986} run 
Markov chain Monte Carlo simulations of the model at multiple values for a parameter 
to determine which fits the data best.  The authors also get \emph{maximum pseudolikelihood 
estimators (MPLE)} obtained from a standard logistic regression (we will discuss the pseudolikelihood approach in the next section) and observe that the 
MPLEs are close to those they arrived at from their rigorous simulations, leading them to suggest that these MPLEs are good enough.  

%In a chronological review of the network model literature, 
%it appears that this simplification of parameter estimation methodology helped
%propel 

%that has allowed the evolution 
%of the network model to the more general form of \eqref{E:ERGM} that we now refer as   
%More recent work has shown that this model with the exhibits problems with \textit
%{degeneracy} in which a model fit with parameters set to MLEs will generate only 
%graphs that are empty or complete \citep{Handcock:Degeneracy}.  


%%%%%%%%%%%%%%%%% SECTION %%%%%%%%%%%
\section{ERGM parameter estimation}
Exponential random graph models have a deceptively simple form \eqref
{E:ERGM} that belies the challenges involved in parameter estimation where
the difficulties
result from the intractable normalizing constant discussed in Section~\ref{S:intractable}.
%resulting from the computationally infeasible normalizing constant \eqref{E:kappa}.  
In this section, we discuss the most commonly used parameter estimation approaches
used for exponential families with complex dependence like ERGMs.  All approaches avoid evaluating the likelihood function directly but have drawbacks that can be improved upon.  
%These provide the backdrop for the new algorithm we propose in this paper.

%However, even with increasingly sophisticated simulation methods, finding MLEs for 
%ERGMs can be problematic in two ways:
%\begin{enumerate}
%\item The methodology used to find MLEs fails due to a shortcoming in the methodology 
%itself.  That is, an alternative approach might yield parameter estimates resulting in 
%a perfectly good model.
%
%\item The model itself is specified in such a manner so that it can be classified as 
%\emph{degenerate}, a term first applied to ERGMs by \citet{Handcock:Degeneracy} and 
%further clarified by \citet{Rinaldo:2009} to refer to instances where
%\begin{enumerate}
%\item Random graphs generated from the fitted model lack variability, often only 
%giving rise to unrealistic graphs, usually empty or complete (or nearly complete).
%\item the MLE does not exist.
%\item The fitted model makes the observed network highly unlikely.
%\end{enumerate}
%\end{enumerate}
%The two issues are related; for example, if the MLE does not actually exist, then 
%commonly used algorithms sent to find it will surely fail, or worse, return values 
%that the user may then treat as correct.   The issue is significant enough to be a 
%barrier to the use of ERGMs \citep{advancesp*}.



\subsection{Maximum pseudolikelihood method}
As mentioned Section~\ref{S:p1}, \citet{Frank:1986} succsesfully applied 
the maximum pseudolikelihood method to social network models, a method first used in lattice systems in plant biology \citep{Besag:1974,Besag:1975}.  \citet{Strauss:1990} further justified the use of 
maximum pseudolikelihood estimators (MPLE) as reasonable approximations for MLEs in 
social network models.  \citet{Wasserman:1996, Pattison:1999, logit} leaned on this 
result to broaden the scope of network models, allowing 
for any combination of network structures to be considered.  The result is the more general form of \eqref{E:ERGM} that is currently used.

The method of maximum pseudolikelihood finds the values for the parameters that 
maximize the \textit{pseudolikelihood function} for the observed 
data set, which can be constructed from the distributions of a dyad $Y_{ij}$ 
conditional on the rest of network, denoted by $f_{Y_{ij}}( y_{ij} \mid \textrm{rest})$.
Then the pseudolikelihood function $PL(\eta)$ is defined to be the product of these,
\begin{align}
	PL(\eta) = \prod_{i \neq j}f_{Y_{ij}}( y_{ij} \mid \textrm{rest}), \label{E:PL}
\end{align}
and in general is different than the likelihood function.

The conditional distribution of $Y_{ij} \mid \textrm{rest}$ for an ERGM is a Bernoulli 
distribution with log odds:
\begin{align}
	\log \left \{ \frac{P( Y_{ij} =1 \mid \textrm{rest} ) }
				 	 { P( Y_{ij} =0 \mid \textrm{rest} ) } \right \} 
					 			= \eta^T \Delta(g(y))_{ij}, \label{E:logodds}
\end{align}
where we define the vector of \textit{change statistics} $\Delta(g(y))_{ij}$ to be
\begin{align*}
	\Delta(g(y))_{ij} = g(y_{ij}^+) - g(y_{ij}^-)
\end{align*}
where $y_{ij}^+$ and $y_{ij}^-$ represent networks with $y_{ij} = 1$ or $y_{ij} = 0$, 
respectively, while leaving the rest of the network as $y$.  Thus $\Delta(g(y))_{ij}$ 
is the change in $g(y)$ when $y_{ij}$ changes from 0 to 1.
The form of \eqref{E:logodds} in the context of \eqref{E:PL} naturally lends
itself to the use of logistic regression through which we can get the estimates of $\eta$, called the maximum pseudolikelihood estimators (MPLE), that maximize \eqref{E:PL}.

In the case where the dyads are in fact independent, the MPLEs will equal the MLEs.  
\citet{Strauss:1990} show that in 
many cases with dyad dependence, MPLE still yield reasonable approximations of the 
true MLEs for social network models.  

However, \citet{Geyer:1992, Snijders:2002, Duijn:2009} demonstrated that 
MPLEs can produce very misleading results when dependence is strong.  \citet{Composite}
show that pseudolikelihood approach can be improved upon in a generalization called the \emph{composite likelihood} approach; this approach is identical
to the pseudolikelihood one except that the conditional distributions used to build the \emph{composite likelihood function} involve multiple dyads rather than a single dyad.
Neverthless, researchers now avoid citing parameter estimates based on these approaches.
Network software packages such as \texttt{statnet} \citep{statnet:R} in the R 
platform now overwhelmingly use MLE methods rather than MPLE.  



\subsection{Markov chain Monte Carlo methods}
\citet{Geyer:1992, Corander:1998, Snijders:2002} developed Markov chain Monte Carlo 
(MCMC) methods to approximate the MLE of an exponential family.  Of these, \citeauthor
{Geyer:1992}'s Markov chain Monte Carlo-maximum likelihood estimator (MCMC-MLE) method appears to be most commonly implemented in the 
literature and software \citep{Hunter:2006, Handcock:2006, ergm, statnet, GOF}.  

Rather than maximizing the log likelihood \eqref{E:loglike}
with respect to $\eta$, \citeauthor{Geyer:1992} fix $\eta^0$ at a known value and consider 
the log of the likelihood ratio $r( \eta, \eta^0 )$:
\begin{align}
 r( \eta, \eta^0 ) &= \ell( \eta ) - \ell( \eta^0 ) \notag \\ 
				  &= ( \eta - \eta^0)^T g(y) - \log \left [ \exp \bigl( c(\eta) - c(\eta^0) \bigr) \right ].\label{E:r}
\end{align}
The value of $\eta$ that maximizes an
approximation of $r( \eta, \eta^0 )$ is then a good estimate of the MLE when it 
exists.  
The approach does this by approximating the ratio of normalizing constants 
$\exp \left (  c(\eta) - c(\eta^0) \right )$ using \eqref{E:kappa} as follows:
\begin{align*}
	\exp \left (  c(\eta) - c(\eta^0) \right ) &= \frac{ \int \exp \bigl ( \inner{ \eta, g(x) }\bigr ) \, d\mu(x) }{ \kappa(\eta^0)  } \\
	&= \frac{ \int \exp \left ( \inner{ \eta - \eta^0, g(x)} + \inner{ \eta^0, g(x)} \right ) \, d\mu(x)  }{ \kappa(\eta^0) } \\
	&= \int \exp \left( \inner{\eta - \eta^0, g(x} \right ) \frac{ e^ { \inner{ \eta^0, g(x)} } }{ \kappa(\eta^0) } \, d\mu(x)\\
	&= \E_{\eta^0} \exp \left( \inner{ \eta - \eta^0, g(Y)}  \right ) .
\end{align*}

By the Markov chain strong law of large numbers (or Birkhoff ergodic theorem), this 
expectation can be approximated by the sample mean for large sample size,
\begin{align*}
	&\approx \frac{1}{m} \sum_{i=1}^{m}\exp \left ( \inner{ \eta - \eta^0,g(Y_i)} \right )
\end{align*}
where $Y_1, \ldots, Y_m$ are draws from the exponential family distribution with 
parameter $\eta^0$.  This sample can be generated using Markov chain Monte Carlo 
method such as a Metropolis algorithm.

Thus, $r( \eta, \eta^0 )$ can be approximated by
\begin{align}
\hat{r}_m( \eta, \eta^0 ) &= \inner{ \eta - \eta^0, g(y)} - \log 
	\left [ \frac{1}{m} \sum_{i=1}^{m} \exp \left ( \inner{ \eta - \eta^0, g(Y_i)} \right ) \right ] 
%	\left [ \frac{1}{m} \sum_{i=1}^{m} e^{  \inner{ \eta - \eta^0, g(Y_i)} } \right ] 
	\label{E:r_hat}
\end{align}
and 
\begin{align*}
	\hat{r}_m( \eta, \eta^0 ) \to r( \eta, \eta^0 ) \text{ a.s. as $m \to \infty$}.
\end{align*}

If we call the maximizer of \eqref{E:r_hat} $\hat{\eta}_m$ and assume that the MLE 
$\etaMLE$ exists, \citeauthor{Geyer:1992} show that 
\begin{align*}
	\hat{\eta}_m \to \etaMLE \quad a.s.
\end{align*}
 whenever the Markov chain is ergodic. 

In practice, \citeauthor{Geyer:1992} recognize that ``enormous" Monte Carlo sample 
sizes may be necessary and that best results are obtained when $\eta^0$ is near 
$\etaMLE$---a condition that of course cannot be checked since $\etaMLE$ is unknown.  
In addition, \citeauthor{Geyer:1992} recommend iterating the algorithm several times, 
where each successive value will be closer to $\etaMLE$ than the previous.  At the 
time of this writing, the MCMC-MLE routine in \texttt{statnet} uses by default 10,000 
Monte Carlo samples and a maximum of three iterations \citep{statnet:R}, using the 
MPLE as the initial value for $\eta^0$.  

%We follow up with an example presented by 
%\citet{ergm} in \texttt{statnet} in which the MCMCMLE procedure can fail.

\citet{ergm} illustrate the practical difficulty associated with a poor initial 
value in the MCMC-MLE algorithm with Sampson's monastery data set depicted in 
Figure \ref{F:Sampson}.  The 
observed network $\yobs$ is directed with 18 actors and 88 ties present out of $18 \cdot 17=306$ possible 
ties.  To simply illustrate the issue, \citeauthor{ergm} use the simple Erd\H{o}s-R\'{e}nyi-Gilbert model 
described in Section~\ref{S:Erdos}, with the network statistic $g(y)$ equal to the total number of 
edges present.  As noted earlier, the true MLE is equal to 
\begin{align*}
	\etaMLE = \logit\left( \frac{g(\yobs)}{n(n-1)}\right) = \logit \left( \frac{88}{306}\right ) = -0.9072.
\end{align*}
  
When $\eta^0$ is chosen to be $1$, however, \citeauthor{ergm} demonstrate 
that the algorithm will not attain this value in a single iteration.  
For this value of $\eta$, the model dictates that each of the 306 possible edges will occur independently with probability $p = \frac{1}{1+e^{-\eta}} = \frac{1}{1+e^{-1}} = 0.731$.  The problem 
arises from the fact that this is a high probability relative to the sparsity of relations in the observed data 
set, which suggests a much smaller probability of tie formation of $88/306= 0.288$.  
In fact, the probability of obtaining fewer than 88 ties for this model is nearly zero at $2.3 \times 10^{-59}$, calculated using a binomial distribution with $n=306$, $p =0.731$.  

The MCMC-MLE algorithm looks to maximize the approximated log 
likelihood ratio \eqref{E:r_hat}, but if the MCMC engine is unable to generate 
$g(Y)< g(\yobs)$, \eqref{E:r_hat} will not have a maximizer since the function will not have 
a point where the derivative is zero (see dotted-line in Figure \ref{F:MCMC-MLE}, left).  
The problem is not present when an initial value close to the true MLE like 
$\eta^0 = -1$ is used (dotted-line in Figure \ref{F:MCMC-MLE}, right).  With the default three 
iterations in the \texttt{statnet} software, the algorithm gets to $\eta = -0.364$, 
but with 10 iterations it arrives at the MLE.

\begin{figure}  \label{F:MCMC-MLE}
\begin{center} 
{\includegraphics[width=2.95in]{mcmc-mle1}}
{\includegraphics[width=2.95in]{mcmc-mle-1}}
\end{center} 
\caption{Log likelihood ratios for different values of $\eta$ for the Sampson 
Monastery data set.  Left: $\eta^0 = 1$, right: $\eta^0 = -1$. Solid lines are exact log likelihood ratios $\ell(\eta) - \ell(\eta^0)$, dotted lines are the 
approximation by \eqref{E:r_hat}.  Using code accompanying \citet{Hummel}.} 
\end{figure} 

%\begin{align*}
%\hat{r}_m( \eta, \eta^0 ) &= ( \eta - \eta^0)^Tg(y) - \log \left [ \frac{1}{m} \sum_
%{i=1}^{m} \exp \{ ( \eta - \eta^0)^Tg(Y_i)\} \right ] 
%\end{align*}





%\subsection{Generalization to exponential families}
%All of the parameter estimation issues discussed thus far for ERGMs are relevant to 
%the larger class of discrete state space exponential family models.
%These models are commonly used to model phenomena with dependent structure, 
%where the outcomes of the response variable of interest are in fact dependent on one 
%another.  For example, the Ising 
%model \citep{Ising,Potts} is an exponential family model that has been used to model 
%ferromagnetism.  A realized 
%sample from this model is depicted in Figure~\ref{F:pottsimage}, where neighboring 
%pixels (representing atoms in a crystal lattice) are more likely to have the same 
%color.  
%%We explore this model further in Section~\ref{S:Examples:Ising}.
%Other examples of phenomena with dependent structure modeled with exponential 
%families include
%plant ecology \citep{Besag:1974,Besag:1975} and the lifetime fitness of plants \citep
%{Shaw:2008}.
%
%\begin{figure}
%\begin{center}
%\includegraphics[width=4.5in,keepaspectratio]{potts}
%\end{center}
%\caption{A realized sample from an Ising model on a $32 \times 32$ lattice with $\eta 
%= \left(0, \log(1 + \sqrt{2}) 
%\right)^T$.  This value of $\eta$ corresponds to the phase transition point, where 
%the sample images are mostly one 
%color with small but significant portions of the other color.  There is no preference 
%for the dominant color to be 
%white or black.}
%\label{F:pottsimage}
%\end{figure}
%
%The algorithm and approaches we present here are generally applicable to all regular 
%exponential families on finite state spaces, including ERGMs.  Thus we present the 
%background theory at the higher level of exponential families though we will return to 
%ERGMs in our most complicated applications.

\section{Parameter estimation in exponential families}
Calculating the maximum likelihood estimators for exponential families when dependence 
is complex 
remains a challenging problem because the likelihood function may be computationally 
infeasible.  In particular, the 
form of the likelihood is determined by the chosen statistics up to a normalizing 
constant, but this normalizing 
constant may involve a summation over an astronomical number of terms.  Evaluating the 
likelihood function---let alone 
maximizing it---presents a significant challenge.
  
Two commonly used parameter estimation methods to circumvent this issue in exponential 
families are the \emph{pseudo-likelihood}
approach \citep{Besag:1975,Strauss:1990,Composite}, which finds parameter values that 
maximize the pseudo-likelihood function,
and the \emph{Markov chain Monte Carlo maximum likelihood estimate} (MCMC-MLE) 
approach \citep{Geyer:1992,Geyer:1994},
which uses MCMC to approximate the log likelihood so that it can subsequently be 
maximized.  

\subsection{MCMC-MLE}

The MCMC-MLE approach is theoretically guaranteed to converge to the MLE if it exists 
and is the default algorithm in 
software packages such as \texttt{statnet} \citep{statnet:R} in the R platform for 
network models.  
However, this approach has been shown in practice to be sensitive to initial parameter 
values when used without the 
trust region methodology recommended in \citep{Geyer:1992}, and the algorithm may 
require many iterations and enormous 
(sometimes infeasibly large) Monte Carlo sample sizes when the starting value is far 
from the MLE \citep*{ergm}.  
Improvement to the MCMC-MLE approach is an active area of research \citep{Hummel}.     

\subsection{Stochastic approximation}

Variations on the Robbins-Monro \emph{stochastic approximation} (SA) algorithm 
\citep{Robbins-Monro} have been applied to find in the MLE similar contexts: 
\citet{Younes:1988,Younes:1989,Moyeed:1991,Gu:2001}
applied MCMC stochastic approximation to spatial models and \citet{Snijders:2002} to 
social network 
models (exponential random graph models).
%Our approach shares a similar recursive mechanism with SA, so we will describe this 
%method further.  
SA procedures for finding the MLE of a parameter $\eta$ generate iterated estimates 
$\eta_k$ to find the 
root of a gradient function $h(\eta)$:
\begin{align} \label{E:eta SA update}
	\eta_{k+1} = \eta_k + \alpha_k Y_k,
\end{align}
where $\alpha_k$ is a step size and is typically a member of a decreasing sequence of 
positive numbers, and $Y_k$ is a 
random variable from the distribution specified by $\eta_k$ that noisily estimates the 
gradient function $h(\eta_k)$.  

Restrictive conditions are required of $\alpha_k$ and $Y_k$ to establish convergence 
of the sequence $\eta_k$.  
In Robbins-Monro SA \citep{Robbins-Monro}, the step size $\alpha_k$ must be a sequence 
of positive constants 
that satisfies 
\begin{align*}
	\sum \alpha_k^2 < \infty
%	\sum \alpha_k = \infty, \qquad \sum \alpha_k^2 < \infty.
\end{align*}
for which the choice of
\begin{align} \label{E:SA step size}
	\alpha_k = \frac{A}{B + k}
\end{align}
 is commonly used, where $A$ and $B$ are constants that must be specified by the user.  
This specification requires experimentation and care.  There can be significant 
variation in performance depending on choice of these constants. 
A large body of more recent research presents evidence for a sequence that goes to 0 
more slowly than $1/k$ 
for faster convergence \citep[Chapter 11]{Kushner:1997}.  
%Regardless of the exact form, there is no guarantee the likelihood function will 
%increase at each update. 

The conditions on $Y_k$ are more restrictive.  Popular approaches include constraining 
the sequence of estimators $\eta_k$ to a compact set specified \emph{a priori}, 
or assuming that the noise component of $Y_k$ be a martingale 
difference sequence.  As commonly observed \citep{Chen:2002,Andrieu:2005,Liang:2010} 
these may be 
difficult to satisfy in practice.  
See \citep{Andrieu:2005,Liang:2010} for recent developments that impose less 
restrictive conditions using truncated 
updates.

An issue for any recursive search algorithm including stochastic approximation is the 
choice of starting point.  It is 
often the case that algorithms are good at finding the MLE when the starting point is 
close to it, but of course the 
location of the MLE is unknown.  For any exponential family with bounded support, 
Fisher information 
becomes singular as the canonical parameter $\eta$ goes to $\infty$ \citep{Rinaldo:
2009}.  Hence methods which rely on 
the Fisher information matrix may fail when the starting point for $\eta$ is far from 
the MLE \citep{Younes:1989,Gu:2001}.
Of course, one may try different starting points until a ``good'' one is found, but 
this can be cumbersome in 
practice.

\section{Non-existent MLEs}
Parameter estimation via maximum likelihood for these discrete state space models with 
complex dependence---already a 
challenging problem because the likelihood function may be computationally 
infeasible---is further obfuscated by the possibility that the maximum likelihood 
estimator (MLE) may not exist in the conventional sense.  The theoretical background 
for this situation has been understood for many years (see \citet{Barndorff, Brown:
1986})---when the MLE does not exist in the conventional sense, it may exist in the 
Banrdorff-Nielsen completion of the family.
However, until recently, there have not been practical solutions to this problem.

\citet{Geyer:1992} separate the search for the MLE for such models into a two-phase 
algorithm, where phase I determines whether or not an MLE exists in the conventional 
sense via linear programming, and phase II finds the MLE when it exists.
\citet{Geyer:gdor} describes an algorithm to detect non-existent MLEs and construct 
one-sided confidence intervals in the case of generalized linear models, including 
logistic regression and contingency tables.
The approach applies repeated linear programming to the polyhedral convex support of 
the model and observed data to determine the face on which the observed data lies.  
This face in turn defines the support for a new exponential family for which the MLE 
exists and can be found using conventional methods.  The linear programming 
functionality has been implemented into the R package \texttt{rcdd} \citep{rcdd}.  
%However, this approach cannot be directly applied to the complex dependent problems 
%we consider here because the polyhedral convex support is not known except for simple 
%problems.  

\citet{Handcock:degeneracy, Rinaldo:2009} focus on problematic instances of parameter 
estimation for exponential random graph models (ERGM), a particular class of discrete 
exponential families used for modeling complex networks.  
The authors explore the geometric properties of the convex support to explain this 
issue which has come to be  referred to as degeneracy.  According to 
\citet{Handcock:degeneracy}, degeneracy includes the case of non-existent MLEs but also 
cases where a model concentrates most its probability on only a few different sample 
points in the space.  As an example, \citet{Rinaldo:2009} study in detail a 9-node 
network model and illustrate how the normal fans of the polyhedral convex support 
explain which portions of the natural parameter space are more likely to correspond to 
degenerate models.  In both works, the authors work with full knowledge of the 
geometry of the convex support, attained by enumerating all possible graph 
realizations.
%Shannon entropy

%%%%%% 1/25 - From Algorithm.tex
\textbf{Example of a degenerate social network model is in \citet{statnet-tutorial}.}  
As summarized by \citet{Rinaldo:2009}, model degeneracy refers to instances where
\begin{enumerate}
\item Random graphs generated from the fitted model lack variability, often only 
giving rise to empty graphs and complete or nearly complete graphs
\item MLE of $\theta$ does not exist.  OR HARD TO OBTAIN.  includes case where MCMC 
methods fails to converge.
\item fitted model makes the observed network very unlikely.
\end{enumerate}
%%%%%%%%%%%%%

\citet{Okabayashi:longrange} present a ``long range" search algorithm to climb the log 
likelihood of an exponential family, intended for settings where the initial guess of 
the parameter value may be far from the MLE.  The algorithm is guaranteed to converge 
when the MLE exists in the conventional sense.


\section{Algorithm overview} 
In this article, we propose a simple and practical line search algorithm that 
converges to the MLE of any regular 
exponential family when the MLE exists and is unique and the first derivative of the 
log likelihood can be calculated 
exactly.  
When it cannot, the first derivative still has a particularly convenient form that is 
easily estimable with MCMC, 
making the algorithm still useful in application.  We also show how to construct and 
apply confidence intervals in such 
a setting to increase the probability of convergence.  

The appeal of this algorithm is its usability: no trial and error is needed.  
No experimentation with multiple starting points or tuning parameters is necessary and
no unrealistic \emph{a priori} information about the problem need be specified.  
It is currently used in the \texttt{aster2} contributed R package 
\citep{aster:R} as the safeguard for steepest ascent and Newton-Raphson iterations in 
finding the MLE for aster models.

Our algorithm generates iterated estimates $\eta_k$ of the MLE $\hat{\eta}$ of the 
form 
\begin{align} \label{E:eta update}
	\eta_{k+1} = \eta_k + \alpha_k p_k
\end{align}
where $\alpha_k$ is a step size and $p_k$ is a \emph{search direction} and is 
restricted to be an ascent direction of 
the log likelihood.  
Despite the visual similarity between \eqref{E:eta SA update} and \eqref{E:eta 
update}, the line search approach treats 
the search direction $p_k$ in \eqref{E:eta update} as constant whereas in SA the 
corresponding $Y_k$ in \eqref{E:eta SA 
update} is random.
Furthermore, line search algorithms have more restrictions on the step size $\alpha_k$.  
The step size 
conditions in the classical gradient ascent algorithm, which is the basis for our 
algorithm, force  a sufficiently 
large increase in the objective function at every step, guaranteeing convergence to 
the global maximum.
%By contrast, there may be steps in SA that result in a decrease of the objective 
%function.   

Theorem 3.2 in \citep{NW} implies the global convergence of the steepest ascent 
algorithm for a continuously differentiable function, $\ell(\eta)$.  It requires the 
step length $\alpha_k$ to satisfy 
the Wolfe conditions for \emph{sufficient increase} and \emph{curvature}:
\begin{equation} \label{eq:wolfe}
\begin{split}
	\ell(\eta_k + \alpha_k \eta_k) \geq \ell(\eta_k) + c_1 \alpha_k \nabla \ell (\eta_k)^T p_k \\
	\nabla \ell( \eta_k + \alpha_k p_k)^T p_k \leq c_2 \nabla \ell( \eta_k)^T p_k
\end{split}
\end{equation}
where $\nabla$ is the gradient operator and $0 < c_1 < c_2 < 1$.   
Variations of these conditions exist in the numerical optimization literature \citep
{Fletcher,NW,Sun:2006}, but all 
require evaluating the objective function.

Exponential families we consider are an unusual case in optimization in that the 
objective function 
is harder to compute than its derivatives and hence not previously considered by 
optimization theorists.
In our algorithm, we replace \eqref{eq:wolfe} with a single modified curvature 
condition:
\begin{align} \label{E:curvature mod}
	 0 & \leq \nabla \ell( \eta_k + \alpha_k p_k)^T p_k \leq c \nabla \ell(\eta_k)^T p_k
\end{align}
for some $0 < c < 1$.  This replacement is possible while still guaranteeing 
sufficient increase and convergence 
because we have the additional property that the exponential family log likelihood 
function we consider is strictly 
concave.  The restrictions on the step size $\alpha_k$ along a particular direction 
$p_k$ and the resulting values for 
$\ell(\eta_{k+1})$ are depicted in Figure~\ref{F:alpha_region}.  



\begin{figure}
\centering
    \scalebox{.4}{\input{Figures/alphamax.pdf_t}}
	\caption{The acceptable region for step size $\alpha_k$ along a particular search 
direction $p_k$ according to the modified curvature condition \eqref{E:curvature mod}.  
The step sizes $\alpha_{c}$ and $\alpha_{\textrm{max}}$ 
correspond to values of $\nabla \ell( \eta_k + \alpha p_k)^T p_k$ equaling 
$c \nabla \ell(\eta_k)^T p_k$ and $0$, 
respectively.  The condition ensures sufficient increase in the log likelihood along 
the search direction $p_k$.}
\label{F:alpha_region}
\end{figure}
 
The desire to avoid calculation of higher order derivatives is motivated not just by 
computational considerations, but 
also by how much useful information can be extracted from them.   As noted previously, 
if $\eta$ is far from the MLE,  
the Fisher information matrix may be near-singular and algorithms like (unsafeguarded) 
Newton-Raphson algorithm may fail.  For this 
reason, the best use of our algorithm may be from ``long range,'' filling a gap in the 
MLE estimation toolbox.  It may 
be expedient to switch to another algorithm like Newton-Raphson after significant 
progress is made and 
the Fisher information matrix becomes useful.  Our line search algorithm with $p_k$ 
the Newton direction provides a
safeguard for Newton-Raphson that makes it safe (not necessarily efficient) for use 
from any range.
%, though it is difficult to quantify what is significant progress since the 
%limitations of these other algorithms are not well-defined.  
The \texttt{aster2} contributed R package \citep{aster:R} switches $p_k$ from steepest 
ascent direction to Newton direction
after a fixed number of steps ($d / 2$ where $d$ is the dimension $\eta$) but always 
finds a step length $\alpha_k$ satisfying
\eqref{E:curvature mod}, iterating until the (unsafeguarded) Newton step satisfies 
\eqref{E:curvature mod}.\\


%%% Can't just put a \newpage just anywhere in the text
%\pagebreak[3]

Our algorithm can be outlined as follows.  Let $\lVert \, \cdot \, \rVert$ denote the 
Euclidean norm function, and $\epsilon$ 
a small value greater than 0.  \\

% ALGORITHM 
\noindent Get an initial value, $\eta_0$.\\ 
Set $k=0$. \\
Calculate $\nabla \ell( \eta_k)$, the direction of steepest ascent. \\
Set $p_k = \nabla \ell( \eta_k)$. \\
\textbf{while}  $\lVert \nabla \ell( \eta_k) \rVert > \epsilon$ \\ 
\hspace{4mm} \indent	 \textbf{Find} a step size $\alpha_k$ that satisfies the modified 
curvature condition
\begin{align*}
	 0 & \leq \nabla \ell( \eta_k + \alpha_k p_k)^T p_k \leq c \nabla \ell(\eta_k)^T 
p_k
\end{align*}
\indent for some $0 < c < 1$.  
%This condition requires $\alpha_k$ to fall within \\
%\indent the acceptable region in Figure \ref{F:alpha_region}. \\


$\eta_{k+1} = \eta_k + \alpha_k p_k$.\\
\indent Calculate $\nabla \ell( \eta_{k+1})$.\\
\indent \textbf{Find} the new search direction $p_{k+1}$, which must be an ascent 
direction. \\
\indent $k = k + 1$.  \\
\textbf{end while}\\

We look to generalize this algorithm to accommodate the setting for the discrete state 
case when the MLE does not exist in the conventional sense.  In such a case, the MLE 
exists in the limiting conditional model, and the algorithm should find this new MLE.

It is a well-known theorem of exponential families that the non-existence of the MLE 
is synonymous with the the observed natural statistic occurring on a boundary of the 
convex support $C$.
Because we do not assume to know the full geometry of $C$, we do not know at the 
outset if the MLE exists.  
Thus we need to explore the sample space through sampling and determine on the fly 
whether or not the observed natural statistic occurs on a boundary of the perceived 
convex support.  
Should this occur, the algorithm defines the new limiting conditional model, which is 
the exponential family restricted to the pertinent boundary, and proceeds to maximize 
its log likelihood in search of the maximizer.

The algorithm is summarized on the next page.  Below are a few comments about notation 
and equations:
\begin{itemize}
\item $C$ is the convex support.
\item $Y$ is the random variable in the sample space.
\item $g(\cdot)$ is the function that maps $y$ to its natural statistics.
\item $\yobs$ is the observed observed, $g(\yobs)$ the natural statistics of the observed data.
\item $\con()$ is the convex hull of a set of points.
\item $\bd()$ is the boundary of a set of points.
\item $\norm{\cdot}$ is the Euclidean norm.
\item The curvature condition \eqref{E:curvature} used here comes from the search 
algorithm of \citet{Okabayashi:longrange} and is necessary for guaranteeing 
convergence to the MLE when it exists.
%\item $\bar{Y}_m$ is the sample mean, $\frac{1}{m}\sum_{i=1}^m g(Y_i)$
\end{itemize}
\newpage
{\small
\noindent \textbf{LCM MLE Algorithm}

\noindent \begin{algorithmic}[1]
\State Get an initial value, $\eta_1 = (0, \ldots 0)$.
\State \textbf{Sample} $Y_1, \ldots, Y_m$ from the distribution with parameter $\eta_{1}$.  
\State Set $ty.hull = \con(g(Y_1), \ldots, g(Y_m) )$.
\State Approximate 
\begin{align} \label{E:nabla ell approx}
\nabla \ell( \eta_1) \approx g(\yobs) - \frac{1}{m}\sum_{i=1}^m g(Y_i).
\end{align}
\State Set $p_1 = \nabla \ell( \eta_1)$, $k=1$, $LCM.flag$ = FALSE, $c=0.2$.\\
%, $LCM.k=1$, 
%\State , $on.boundary$ = FALSE, $on.interior$ = FALSE.
%\State Set $face.cutoff = 0.30$.

\While{$\lVert \nabla \ell( \eta_k) \rVert > \epsilon$}
\State \textbf{Find} a step size $\alpha_k$ that satisfies the \textit{curvature condition}
\begin{align}\label{E:curvature}
	 0 & \leq \nabla \ell( \eta_k + \alpha_k p_k)^T p_k \leq c \nabla \ell(\eta_k)^T p_k.
\end{align}
%\State for some $0 < c < 1$. % (Calculating $\nabla \ell(\cdot)$ requires more sampling)

\State $\eta_{k+1} = \eta_k + \alpha_k p_k$.
\State \textbf{Sample} $Y_1, \ldots, Y_m$ from the distribution with parameter $\eta_{k+1}$.
\If{$LCM.flag=$TRUE}
	\State Restrict sample points to those in empirical face.
\EndIf
\State Call the resulting sample points $g(Y_{(1)}), \ldots, g(Y_{(k)})$.
\State \textbf{Update} $ty.hull$ to reflect new sample points, $g(Y_{(1)}), \ldots, g(Y_{(k)})$.\\
\State \textbf{Question: $g(\yobs) \in \bd( \con(g(Y_{(1)}), \ldots, g(Y_{(k)}) ))$? }
%\If{Yes, $g(\yobs)$ is outside the convex hull}
%	\State  Keep sampling.  
%%	\State $on.boundary$ = FALSE.
%	\State Skip to estimating $\nabla \ell( \eta_{k+1})$.
%\ElsIf{No, $\yobs$ is inside the convex hull}
%	\State \textbf{The MLE exists}.  Finding it should be straightforward, (except 
%when 
%	\State it isn't ...) 
%	\State $on.boundary$ = FALSE, $on.interior$ = TRUE.
%	\State Skip to estimating $\nabla \ell( \eta_{k+1})$.
%\Else 
\If{Yes} %\Comment{$g(\yobs)$ is on the boundary of convex hull}
	\State \textbf{Either:}
	\State (1) the MLE exists but the sample just touches $g(\yobs)$, 
	\State (2) the MLE does \emph{not} exist; both $g(\yobs)$ and our sample points  
	\State are touching the boundary of $C$.
	\State \textbf{Find} the empirical face $F$ of $ty.hull$ on which $g(\yobs)$ lies.
%	\State \textbf{Calculate} $face.prop$, the proportion of the sample that falls on
%	\State this face.\\
%\newpage
	\If{$>60\%$ of the sample points are on $F$}
		\State Conclude that we are in case (2); case (1) is very unlikely.
		\State \textbf{Set} $LCM.flag$ = TRUE.
	\EndIf
\EndIf\\
%\State \textbf{Calculate} $\nabla \ell( \eta_{k+1})$ as follows: \label{Calc:nabla}
%\If{ $LCM.flag$ == FALSE }
%	\State $\nabla \ell( \eta_{k+1}) \approx g(\yobs) - \frac{1}{m}\sum_{i=1}^m g(Y_i)$
%\Else
	\State Approximate
	\begin{align} \label{E:nabla ell approx LCM}
	\nabla \ell( \eta_{k+1}) \approx g(\yobs) - \frac{1}{k}\sum_{i=1}^k g(Y_{(i)}).
	\end{align}

%, where the sample mean is restricted 
%	\State to empirical face points.
%\EndIf\\

\State \textbf{Find} the new search direction $p_{k+1}$, which must be an ascent 
direction.
\Statex This may involve using a direction normal to empirical face, or a regression 
\Statex over previous $\eta_k$ values, or simply using steepest ascent, $\nabla \ell
( \eta_{k+1})$.

\State $k = k + 1$.
\EndWhile
\end{algorithmic}

}

% \section{Example: social network models} \label{S:Example}

Our motivating application is the modeling of network data using discrete state space 
exponential families, commonly known as exponential random graph models (ERGM).  See 
\citet{Goldenberg:2009} for an comprehensive introduction to social network modeling 
and ERGMs in particular.  (ADD MORE?)
  In network problems, the data of interest can be represented by a graph, with nodes 
representing the individuals and an edge between a pair of nodes (or lack thereof) 
corresponding to the presence or absence of a relational tie between the individuals.  
Ideally, a researcher can select the network statistics of interest, thereby fully 
specifying the ERGM, and then apply maximum likelihood methods to find the MLEs.  
\citet{GOF} discuss some of the difficulties with this process, which we will not 
address in this paper. 

Like \citet{Handcock:degeneracy, Rinaldo:2009}, we focus on small networks (9 nodes or 
fewer) with only two or three network statistics.  This is because the number of 
different possible graphs can be enormous---even for an undirected 9-node network, 
there are $2^{{9\choose 2}}$, or about 68 billion different graphs.  Calculating exact 
probabilities requires summations over all graphs, a computation that is possible 
still for 9-node network, but becomes prohibitively expensive as the number of nodes 
increases.  

The choice of possible network statistics in a network model is broad and evolving; 
\citet{introp*,recentp*} describe some of the recent work in this area.  Here, for 
comparison purposes to \citet{Rinaldo:2009}, we focus first on a model with the number 
of edges and triangles as the natural statistics.  A two-dimensional statistic 
naturally lends itself to more easily interpretable figures.  We also use a model with 
a three-dimensional statistic comprising edges, triangles, and two-stars to get a 
greater variety of empirical faces and normal cones.



%Finally, a future application of this algorithm may be to discrete state space 
%exponential families 
%where the MLE for $\eta$ does not exist with positive probability.  
%In these cases, the MLE is ``at infinity'' and the concave log likelihood continues 
%to increase as 
%$\eta \to \infty$ along certain directions of recession \citep{Rinaldo:2009, 
%Geyer:gdor}.  
%Finding ``the'' MLE then becomes a very different problem, and conditions to restrict 
%$\eta$ to a 
%compact set as utilized in MCMC stochastic approximation \citep{Andrieu:2005, Liang:
%2007, Liang:2010} 
%would not be relevant.    Our proposed algorithm may be applied to this setting to 
%climb the log likelihood until it 
%``flattens out''  and the gradient approaches zero.  
%This in turn may be useful in identifying the directions of recession. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Background Theory}\label{Section:Background}
%\input{Background}

\section{Exponential Family Theory}
An exponential family of distributions \citep{Barndorff,Geyer:gdor}
on a sample space $\YY$ has log likelihood \eqref{E:loglike}.
%\begin{align} 
%   \ell(\eta) = \inner{g(y), \eta} - c(\eta)
%\end{align}
%where $g(y)$ is a $d$-dimensional vector of canonical statistics, $\eta$ a $d$-
%dimensional vector of
%canonical parameters, and $\inner{\fatdot, \fatdot}$ denotes the bilinear form
%$$
%   \inner{g, \eta} = \sum_{i =1}^d g_i \eta_i.
%$$
%So that the probability function integrates to 1,
%the cumulant function $c$ must have the form
%\begin{align} \label{E:cumulant}
%      c(\eta) = \log \left(\int e^{\inner{g(y), \eta}} \, d\mu(y) \right),
%\end{align}
%where $\mu$ is a measure on $\YY$.
%Define
%\begin{align} \label{E:fullparam}
%	\Xi = \{ \eta \in \RR^q: c(\eta) < \infty \}.
%\end{align}
%The exponential family is \emph{full} if the natural parameter space is \eqref
%{E:fullparam}, and \emph{regular} if, in 
%addition, $\Xi$ is an open set.  We say an exponential family is \emph{minimal} if $g
%(y)$ is not concentrated on a 
%hyperplane. Minimality guarantees that if an MLE exists, it is unique \citep
%{Geyer:gdor}.

In finite state space models with complicated dependence like an Ising model or 
exponential random graph model,  \eqref
{E:cumulant} is a sum which may have no simple expression and can only be evaluated by 
explicitly doing the sum.
When the sample space $\YY$ is even moderately large, this can be prohibitively 
expensive.  For example, an Ising model 
defined on a $32\times 32$ square lattice where each entry takes values of 0 or 1, 
there are $2^{1024} \approx 10^
{300}$ elements in $\YY$.  A loop with this many iterations takes too long no matter 
how programmed.

A useful property of all exponential families \cite[p.~27]{TPE2} on which we rely 
heavily is that 
\begin{align*}
	\E_\eta(g(Y)) &= \nabla c(\eta)	\\
	\Var_\eta(g(Y)) &= \nabla^2 c( \eta ).
\end{align*}

Thus we can express first and second derivatives of the log likelihood \eqref
{E:loglike} and Fisher information, $I
(\eta)$, as
\begin{align}
	\nabla \ell( \eta ) &= g(y) - \E_\eta g(Y) \label{E:nabla ell} \\
	\nabla^2 \ell( \eta ) &=  - \Var_\eta g(Y) \label{E:nabla2 ell} \\
	\I(\eta) &= -\E_\eta \nabla^2 \ell (\eta ) = \Var_\eta g(Y) \label{E:FI}
\end{align}
and thereby avoid evaluation of the problematic cumulant function $c$.


By the strict convexity of the log likelihood function ensured by \eqref{E:nabla2 
ell}, the global 
maximum, if it is exists, is attained when $\eta$ is such that $\nabla \ell( \eta ) = 
0$, or, by \eqref{E:nabla ell},
\begin{align}
	\E_\eta g(Y) = g(\yobs). \label{E:Observed-Expected}
\end{align}


\section{Convex Analysis}
The issue of MLE existence in the conventional sense in an exponential family is 
closely tied to the geometric properties of 
the convex support of the model \citep{Barndorff, Geyer:gdor, Rinaldo:2009}.  We 
describe the relevant theory from convex analysis as it pertains to the case of 
exponential families.

A \emph{convex polytope} $C$ is the convex hull of a finite set of points $V$,
\begin{align*}
	C = \con( V ).
\end{align*}
where [\textbf{DEFINE pos().}]

  By the Minkowski-Weyl theorem \citep[Theorem 19.1]{Rockafellar:1970}, this convex 
set can equivalently be represented as the intersection of a finite collection of 
closed half-spaces.  These two representations of a convex polyhedron are referred to 
as the V-representation and H-representation, respectively.  
%The V-representation of a convex polyhedron $C$ is the set of all linear combinations
%\begin{align*}
%	\sum_{i \in E \cup I} b_i \alpha_i
%\end{align*}
%where $\alpha_i$ are vectors, $b_i$ are scalars, $E$ and $I$ are disjoint finite sets 
%such that
%\begin{align*}
%	b_i \geq 0, \quad i \in E \cup I
%\end{align*}
%and if $I$ is nonempty
%\begin{align*}
%	\sum_{i \in I} b_i = 1.
%\end{align*}

The H-representation can be expressed as the solution set of a finite set of linear 
equations and inequalities,
\begin{align*}
	C = \{x: Ax \leq b \},
\end{align*}
where $A$ is a matrix and $b$ a vector.

A nonempty \emph{face} of a convex polyhedron $C$ is a convex subset of $C$ such that 
every line segment in $C$ with a relative interior point in $F$ has both end points in 
$F$ \citep{Rockafellar:1970}.  It is itself a convex polyhedron.
A \emph{proper} face is a face that is not the empty set or $C$, and 
\emph{facets} are proper faces of the highest dimension.

The \emph{tangent cone} of a convex set $C$ at a point $x \in C$ is
\begin{align*}
	T_C(x) = \cl\{s(w-x):w \in C \text{ and } s \geq 0 \},
\end{align*}
where $\cl$ denotes the closure operation \citep[Theorem 6.9]{Rockafellar}.  

The \emph{normal cone} of a convex set $C$ in $\RR^d$ at a point $x \in C$ is 
\begin{align*}
	N_C(x) = \{ \delta \in \RR^d: \inner{w-x,\delta} \leq 0 \text{ for all } w \in C 
\}.
\end{align*}

Tangent and normal cones are polars of each other, that is, each determines the other.  
The normal cone at $x$ can be defined in terms of the tangent cone at $x$ by
\begin{align*}
	N_C(x) 	&= \{ w \in \RR^d: \inner{ w, v } \leq 0 \text{ for all } v \in T_C(x) \}.
\end{align*}

DEFINE \emph{direction of recession}, \emph{direction of constancy}.  \textbf{get from 
\citep{Rockafellar:1970}.}

\section{MLE existence in exponential families}
Charlie's GDOR theorems rely heavily upon some results from his thesis \citep{Geyer:
1990}.  Adapted here 
using the notation from his GDOR paper,
\begin{theorem}[Theorem 2.2 in \citep{Geyer:1990}]
\begin{align*}
e^{c(\theta + s \delta) - bs} &\to 
		\begin{cases} 
			0 								& b > \sigma_c(\delta) \\
			e^{c(\theta)} P_\theta(Y \in H ) 	& b = \sigma_c(\delta) \\
			+\infty							& b < \sigma_c(\delta)
		\end{cases}
& \text{as } s \to +\infty.
\end{align*}
where $\delta$ is a non-zero direction, $C$ the convex support, and
\begin{align*}
	\sigma_C (\delta) = \sup_{y \in C} \inner{ y, \delta} \\
	H_\delta = \set{w: \inner{w, \delta} = \sigma_C(\delta) }.
\end{align*}
\end{theorem}
$H_\delta$ is the supporting hyperplane to the set $C$ with normal vector $\delta$.

\begin{proof}
\textbf{Case: $b = \sigma_C(\delta)$.}

Starting with density of the exponential family with parameter $\theta$, we know that
\begin{align*}
	e^{c(\theta)} = \int h(y) e^{\inner{y,\theta}} \, dy.
\end{align*}
So,
\begin{align*}
	e^{ c(\theta + s \delta ) - bs } &= \int h(y) e^{\inner{y,\theta + s \delta - 
bs} } \, dy. \\
									&= \int h(y) e^{\inner{y,\theta}  + s [ \inner
{y,\delta} - b ] } \, dy. 
\end{align*}
Multiply by $\frac{p_\theta(y)}{p_\theta(y)}$ to get
\begin{align*}
	e^{ c(\theta + s \delta ) - bs } &= \int h(y) e^{\inner{y,\theta}  + s [ \inner
{y,\delta} - b ] }  \frac{ h(y)e^{\inner{y, \theta} - c(\theta)} }{ h(y)e^{\inner{y, 
\theta} - c(\theta)} }\, dy \\
	&= \int e^{  s [ \inner{y,\delta} - b ] + c(\theta) }  h(y)e^{\inner{y, \theta} - 
c(\theta)} \, dy \\
	&= \E_\theta e^{  s [ \inner{Y,\delta} - b ] + c(\theta) }
\end{align*}
What happens as $s \to +\infty$?  We would like to reverse the order of taking the 
limit and expectation.  Fortunately, we have the monotone convergence theorem.  For $
\inner{y, \delta} \leq b$, we have a monotonically decreasing sequence of random 
variables.  For $\inner{y, \delta} > b$, the sequence is increasing.  Thus,
\begin{align*}
	\lim_{s\to \infty} \E_\theta e^{  s [ \inner{Y,\delta} - b ] + c(\theta) } &= E_
\theta \lim_{s\to \infty} e^{  s [ \inner{Y,\delta} - b ] + c(\theta) }. 
\end{align*}
Ignoring the expectation and examining the just limit component of the above,
\begin{align*}
	\lim_{s\to \infty} e^{  s [ \inner{Y,\delta} - b ] + c(\theta) } &= 
			\begin{cases} 
			0 								& \inner{Y,\delta} < b \\
			e^{c(\theta)} 		 			& \inner{Y,\delta} = b \\
			+\infty							& \inner{Y,\delta} > b.
		\end{cases}
\end{align*}
In the case that we are considering, however, $b = \sigma_C(\delta) = \sup_{y \in C}
\inner{y,\delta}$, so $\inner{Y,\delta}$ can never be greater than $b$, so the third 
case in the limit above is not possible.  Thus we can rewrite the result above 
succinctly as
\begin{align*}
	\lim_{s\to \infty} e^{  s [ \inner{Y,\delta} - b ] + c(\theta) } &= I(\inner{Y,
\delta} = b ) e^{c(\theta)} 
	= I( Y \in H_\delta ) e^{c(\theta)}.
\end{align*}
Then returning to the full expression,
\begin{align*}
	\lim_{s\to \infty} \E_\theta e^{  s [ \inner{Y,\delta} - b ] + c(\theta) } &= e^
{c(\theta)} P( Y \in H_\delta ).
\end{align*}

\textbf{Case: $b > \sigma_C(\delta)$}.
\begin{align*}
	\lim_{s\to \infty} e^{ c(\theta + s \delta ) - bs } &= 
	\lim_{s\to \infty} e^{ c(\theta + s \delta ) - \sigma_C(\delta)s + \sigma_C
(\delta)s - bs }  \\
	&= \left( \lim_{s\to \infty} e^{ c(\theta + s \delta ) - \sigma_C(\delta)s} 
\right ) \left(  \lim_{s\to \infty} e^{ s[ \sigma_C(\delta) - b] } \right )\\
	&= \left (e^{c(\theta) }P(Y\in H_\delta) \right ) \cdot 0 = 0.
\end{align*}

\textbf{Case: $b < \sigma_C(\delta)$}.
\begin{align*}
	\lim_{s\to \infty} e^{ c(\theta + s \delta ) - bs } &= 
	\lim_{s\to \infty} e^{ c(\theta + s \delta ) - \sigma_C(\delta)s + \sigma_C
(\delta)s - bs }  \\
	&= \left( \lim_{s\to \infty} e^{ c(\theta + s \delta ) - \sigma_C(\delta)s} 
\right ) \left(  \lim_{s\to \infty} e^{ s[ \sigma_C(\delta) - b] } \right )\\
	&= \left (e^{c(\theta) }P(Y\in H_\delta) \right ) \cdot \left ( + \infty \right ) 
= + \infty.
\end{align*}
\end{proof}

The \emph{convex support} of an exponential family is the smallest closed convex set 
that the contains the natural statistic \citep{Geyer:gdor}.

\begin{theorem}[Theorem 1 from \citet{Geyer:gdor}] \label{Thm:DOC}
For a full exponential family with
\begin{itemize}
\item log likelihood function, $\ell(\eta)$, as in \eqref{E:loglike},
\item natural parameter space, $\Xi$, as in \eqref{E:fullparam},
\item natural statistic, $g(Y)$,
\item observed data, $\yobs$, such that $g(\yobs) \in C$, the convex 
support,
\end{itemize}
the following are equivalent:
\begin{enumerate}
\item $\delta$ is a direction of constancy of the log likelihood.
\item For all $\eta \in \Xi$, the function $s \mapsto \ell( \eta + s\delta)$ is 
constant on $\RR$ \cite[Theorem 1 (b)]{Geyer:gdor}.
\item The parameter values $\eta$ and  $\eta + s\delta$ correspond to the same 
probability distribution for all $\eta \in \Xi$ and all real $s$ \cite[Theorem 1 (d)]
{Geyer:gdor}.
\item $\inner{g(Y) - g(\yobs),\delta} = 0$ almost surely for all distributions in the 
family \cite[Theorem 1 (f)]{Geyer:gdor}.
\item $\delta \in N_C(g(\yobs))$ and $-\delta \in N_C(g(\yobs))$ \cite[Theorem 1 (g)]
{Geyer:gdor}.
\item $\inner{w,\delta} = 0$ for all $w \in T_C(g(\yobs))$ \cite[Theorem 1 (h)]
{Geyer:gdor}.
\end{enumerate}
\end{theorem}
The set of all directions of constancy is called the \emph{constancy space} of the log 
likelihood.

\begin{theorem}[DOR: Theorem 3 from \cite{Geyer:gdor}] \label{Thm:DOR}
For a full exponential family with the same setting as Theorem~\ref{Thm:DOC},
%\begin{itemize}
%\item log likelihood function, $\ell(\eta)$, described by \eqref{E:loglike},
%\item natural parameter space, $\Xi$,
%\item natural statistic, $g(Y)$,
%\item observed value of the natural statistic, $g(\yobs)$, such that $g(\yobs) \in C$, the convex 
%support,
%\end{itemize}
the following are equivalent:
\begin{enumerate}
\item $\delta$ is a direction of recession of the log likelihood.
\item For all $\eta \in \Xi$, the function $s \mapsto \ell( \eta + s\delta)$ is 
nondecreasing on $\RR$ \cite[Theorem 3 (b)]{Geyer:gdor}.
\item $\inner{g(Y) - g(\yobs),\delta} \leq 0$ almost surely for all distributions in 
the family. \cite[Theorem 3 (d)]{Geyer:gdor}.
\item $\delta \in N_C(g(\yobs))$ \cite[Theorem 3 (e)]{Geyer:gdor}.
\item $\inner{w,\delta} \leq 0$ for all $w \in T_C(g(\yobs))$ \cite[Theorem 3 (f)]
{Geyer:gdor}.
\end{enumerate}
\end{theorem}


%%%%%%%%%%%%%%%%%%%%%%% 1/26/11 - Added from Algorithm.tex
\subsection{Theorem 3(a) and (c), \citet[p. 270]{Geyer:gdor}}
So what do we this theorem for?  It relates when $\delta$ is a direction of recession 
or not.  Theorem 3 in GDOR has says the following are equivalent:
\begin{itemize}
\item (a) There exists a $\theta \in \Theta$ such that the function $s \mapsto \ell
(\theta+s\delta)$ is nondecreasing on $\RR$.
\item (c) $\inner{Y-y, \delta} \leq 0$ almost surely for all distributions in the 
family.
\end{itemize}

The $\delta$ in (a) in the above is a direction of recession.  

The proof requires the following lemma, which a PROOF WILL BE NEEDED.
$\ell(\theta+s\delta)$ is non-dereasing if and only if $\lim_{s \to \infty} \ell
(\theta+s\delta) > -\infty$.

\textbf{From $(c) \to (a)$}:

Take $\E_{\theta + s \delta}()$ of $\inner{Y-y, \delta} \leq 0$.  Then
\begin{align*}
\inner{ \E_{\theta + s \delta} Y-y, \delta} \leq 0.
\end{align*}
Now, take the derivative of $\ell( \theta + s\delta)$ with respect to $s$.
\begin{align*}
\deriv{\ell( \theta + s \delta}{s}) &= \deriv{}{s} \left (   \inner{y, \theta+s
\delta} - c(\theta+s\delta)  \right )\\
	&= \inner{y, \delta} - \deriv{}{s} c(\theta+s\delta) \\
	&= \inner{y, \delta} - \inner{ \E_{\theta+s\delta}Y,\delta }\\
	&= - \inner{ \E_{\theta+s\delta}Y - y,\delta }.
\end{align*}
Applying the above from the assumption, we get that 
\begin{align*}
\deriv{\ell( \theta + s \delta)}{s} \geq 0.
\end{align*}
Thus $\ell(\theta+s\delta)$ is a non-decreasing function of $s$.

\textbf{From $(a) \to (c)$}:
\begin{align*}
	\ell( \theta+s\delta) &= \inner{y, \theta+s\delta} - c(\theta+s\delta) \\
	&= \inner{y, \theta} + s \inner{y,\delta} -bs +bs - c(\theta+s\delta) \\
	&= \inner{y, \theta} + s [\inner{y,\delta} -b]  - \log e^{c(\theta+s\delta) -bs}.
\end{align*}
We know from the above lemma that $\ell(\theta+s\delta)$ is non-dereasing if and only 
if $\lim_{s \to \infty} \ell(\theta+s\delta) > -\infty$.  This implies that in the 
above expression, for the right-most term, $b \geq \sigma_c(\delta)$, and also that
\begin{align*}
	\inner{y, \delta} - b \geq 0,
\end{align*}
or 
\begin{align*}
	b - \inner{y, \delta}  \leq 0.
\end{align*}
If the above is true, then 
\begin{align*}
	\sigma_C(\delta)  - \inner{y, \delta} \leq b - \inner{y, \delta}  \leq 0,
%#	\inner{y, \delta} - \inner{Y_{max},\delta } \geq 0.
\end{align*}
and recalling that $\sigma_C(\delta) = \sup_{y \in C} \inner{y, \delta}$, then
\begin{align*}
	\inner{Y - y,\delta } \leq 0.
\end{align*}
(with probability one---do I even need to add this).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

From the two theorems above, it is clear that every direction of constancy is a 
direction of recession.  These induce the following criteria about the existence of 
the MLE in the conventional sense:

\begin{corollary}[Theorem 4, Corollary 5 \citep{Geyer:gdor}] \label{Cor:MLE DNE}
For a full exponential family with the setting as Theorem~\ref{Thm:DOC}, if $\delta$ 
is a 
direction of recession that is not a direction of constancy, then  
\begin{enumerate}
\item the MLE does not exist.
\item $N_C(g(\yobs))$ is a vector subspace.
\item $T_C(g(\yobs))$ is a vector subspace.
\item for all $\eta \in \Xi$, the function $s \mapsto \ell(\eta + s \delta)$ is 
strictly increasing on 
the interval where it is finite.
\end{enumerate}
\end{corollary}

The \emph{relative interior} of a convex set $C$, denoted $\rint C$, is the interior 
relative to its affine hull.  We call $\delta$ a \emph{generic direction of recession} 
(GDOR) if $\delta \in \rint N_C(g(\yobs))$.  By construction it is not a direction of 
constancy.  By Corollary~\ref{Cor:MLE DNE}, a GDOR exists if and only if the MLE does 
not exist.

The well-known condition for the existence of the MLE \citep{Barndorff, Brown:1986} is 
formally stated as follows:
\begin{theorem} \label{Thm:MLE rint}
Under the conditions [CONDITIONS], the MLE exists in the conventional sense and is 
unique if and only if 
$g(\yobs) \in \rint(C)$.
\end{theorem}

When the MLE does not exist for an exponential family in the conventional sense, there 
exists a GDOR along which the log likelihood goes to $+\infty$.  The behavior of the 
density of the distribution is described in the following theorem:

\begin{theorem}[Theorem 6 from \citet{Geyer:gdor}] \label{Thm:LCM}
For a full exponential family with the setting as Theorem~\ref{Thm:DOC}, and 
additionally,
\begin{enumerate}
\item density function \eqref{E:pdf},
\item direction of recession, $\delta$,
\item $H = \{ w \in \RR^d: \inner{ w-g(\yobs), \delta } = 0 \}$,
\item $P( g(Y) \in H) > 0$ for some distribution in the family,
\end{enumerate}
then for all $\eta \in \Xi$
\begin{align} \label{E:LCM}
\lim_{s \to \infty} f_{\eta+s\delta}(y) = 
			\begin{cases} 
			0 								& \inner{g(Y) - g(\yobs), \delta} < 0 \\
			\frac{f_\eta(y)}{P_\eta(g(Y) \in H)} 	& \inner{g(Y) - g(\yobs),
\delta} = 0 \\
			+\infty							& \inner{g(Y) - g(\yobs), \delta} > 0.
		\end{cases}
\end{align}
If $\delta$ is not a direction of constancy, then $s \mapsto P_{\eta+s\delta}( g(Y) 
\in H)$ is continuous and strictly increasing, and 
$P_{\eta+s\delta}( g(Y) \in H) \to 
1$ as $s \to \infty$.
\end{theorem}


The right-hand side of \eqref{E:LCM} can be viewed as a conditional density of a 
distribution with parameter $\eta$ given $g(Y) \in H$ and hence expressed as $f_{\eta}
(\, \cdot\,  | g(Y) \in H)$ (the set that maps to $+\infty$ has probability zero by 
Theorem~\ref{Thm:DOR}).  Because it still has the same functional form as the 
exponential family density, $f_\eta(y)$, the family of distributions
\begin{align} \label{E:f conditional}
\{ f_{\eta}(\, \cdot\,  | g(Y) \in H) \text{ for } \eta \in \Xi \}
\end{align}
is itself an exponential family with the same natural parameters and statistics as the 
original family.  
%Then we can succinctly summarize the result of Theorem~\ref{Thm:LCM} as
%\begin{align*}
%\lim_{s \to \infty} f_{\eta+s\delta}(y) = f_{\eta}( y | g(Y) \in H).
%\end{align*}
It may not be full, however; the full family containing this exponential family,
\begin{align*}
\{ f_{\eta}(\, \cdot\,  | g(Y) \in H) \text{ for }  \eta + \gamma: \eta \in \Xi \text
{ and } \gamma \in \Gammalim \},
\end{align*}
where $\Gammalim$ is the constancy space of \eqref{E:f conditional},
is called the \emph{limiting conditional model} (LCM) \citep{Geyer:gdor}.  
An MLE for this new model must exist, since $g(\yobs)$ cannot lie on the boundary of 
the convex support which was itself determined by $g(\yobs)$ lying in the interior of 
it.  


\subsection{Theorem 6, \citet[p. 271]{Geyer:gdor}, 7/25/10}
And now the big one:
\begin{theorem}
If $\delta$ is a direction of recession, and
\begin{align*}
H = \set{ w \in \RR^p: \inner{w-y,\delta}=0 },
\end{align*}
and $P(Y \in H) > 0$ for some distribution in the family, and hence for all, then for 
all $\theta \in \Theta$,
\begin{align*}
\lim_{s \to \infty} f_{\theta+s\delta}(\omega) = 
			\begin{cases} 
			0 								& \inner{Y(\omega) - y ,\delta} < 0 \\
			\frac{f_\theta(\omega)}{P_\theta(Y \in H)} 	& \inner{Y(\omega) - y ,
\delta} = 0 \\
			+\infty							& \inner{Y(\omega) - y ,\delta} > 0.
		\end{cases}
\end{align*}
If $\delta$ is not a direction of constancy, then $s \mapsto P_{\theta+s\delta}( Y 
\in H)$ is continuous and strictly increasing, and $P_{\theta+s\delta}( Y \in H) \to 
1$ as $s \to \infty$.
\end{theorem}
Before going on to the proof, let's think about what this means.  Suppose $\delta$ is 
a DOR and not a DOC, because the latter is not interesting.  So, the MLE does not 
exist because the log-likelihood, despite being strictly convex, is strictly 
increasing when we go in the direction of $\delta$.  That's what DOR means.  So then 
what?

Well, we need to think first about $H$ again, this plane that is perpendicular to $
\delta$ on which the observed data $y$ lies.  Looking first at the last sentence of 
this theorem, it says that for the sequence of exponential families with parameter 
value $\theta+s\delta$, the probability of $Y$ occurring on the plane $H$ is strictly 
increasing, and in fact, going to 1.  This is what Charlie is referring to when he 
says things like ``the probability is accumulating on the boundary".  So, $H$ 
actually coincides with the boundary of the convex hull, the observed data $y$ sits 
is on this boundary (hence the MLE does not exist, by the usual MLE existence 
theorem, and hence a DOR exists).  When we take the parameter value further and 
further along in the direction of the DOR, the samples generated from that model will 
be increasingly cluster around that boundary face of the convex hull on which $y$ 
sits.

So how about the rest of the theorem?  We saw in Theorem 3 that $\inner{Y-y,\delta} 
\leq 0$ so the set where the above is $+\infty$ has probability zero.  I think the 
set for which $\inner{Y-y,\delta} = 0$ corresponds to a DOC, doesn't it?  Hmm, 
something's not right with my reasoning.

Charlie's paper says: the right side (excluding the 0 probability part) is the 
density of the conditional distribution given the event $Y \in H$ of the distribution 
having parameter value $\theta$, so we could denote the RHS by $f_\theta(\omega | Y 
\in H)$.  The exponential family with the \emph{full} natural parameter space (I'm 
glossing over some stuff) is the limiting condition model (LCM).  ``If an MLE exists 
for the LCM, then it maximizes the likelihood in the family that is the union of the 
LCM and the original family, and it maximizes the likelihood in the family that is 
the set of all limits of sequences of distributions in the original family.  When 
this happens, we say we have found an MLE in the Barndorff-Nielsen completion of the 
original family."

\begin{proof}
Hmm, I'm concerned about the different forms of $H$: are they actually all the same 
thing?  Well, carry on.

By Theorem 3, if $\delta$ is a DOR, then $\inner{Y-y, \delta} \leq 0$ which implies 
that $\inner{Y, \delta} \leq \inner{y, \delta}$.  So, the largest value that $\inner
{Y, \delta}$ can take on is $\inner{y, \delta}$.  Then $\sigma_C(\delta) = \inner{y, 
\delta}$.

Focus on the form of the density for $f_{\theta+s\delta}(\omega)$.  According the 
form of the relative density previously defined with respect to $\psi$,
\begin{align*}
 f_{\theta+s\delta}(\omega) &= e^{ \inner{y,\theta+s\delta - \psi} - c(\theta+s
\delta) + c(\psi)  } \\
 	&= e^{ \inner{y,\theta - \psi} -c(\theta) + c(\theta) + s \inner{y,\delta} - c
(\theta+s\delta) + c(\psi)  } \\
 	&= e^{ \inner{y,\theta - \psi} -c(\theta) + c(\psi) - c(\theta+s\delta) + s 
\inner{y,\delta} + c(\theta)   } \\
 	&= f_\theta(\omega) \frac{e^{c(\theta)}}{e^{ c(\theta+s\delta) - \inner{y,\delta}
s } }.
\end{align*}
This form is starting to look familiar, in particular, the denominator is from 
Theorem 2.2 from \citet{Geyer:1990} except with $\inner{y,\delta}$ instead of $b$ 
(where this 
$y$ is the dummy variable in the density, not the observed data).  So what happens as 
$s \to \infty$?  

It depends on how $\inner{Y(\omega),\delta}$ relates to $\sup_{y \in C}\inner{y,
\delta} = \inner{y,\delta}$, for the observed data $y$.  (our notation is getting a 
little confusing since $y$ can denote the observed data $y$ or the dummy variable in 
the density).  
\begin{align*}
	f_{\theta+s\delta}(\omega) = f_\theta(\omega) \frac{e^{c(\theta)}}{e^{ c(\theta+s
\delta) - \inner{y,\delta}s } } 
	\to	
			\begin{cases} 
			0 								& \inner{Y(\omega),\delta} < \inner{y,
\delta} \\
			\frac{f_\theta(\omega)}{P_\theta(Y \in H)} 	& \inner{Y(\omega) ,
\delta} = \inner{y,\delta} \\
			+\infty							& \inner{Y(\omega),\delta} > \inner{y,
\delta}.
	\end{cases}
\end{align*}
For $\delta$ a DOR but not DOC, we need to show that the $P_{\theta+s\delta}(Y \in H) 
\to 1$ 
as $s \to \infty$, where $H = \set{w \in \RR^p: \inner{w-\yobs,d}=0}$.
\begin{align*}
 P_{\theta+s\delta}(Y \in H) &= \int_H e^{\inner{y, \theta+s\delta - \psi} - c(\theta
+s\delta) + c(\psi)} \, d\psi \\
		&= \E_\psi \left \{ I_H e^{\inner{y, \theta - \psi} +c(\psi) - [c(\theta+s
\delta) -s\inner{y,\delta}]} \right 
\}\\
		&= \E_\psi \left \{ I_H  \frac{e^{c(\theta)} }{ e^{ c(\theta+s\delta) -s\inner
{y,\delta} } } 
		e^{\inner{y, \theta - \psi} -c(\theta)+c(\psi)}  \right \}.
\end{align*}
Since the indicator function, $I_H$, fixes $\inner{ y, \delta}$ to be a constant, it 
can pulled out of the expectation, so that 
\begin{align*}
		 P_{\theta+s\delta}(Y \in H)
		 &= \frac{e^{c(\theta)} }{ e^{ c(\theta+s\delta) -s\inner{y,\delta} } }
		 \E_\psi \left \{ I_H   
		e^{\inner{y, \theta - \psi} -c(\theta)+c(\psi)}  \right \}, \\
		 &= \frac{e^{c(\theta)} }{ e^{ c(\theta+s\delta) -s\inner{y,\delta} } } 
		 P_\theta ( Y \in H ).
		 \end{align*}
 
Then applying Theorem 2.2 from Geyer:1990,
\begin{align*}
 P_{\theta+s\delta}(Y \in H)
		&\to \frac{1}{P_\theta(Y \in H)}  P_{\theta}(Y \in H) = 1
 \end{align*}
 as $s \to \infty$.  
 
 That this probability is strictly increasing follows directly from the DOR property 
which requires $\ell( \theta+s
\delta)$ to be strictly increasing.   
\end{proof}


\subsection{log likelihood is bounded by LCM}
\subsection{summary}



In summary, by Theorem~\ref{Thm:MLE rint}, when the observed statistic, $g(\yobs)$, is 
on the boundary of the convex support $C$, the MLE does not exist in the conventional 
sense.
Then by Corollary~\ref{Cor:MLE DNE}, there must exist a direction of recession, $
\delta$, that is not a direction of constancy.  
According to Theorem~\ref{Thm:LCM}, as we move in the natural parameter space in the 
direction of $\delta$, the distribution with this parameter value will put 
increasingly probability on points for which the natural statistics, $g(Y)$, land in 
the hyperplane $H$ on which $g(\yobs)$ lies.  This hyperplane is orthogonal to $\delta
$ by construction and contains the boundary of the convex support.  Samples generated 
from these models will therefore increasingly fall on the face on which $g(\yobs)$ 
lies as $\eta$ increases in the direction of $\delta$.  Theorem~\ref{Thm:LCM} says 
that eventually, all generated sample points will fall on this boundary.


\subsection{Mean value parameterization}

An alternative parameterization of an exponential family is the mean value 
parameterization.  For each natural parameter $\eta$, we can define the mean parameter 
$\mu$ such that
\begin{align*}
	\mu = \E_\eta g(Y).
\end{align*}
The space for the mean value parameterization is the same as the convex support of the 
natural statistics and thus lends itself to easier interpretability  \citep
{Handcock:degeneracy, Rinaldo:2009}.  In particular, $\mu = g(\yobs)$ is the MLE in 
the mean value parameterization.  \citeauthor{Handcock:degeneracy} observed that mean 
value parameters located too close to the boundary of the convex support correspond to 
degenerate distributions.  

There exists a one-to-one mapping between a natural parameter and its mean value 
parameter, and one can calculate mean value parameters from natural parameters. In 
general there is no simply way to get the natural parameter value from the mean value 
parameter (if there was, then finding MLEs would be very easy and we wouldn't need all 
these algorithms!).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Linearity}\label{S:linearity}
\citet{Geyer:gdor} defines the \emph{linearity} of a set of points $V$ to be
\begin{align*}
	L = \{ w \in V: -w \in \con( \pos V) \}.
\end{align*}
It is the subspace with bases determined by $V$.

We use this to find the face of the polyhedral convex support on which the observed 
statistic lies in the interior of.  The function \texttt{linearity} in the \texttt
{rcdd} package can take as input the rays directed from observed statistic to sample 
points generated via MCMC from the distribution with parameter value of interest.  
From these, it determines the rays that form the basis of a vector subspace.  Of 
course we are not interested in the vector subspace; we need only take the points 
corresponding to these bases as our empirical face $F$.  By construction, the observed 
statistic lies in the interior of $F$.

%Let $\widetilde{T}_C(x)$ be the empirical tangent cone at the point $x$ constructed 
%from a set of points $W$ all in $C$.  That is,
%\begin{align*}
%	\widetilde{T}_C(x) = \{ w - x: w \in W\}.
%\end{align*}
%Then for $V = \widetilde{T}_C(g(\yobs))$, the linearity corresponds to the set of 
%points from $W$ (shifted by $g(\yobs)$) that form what we refer to as the empirical 
%face $F$.  
%In our algorithm, we use the MCMC sample points for $W$.  \citet{Geyer:gdor} provides 
%the function \texttt{linearity} in the R package \texttt{rcdd} to do this computation.

%Consider the case when $g(\yobs) \in \rintr C$.  Then the MLE exists, and the 
%linearity will correspond to all the points $W \in C$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{One-sided confidence interval}

Consider the probability distributions defined with log likelihood $\ell( \eta + s 
\delta)$ as defined 
by \eqref{E:loglike}, where $s$ is a real scalar and $\delta$ is a direction of 
recession.  Then 
as $s$ goes from $-\infty$ to $+\infty$, the probability of observing $g(Y) \in H$ 
goes from zero to one.  This 
function is strictly increasing by Theorem~\ref{Thm:LCM}.  Thus we can find the unique 
$s$, call it $\hat{s}$, that makes 
this probability 0.05.  Then $[\hat{s}, +\infty)$ is a 95\% confidence interval for 
the scalar parameter 
$s$, and, in turn, $[\hat{\eta} + \hat{s}\delta, +\infty)$ gives a 95\% confidence 
interval for $\etaMLE
$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Subsampling}
%Once our algorithm has determined that the observed data is on the boundary and thus 
%the MLE does not exist in the conven
Our algorithm depends on being able to to subsample from the MC sample points when 
optimizing in the LCM, restricting to the sample points that comprise the support of 
this model.  The subsampling operation itself is straightforward since we determined 
empirically the face that forms this support.  

However, it is not obvious that when we draw $g(Y_1), \ldots, g(Y_m)$ from the 
original model with parameter value $\eta$ that the subsample restricted to the 
support is in fact a sample from the LCM with parameter value $\eta$.  This is a 
convenient consequence of Theorem~\ref{Thm:LCM}: by this stage in the algorithm, the 
majority of sample points (greater than 60\%) are on the face.  Then $s$ in the 
expression $P_{\eta + s \delta}(g(Y) \in H)$ is a large value.  But since the LCM 
density is the limit of the density of the original model as $s$ goes to $+\infty$, 
the distribution of the LCM is accordingly well approximated.  (\textbf{BUT WELL 
ENOUGH?})



\chapter{Algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Long range search algorithm for MLEs} \label{Section:Algorithm}
We now present our search algorithm, which will converge to the optimum for any 
continuously differentiable, strictly 
convex (or concave) function.  The algorithm and requirements are presented in 
Theorem~\ref{Thm:Line Search}.  Proofs 
are in Appendix~\ref{Section:Proofs}. 


We apply the algorithm in Theorem~\ref{Thm:Line Search works} to the specific setting 
of finding the MLE in a regular 
exponential family when the MLE is known to exist and be unique and the gradient can 
be calculated exactly.

%\section{Line search convergence}
In order to be consistent with the general optimization literature \citep
{Fletcher,NW}, we state our algorithm in this 
section from the perspective of a minimization problem.  Thus we wish to minimize a 
real-valued objective function $f$ 
defined on $\RR^n$.  


%%%%%%%%%%% BEGIN THEOREM %%%%%%%%%%%%%%
\begin{theorem}[Convex function root search] \label{Thm:Line Search}
Consider any line search of the form 
\begin{align}
	x_{k+1} &= x_k + \alpha_k p_k \label{E:x_update}
\end{align}
used to minimize the objective function $f$, which satisfies the following 
assumptions:
\begin{enumerate}
	\item The objective function $f$ is bounded below in $\RR^n$. \label{ass:one}
	\item The objective function $f$ is proper, lower semicontinuous, and strictly 
convex.
	\item The objective function $f$ is differentiable in an open set $\NN$ containing 
the level set $\lev_{\leq f
(x_0)} f$, which is bounded, where $x_0$ is the starting point of the iteration.
%\item The \emph{step length} $\alpha_k$ is greater than $0$ unless $\nabla f(x_k) = 0$, 
% in which case $x_k$ is already the solution and the search is complete.
\item The \emph{search direction} $p_k$ is a non-zero \emph{descent direction} \label
{ass:four}
such that the angle $\theta_k$ between the search direction $p_k$ and steepest descent 
direction $-\nabla f(x_k)$ is 
restricted to be less than 90 degrees by
\begin{align*}
\cos \theta_k \geq \delta > 0
\end{align*}
 for some fixed $\delta > 0$.  
\end{enumerate}

Then, unless $\nabla f(x_k) = 0$, in which case $x_k$ is already the solution and the 
search is complete, it is 
possible to find a step length $\alpha_k$ that satisfies the \emph{curvature 
condition}
\begin{align}
	c \nabla f(x_k)^T p_k &\leq \nabla f( x_k + \alpha_k p_k)^T p_k \leq 0 \label
{E:Wolfe-mod}
\end{align}
for some fixed $0 < c < 1$.

Furthermore, repeated iterations of \eqref{E:x_update} satisfying assumptions~\ref
{ass:one} through~\ref{ass:four} and \eqref{E:Wolfe-mod} will produce 
a sequence, $x_1, x_2, \ldots$ such that
\begin{align*}
	\lim_{k \to \infty} || \nabla f(x_k) || = 0.
\end{align*}
\end{theorem}

%\section{Line search for MLE estimation}
\begin{theorem}[Exponential family log likelihood maximization] \label{Thm:log like 
max}
Consider any line search of the form 
\begin{align}
	\eta_{k+1} &= \eta_k + \alpha_k p_k \label{E:eta_update}
\end{align}
used to minimize the negative log likelihood function $-\ell(\cdot)$ of a regular 
exponential family on a finite sample space, where the \emph{search direction} $p_k$ 
is a non-zero \emph{descent direction}
such that the angle $\theta_k$ between the search direction $p_k$ and steepest descent 
direction $-\nabla \ell(\eta_k)$ is 
restricted to be less than 90 degrees by
\begin{align*}
\cos \theta_k \geq \delta > 0
\end{align*}
 for some fixed $\delta > 0$.  

Then, unless $\nabla \ell(\eta_k) = 0$, in which case $\eta_k$ is already the solution 
and the search is complete, it is 
possible to find a step length $\alpha_k$ that satisfies the \emph{curvature 
condition}
\begin{align}
	0 \leq \nabla \ell( \eta_k + \alpha_k p_k)^T p_k  \leq c \nabla \ell(\eta_k)^T p_k  
\label{E:Wolfe-ll}
\end{align}
for some fixed $0 < c < 1$.

Furthermore, repeated iterations of \eqref{E:eta_update} along a descent direction 
satisfying \eqref{E:Wolfe-ll} will produce a sequence, $\eta_1, \eta_2, \ldots$ such 
that
\begin{align*}
	\lim_{k \to \infty} || \nabla \ell(\eta_k) || = 0.
\end{align*}
\end{theorem}



We apply Theorem~\ref{Thm:Line Search} to the setting of exponential families to find 
the MLE when it exists.  

\begin{theorem}[] \label{Thm:Line Search works}
For a regular exponential family with minimal representation where the MLE exists, the 
line search described in 
Theorem~\ref{Thm:Line Search} can be applied to the negative log likelihood function 
$-\ell(\eta)$ so that a search 
starting at any $\eta_0 \in \Xi$ will converge to the MLE of $\eta$.
\end{theorem}

The issue of MLE existence is a problem in computational geometry, not an optimization 
problem, so we do not address it 
here.  See \citep{Geyer:gdor,Rinaldo:2009} and references cited therein.

%%%%%%%% ADD CONJUGATE GRADIENT SECTION IN NEXT VERSION
\chapter{Refinements of algorithm}

In Theorem~\ref{Thm:Line Search}, we restricted our search direction $p_k$ to be a 
descent direction, so that $\nabla f
(x_k)^T p_k < 0$ or, alternatively, the angle $\theta_k$ between the search direction 
$p_k$ and steepest descent 
direction $-\nabla f(x_k)$ is less than 90 degrees.  However, this still leaves many 
possibilities for the choice of 
$p_k$ other than steepest descent.  In addition, we have specified restrictions on the 
step size $\alpha_k$ in the 
curvature condition \eqref{E:Wolfe-mod} with $0 < c < 1$, but it would be useful to 
know if certain values of $c$ are 
better than others.

\section{Search directions}
In our examples in Section~\ref{S:Examples}, we default to steepest descent directions 
in our implementation for 
transparency.  Although often effective in early steps, steepest descent directions 
can result in a zigzagging 
trajectory of the sequence $x_k$ \citep{Sun:2006}.  Conjugate gradient methods address 
this phenomena and cover the 
sample space more efficiently \citep{NW}.  It is easy to implement a variant of the 
Polak-Ribi\`{e}re method
\citep[pp.~120--122]{NW} here, requiring little more in terms of calculation or 
storage.  The search direction $p_k$ would update 
with an extra intermediate step as follows:
\begin{align*}
	\gamma_{k+1}^{PR} &= \max \left( 0, \frac{ [ \nabla f( x_{k+1}) ]^T( \nabla f( x_{k+1} ) - \nabla f( x_k) )  }
{ \lVert \nabla f( x_k) \rVert^2 } \right )\\
	p_{k+1} &= -\nabla f( x_{k+1}) + \gamma_{k+1}^{PR} \, p_k.
\end{align*}
Note that when $\gamma_{k+1}^{PR} = 0$, $p_{k+1}$ will be just $-\nabla f( x_{k+1})$, 
the direction of steepest 
descent, and thus serves as a ``reset''.  The curvature condition \eqref{E:Wolfe-mod} 
guarantees that this method always 
yields a descent direction for $p_{k+1}$ and thus Theorem~\ref{Thm:Line Search} still 
holds.  


\subsection{Further Refinement on Search Directions}
We require that the search direction, $p_k$, be an ascent direction, but make no 
further restrictions.
If we use only steepest ascent directions, using $p_k = \nabla \ell( \eta_k)$, our 
algorithm 
may not be efficient in scaling the log likelihood due to excessive ``zig-zagging" as 
illustrated in Figure 
\ref{F:zigzag}.  This is especially problematic when the MLE does not exist in the 
conventional sense---the MLE is actually off at infinity and a zig-zagging route may 
take an especially long time to realize this.  \citet{Okabayashi:longrange} made the 
case for using search directions chosen according to Polak-Ribiere conjugate gradient 
updates.  

Here we suggest another alternative that is especially useful when it appears that the 
observed statistic might fall on the boundary of the convex support.  Because our 
algorithm computes the normal cone when it finds an empirical face, we suggest using 
the average normal cone vector as a search direction, checking first that it is an 
ascent direction to ensure the algorithm proceeds uphill.  As theory in the previous 
sections show, a GDOR, if it exists, is any vector in the relative interior of the 
normal cone at the observed statistic.  So, the search direction chosen in this manner 
may in fact be a GDOR of the original model and hence result in large steps when 
meeting the curvature condition.  Alternatively, we also consider using search 
directions resulting from a regression through the previous few parameter values to 
break the zig-zagging pattern.

\begin{figure}[!ht]
\centering
\includegraphics[height=2.6in,width=2.6in]{Figures/zigzag-eta}
\includegraphics[height=2.6in,width=2.6in]{Figures/zagplusnorm-eta}
\caption{Contour plots of the log likelihood when the MLE does not exist.  The surface 
of the log 
likelihood tends to flatten, though technically it is still concave.  This can cause 
the steepest ascent 
algorithm to zigzag, which is inefficient (top).  However, by periodically using 
search directions 
determined by normal vectors  derived from the empirical face or regression through 
previous points, the algorithm can make much larger steps (bottom).}
\label{F:zigzag}
\end{figure}


\section{Step size}
We now turn our attention to the optimal step size $\alpha_k$ when our objective 
function is the log likelihood of an 
exponential family.  Taking the derivative of $\ell( \eta_k + \alpha_k p_k)$ with 
respect to $\alpha_k$ shows that the 
log likelihood is maximized as a function of $\alpha_k$ along the direction $p_k$  
when 
\begin{align*}
	\nabla \ell( \eta_{k+1} )^T p_k = 0.
\end{align*}

By choosing $c$ to be small, say 0.2, we ensure that the step taken is close to 
maximizing the log likelihood along the 
search direction.  This is also apparent in Figure~\ref{F:alpha_region}. 

Making $c$ too small, however, may make it difficult to find an $\alpha_k$ that meets 
the curvature condition \eqref
{E:curvature mod} since this search must be done numerically.  In fact, as the line 
search nears the MLE and $\nabla \ell( \eta_k)$ gets smaller, the rightmost term in \eqref{E:curvature mod} gets 
smaller in magnitude (it equals $c \lVert \nabla \ell(\eta_k) \rVert^2$ if using steepest ascent directions), making a 
numerical search for $\alpha_k$ 
more challenging.  

%Finally, while the choice of 0.2 for $c$ worked well in the problems we explored 
%regardless of search 
%directions used, it follows from our discussion in the previous section that it may 
%make sense to use slightly larger 
%values of $c$ when using steepest ascent directions, thereby reducing the zigzagging 
%phenomenon, but smaller values for 
%$c$ when using conjugate gradient methods.


\section{MCMC approximations} \label{section:MCMC approx}
Our algorithm requires us to be able to calculate $\nabla \ell(\eta)$ using \eqref
{E:nabla ell}.  For many 
applications, we will need to approximate $\E_{\eta}g(Y)$ using MCMC.  That is,
\begin{align}
 	\nabla \ell (\eta) = g(y) - \E_\eta g(Y) \approx g(y) - \frac{1}{m}\sum_{i=1}^m g
(Y_i), \label{E:nabla ell approx}
\end{align}
where $Y_1, \ldots, Y_m$ are MCMC draws from the distribution with parameter $\eta$.  
There are many MCMC algorithms 
such as Metropolis-Hastings or Swensen-Wang (used for the Ising model example in 
Section~\ref{S:Examples:Ising}); see 
\citep{Brooks} and references cited therein.
We show examples in the next section where $\nabla \ell(\eta)$ can be calculated 
exactly and where it must be 
approximated.

The accuracy of the approximation in \eqref{E:nabla ell approx} increases with Monte 
Carlo sample size $m$. 
When the current estimate is far away from the MLE, we can use smaller $m$ to save 
time and work with a 
fairly noisy approximation of the gradient.  However, when the current estimate 
approaches the MLE, larger $m$ are necessary.

Our algorithm relies on the computed values of $\nabla \ell(\eta)$ in the curvature 
condition \eqref{E:curvature mod}, 
as well as the stop condition for the algorithm, $\lVert \nabla \ell( \eta_k ) \rVert 
< \epsilon$.  Given that we may 
only have approximations of $\nabla \ell(\eta)$, we cannot know for certain if either 
of these conditions are truly 
met.  We can ameliorate this by constructing confidence intervals for each of the 
inequalities.  

For the inequalities in \eqref{E:curvature mod}, we can estimate asymptotic standard 
errors of $\nabla \ell( \eta_k + 
\alpha_k p_k)^T p_k$  and $c \nabla \ell(\eta_k)^T p_k - \nabla \ell( \eta_k + 
\alpha_k p_k)^T p_k$ by appealing to the 
Markov chain Central limit theorem \citep{Chan:1994,Jones:2004,Roberts:1997,Roberts:
2004}.
The \texttt{initseq} function from the R package \texttt{mcmc} \citep{mcmc:R} can be 
used to estimate asymptotic 
standard errors for univariate functionals of reversible Markov chains: given an MCMC 
sample for a univariate 
quantity, \texttt{initseq}
returns a value (divided by sample size) that is an estimate of the asymptotic 
variance in the Markov chain central 
limit theorem.  Both of the quantities in \eqref{E:curvature mod} are univariate.  In 
the second expression, $c \nabla \ell(\eta_k)^T 
p_k - \nabla \ell( \eta_k + \alpha_k p_k)^T p_k$, the MCMC sample generated for $
\nabla \ell( \eta_k + \alpha_k p_k)^T 
p_k$ is independent of the sample generated for $c \nabla \ell(\eta_k)^T p_k$.  Thus 
\texttt{initseq} can be applied 
to each sample separately and the results summed for an estimated variance.  
We can then be approximately 95\% confident (non-simultaneously) that $\alpha_k$ 
satisfies \eqref{E:curvature 
mod} if
\begin{align*}
	 \nabla \ell( \eta_k + \alpha_k p_k)^T p_k - 1.645 \cdot \text{se}_1 > 0 \\
	 c \nabla \ell(\eta_k)^T p_k - \nabla \ell( \eta_k + \alpha_k p_k)^T p_k - 1.645 
\cdot \text{se}_2 > 0 
\end{align*}
where $\text{se}_1$ and $\text{se}_2$ are the asymptotic standard errors for $\nabla 
\ell( \eta_k + \alpha_k p_k)^T p_k
$  and $c \nabla \ell(\eta_k)^T p_k - \nabla \ell( \eta_k + \alpha_k p_k)^T p_k$, 
respectively, calculated as described.

The delta method can be applied to estimate a standard error for $\lVert \nabla \ell
( \eta_k ) \rVert$. 
%%%%%%%%%%%%% 1/25/11 -Newly added from Algorithm.tex
The multivariate version of the delta method states that for a sequence of r.v. $B_n$ 
such that
\begin{align*}
	\sqrt{n} ( B_n - \beta) \stackrel{\DD}{\longrightarrow} N( 0, \Sigma ),
\end{align*}
then for a function $h(B)$, where $h$ such that $\nabla h$ is defined and non-zero,
\begin{align*}
	\sqrt{n} \left ( h(B_n) - h(\beta) \right ) \stackrel{\DD}{\longrightarrow} N 
\left ( 0, \nabla h( \beta)^T \Sigma\nabla h( \beta)  \right ).
\end{align*}

We set $B_n = \nabla \ell_n( \theta)$ and $\beta =\nabla \ell( \theta)$, where we 
know that $B_n \stackrel{a.s.}{\longrightarrow} B$ by SLLN.  
We also do not know $\Sigma$, the variance of $\nabla \ell( \theta)$, but this we will 
approximate with $
\hat{\Sigma}$, the scaled sample variance-covariance matrix of our MCMC batches of 
the canonical statistic (the \texttt{initseq} function 
requires a univariate vector and so cannot be used here).  That is,
\begin{align*}
	\hat{\Sigma} = \frac{1}{nbatch}\frac{1}{m-1}\sum_{i=1}^{m} (g(Y_i) - \overline{g
(Y)})( g(Y_i) - 
\overline{g(Y)})^T.
\end{align*}

%%%%%%%%%%%%%%%
Thus the asymptotic variance is calculated by
\begin{align*}
	V \left( \lVert \nabla \ell( \eta_k ) \rVert \right )= \frac{1}{\lVert \nabla \ell
( \eta_k ) \rVert^2} \nabla \ell
( \eta_k )^T \, \hat{\Sigma} \,  \nabla \ell( \eta_k ),
\end{align*}% added hat to Sigma
%where $\Sigma$ is the variance matrix of $\nabla \ell( \eta_k )$ and can be estimated 
%by the sample variance matrix of 
%the batch mean vectors of $g(Y_1), \ldots, g(Y_n)$ divided by the number of batches 
%(the \texttt{initseq} function 
%requires a univariate vector and so cannot be used here).  
We can be approximately 95\% confident that $\lVert 
\nabla \ell( \eta_k ) \rVert > \epsilon$ if 
\begin{align*}
	\lVert \nabla \ell( \eta_k ) \rVert - 1.645 \sqrt{ V \left( \lVert \nabla \ell
( \eta_k ) \rVert \right )} > 
\epsilon.
\end{align*}
%To be conservative, we suggest using a larger quantile, say 2, 
%in the confidence intervals instead of the 1.645 used above.

In practice, however, use of confidence intervals does not appear necessary with  
Monte Carlo sample sizes that are set 
large enough so that these standard errors are initially small relative to the point 
estimates.  The ratio of point 
estimate to standard error of course decreases as the algorithm progresses and the 
estimate of the parameter nears the 
MLE, reflected in $\nabla \ell( \eta_k )$ nearing 0.  Thus these confidence intervals 
are most useful as a guide for
when to increase the MCMC sample size, or when to switch methods, or when to terminate 
the algorithm.



\section{Combining with other algorithms}
We believe the best use of this algorithm is in combination with other faster methods 
like MCMC-MLE \citep{Geyer:1992}
or Newton-Raphson safeguarded by our line search algorithm.  Our algorithm with 
steepest ascent or conjugate gradient search direction
should be used initially from ``long range'', when one has no good intuition for an 
initial value.
It is well known that when the objective function is quadratic the conjugate gradient 
method with exact arithmetic converges to the solution
in at most $d$ steps, where $d$ is the dimension of the problem \citep{NW}.  As a rule 
of thumb, we think using our 
algorithm for $d$ steps before switching seems reasonable.
 


\chapter{Examples} \label{S:Examples}
\section{Example: logistic regression}
We illustrate the application of our algorithm in the case of a logistic regression 
with a starting point far from the 
solution.  In such a case, the Hessian matrix is often near-singular and algorithms 
such as Newton-Raphson which rely 
on it will fail.  For classical SA with step size $1/k$, the magnitudes of the updates 
diminishes too quickly for 
the parameter estimates to approach the MLE in a reasonable amount of time.

The response vector $Y$ has components that are Bernoulli trials with mean vector $p$.  
The natural parameter is $
\theta_i = \log \left( \frac{p_i}{1-p_i} \right )$, which is modeled componentwise as 
a linear function of the 
predictors $1, x_1, \ldots, x_{q}$, so that
\begin{align*}
	\theta_i &= \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \cdots + \beta_{q} x_{q
\,i} = \beta^T x_i \qquad
i = 1, \ldots, n
\end{align*}
where $\beta = (\beta_0, \ldots, \beta_{q} )^T$ and $x_i = ( 1, x_{1i}, \ldots, x_{q 
i})^T$.  

Defining the model matrix $M$ to be the $n \times (q+1)$ matrix with the $x_i$ as 
rows, we can express $\theta = M \beta
$.  This in turn allows us to reparameterize the exponential family  as one with $
\beta$ as the natural parameter 
vector and $M^T y$ the vector of statistics with log likelihood
\begin{align*}
		 \ell(\beta) &=  \beta^T (M^T y) - c(\beta),
\end{align*}
where $y$ is the vector of observed Bernoulli responses.
By \eqref{E:nabla ell}, the gradient is
\begin{align*}
	\nabla \ell( \beta ) &=  M^T y - \E_{\beta}(M^T Y) = M^T( y - \E_{\beta}(Y) ),
\end{align*}
where $\E_{\beta}(Y) = \frac{1}{1 + \exp(-M \beta)}$ can be calculated exactly.  This 
allows us to directly apply 
Theorem~\ref{Thm:Line Search works}.

Suppose we specify our true parameter value to be $\beta = (0, 2, 2, 1, 1, 0, 0, 0)^T$ 
and use 100 independent draws 
from a correlated multivariate normal distribution centered at 0 as our predictors to 
generate 100 independent 
Bernoulli trials.  
Fitting these data using the R function \texttt{glm}, we find the MLE of $\beta$ to be
\begin{align*}
	\betaMLE = (  0.635,  5.949, 1.273, 0.180, 1.006, 1.536, -2.252, -0.472 )^T,
\end{align*}
where the disparity to the true value of $\beta$ results from a relatively small 
sample size of $n=100$.
We use $\beta_0 = ( 5, 4, 3, 2, 1, 0, -1, -2)^T$ for the starting point for our line 
search algorithm, a point for 
which Newton-Raphson fails due to a nearly singular Hessian matrix.  

We measure the performance of our algorithm in terms of the total number of iterations 
used, where each iteration 
requires the evaluation of the gradient, $\nabla \ell( \beta_k + \alpha_k p_k )$.  
Typically, several iterations take 
place in an inner loop to find a step size $\alpha_k$ that meets the curvature 
condition \eqref{E:curvature mod}, a 
process that grows increasingly difficult as the estimates near the MLE since the 
rightmost term in \eqref{E:curvature 
mod} gets smaller in magnitude.  Once an acceptable step size is found, the parameter 
estimate $\beta_k$ is updated and 
a new search direction is determined, requiring another evaluation of the gradient.

Our algorithm took 54 iterations over 20 different search directions to get $\lVert 
\nabla \ell( \beta_k ) \rVert < 
0.01$ and arrive at an estimate for the MLE that differs from the \texttt{glm} result 
by 0.0117 in Euclidean distance 
(See Table~\ref{Table:Logistic}).  
Using the Polak-Ribi\`{e}re conjugate gradient method described in the previous 
section  resulted in comparably sharp 
MLE estimates (see Table~\ref{Table:Logistic}) in fewer iterations---28 over 11 search 
directions---a noticeable 
improvement. 

We also applied  SA with step size $1/k$ (setting $A=1$, $B=0$ in \eqref{E:SA step 
size}) from the same starting point 
$\beta_0$.  The choice of constants $A$ and $B$ in the step size is of course not 
likely to be optimal;
however, we want to apply SA without trial and error experimentation.  
After 10,000 iterations, the parameter estimates look nothing at all like the MLE (See 
Table~\ref{Table:Logistic}).  
The starting point $\beta_0$ is so far from the MLE and the step sizes so small that 
the algorithm does not converge in a reasonable amount of time.
Table~\ref{Table:step size} shows the first 20 step sizes used by SA and our line 
search. Our line search continues to 
use step sizes of relatively large magnitude even well into the process.  It should be 
noted that these 20 step sizes 
correspond to the first 20 iterations of SA but all 54 iterations of our line search 
algorithm since it spends several 
iterations finding an acceptable step size for each update.


% latex table generated in R 2.10.1 by xtable 1.5-6 package
% Tue May  4 17:37:01 2010
\begin{table}
\caption{Comparison of MLEs of $\beta$ for Example 1: MLE = \texttt{glm}, Steep = line 
search using steepest ascent, 
CG = line search using conjugate gradient, and SA =  SA with step size = $1/k$, 
terminated at 10,000 iterations,
$n$ = number of iterations.  Our 
proposed algorithm arrives at nearly identical MLE estimates to \texttt{glm}.}
\begin{center}
\begin{tabular}{rrrrrrrrrr}
  \hline
 & $n$ & $\beta[1]$ & $\beta[2]$ & $\beta[3]$ & $\beta[4]$ & $\beta[5]$ & $\beta[6]$ & 
$\beta[7]$ & $\beta[8]$ \\ 
True $\beta$ & & 0.000 & 2.000 & 2.000 & 1.000 & 1.000 & 0.000 & 0.000 & 0.000 \\ 
  $\hat{\beta}_{\textrm{MLE}}$ & & 0.635 & 5.949 & 1.273 & 0.180 & 1.006 & 1.536 & 
$-2.252$ & $-0.472$ \\ 
  $\hat{\beta}_{\textrm{Steep}}$ & 54 & 0.633 & 5.938 & 1.272 & 0.181 & 1.005 & 1.535 
& $-2.249$ & $-0.470$ \\ 
  $\hat{\beta}_{\textrm{CG}}$ & 28 & 0.631 & 5.936 & 1.272 & 0.181 & 1.003 & 1.532 & 
$-2.244$ & $-0.470$ \\    
  $\hat{\beta}_{\textrm{SA}}$ & $10^4$ & 1.280 & 10.619 & 5.588 & 4.005 & 2.478 & 
$-7.153$ & 1.255 & 0.264 \\ 
  \hline
\end{tabular}
\end{center}
\label{Table:Logistic}
\end{table}

\begin{table}
\caption{The first 20 step sizes used by  SA (with step size $1/k$) and our algorithm 
for Example 1.  The step sizes 
used by our algorithm do not diminish like $1/k$.
}
\begin{center}
\begin{tabular}{rrrrrrrrr}
  \hline
  $k$ & $\alpha_{\textrm{SA}} = 1/k$  & $\alpha_{\textrm{Steep}}$ & $\alpha_{\textrm
{CG}}$ \\ 
  \hline
1	&	1.000	&	0.192	&	0.192	\\
2	&	0.500	&	0.319	&	0.319	\\
3	&	0.333	&	0.403	&	0.416	\\
4	&	0.250	&	0.353	&	0.561	\\
5	&	0.200	&	0.380	&	0.491	\\
6	&	0.167	&	0.333	&	1.092	\\
7	&	0.143	&	0.420	&	0.359	\\
8	&	0.125	&	0.307	&	0.314	\\
9	&	0.111	&	0.442	&	0.275	\\
10	&	0.100	&	0.283	&	0.318	\\
11	&	0.091	&	0.483	&	0.278	\\
12	&	0.083	&	0.241	&	-	\\
13	&	0.077	&	0.745	&	-	\\
14	&	0.071	&	0.203	&	-	\\
15	&	0.067	&	1.224	&	-	\\
16	&	0.063	&	0.173	&	-	\\
17	&	0.059	&	2.510	&	-	\\
18	&	0.056	&	0.195	&	-	\\
19	&	0.053	&	0.944	&	-	\\
20	&	0.050	&	0.173	&	-	\\
  \hline
\end{tabular}
\end{center}
\label{Table:step size}
\end{table}



\section{Example: Ising model} \label{S:Examples:Ising}
In this example, we apply our gradient-based line search algorithm to an Ising model 
\citep{Ising} on a toroidal square 
lattice.  Ising models are exponential families where each entry in the square lattice 
takes the value of either zero 
or one.  A realized sample is shown in Figure~\ref{F:pottsimage}.  The sufficient 
statistic vector is two-dimensional, 
comprising the number of entries with value one and the number of ``neighbor'' entries 
with the same value.  Entries are 
considered ``neighbors'' if they are adjacent to one another horizontally or 
vertically (but not diagonally).  

Here we describe the toroidal square lattice as an $n \times n$ matrix $Y$ and each 
entry as $Y_{ij}$, where $i$ and $j
$ take values in $1, \ldots, n$ considered as a cyclical set (addition is done modulo 
$n$).  The sufficient statistic, 
$g(y)$, has components:
\begin{align*}
	g_1(y) &= \sum_{i=1}^n \sum_{j=1}^n I(Y_{ij}=1), \\
	g_2(y) &= \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n 
				\bigl[ I(Y_{ij}=Y_{i-1,j}) + I(Y_{ij}=Y_{i,j-1}) \\
							&\qquad \qquad \qquad + I(Y_{ij}=Y_{i+1,j}) + I(Y_{ij}=Y_
{i,j+1}) \bigr ]
				,
\end{align*}  
where $I(\cdot)$ denotes the indicator function taking logical expressions to the 
numbers zero and one, false 
expressions to zero and true expressions to one.  

Because of the interdependence of neighboring entries in the lattice, there is no 
closed form expressing $\nabla \ell
( \eta)$ as in the logistic example.  Instead, we need to approximate $\nabla \ell
( \eta)$ using MCMC as described by 
\eqref{E:nabla ell approx}.  As discussed in Section~\ref{section:MCMC approx}, 
Theorem~\ref{Thm:Line Search works} 
cannot be applied directly, but as we demonstrate here, satisfactory estimates are 
still attained.  The MCMC draws are 
performed here using the Swendsen-Wang algorithm \citep{Swendsen-Wang:1987,Swendsen-
Wang:1990}, available in the contributed R 
package \texttt{potts} \citep{Geyer:potts}.

We choose $\eta = \left(0, \log(1 + \sqrt{2} ) \right)^T$ to generate a $32 \times 32$ 
lattice, which we will use as 
our observed data (Figure~\ref{F:pottsimage}).  This value for $\eta$ is of particular 
interest because it corresponds 
to the phase transition point \citep{Potts} and has been shown to be difficult to 
estimate \citep{Geyer:1990}.  In 
order to get a good estimate of the MLE to which we can compare our algorithm's 
results, we use Newton-Raphson starting 
at the true value of $\eta$ so that it will converge.

%%%% 1/25/11 - added Newton
The Newton-Raphson update for optimization is
\begin{align*}
	\eta_{k+1} = \eta_k + \left [  \nabla^2 \ell (\eta_k) \right ]^{-1} \nabla 
\ell (\eta_k).
\end{align*}

When $\eta_k$ is sufficiently close to the MLE, it has been shown to converge 
quadratically (super-quadratically?)  Citation?.  
Our benchmark MLE is computed using the Newton-Raphson for 10 iterations, starting at 
the true value of $
\eta$.  By iterating 10 times, we 
know that the error of the attained estimated for the MLE will be \textbf{SMALL}.

%%%%%%%%


We apply our line search algorithm to this data using an arbitrary initial value of $
\eta^{(0)} = ( 2, 0.001)$ and a 
fixed MCMC sample size of 10,000.  Our algorithm used 62 iterations (gradient 
evaluations) over 17 search directions to 
get  $\lVert \nabla \ell( \eta_k ) \rVert < 0.005$ and arrive at an estimate of the 
MLE that differs from Newton-Raphson
by 0.0037 (see Table~\ref{Table:Potts}).   Using the Polak-Ribi\`{e}re conjugate 
gradient method resulted in 
comparably sharp MLE estimates using 45 iterations over 7 search directions.  The 
total MCMC sample sizes used were $62\times10,0000 = 620,000$ and $45\times10,0000 = 
450,000$, respectively.

%> cat( "Total iterations:",i.total, "\n")
%Total iterations: 62 
%> cat( "Outer iterations:",i, "\n")
%Outer iterations: 18 
%> cat( "Inner iterations:",i.total - i, "\n")
%Inner iterations: 44 



\begin{table}
\caption{Comparison of MLEs for $\eta$ for Example 2: MLE = Newton-Raphson starting 
from the true $\eta$, Steep = 
line search using steepest ascent, CG = line search using conjugate gradient, and SA = 
SA with step size = $1/k$.  All 
algorithms converged.}
\begin{center}
\begin{tabular}{rrrrrrlrr}
  \hline
%    &  &  &  & \multicolumn{1}{c}{inner}\\
  \multicolumn{1}{c}{} & 
  \multicolumn{1}{c}{MC Samples} &
  \multicolumn{1}{c}{$\eta[1]$} &
  \multicolumn{1}{c}{$\eta[2]$} \\
%  & \multicolumn{1}{c}{loop }\\
    &  \multicolumn{1}{c}{(thousands)} &  &  & \\
  \hline
True $\eta$  & & 0.000 & 0.881 \\ 
  $\hat{\eta}_{\textrm{MLE}}$ & & $-0.007$ & 0.896 \\ 
  $\hat{\eta}_{\textrm{Steep}}$ & 620 & $-0.011$ & 0.895 \\ 
  $\hat{\eta}_{\textrm{CG}}$ & 450 & $-0.008$ & 0.895 \\ 
  $\hat{\eta}_{\textrm{SA}}$ & 1368 & $-0.010$ & 0.895 \\ 
   \hline
\end{tabular}
\end{center}
\label{Table:Potts}
\end{table}

We also applied SA, again with step size $1/k$ from the same starting point $\eta^
{(0)}$, and used
a MCMC sample size of 1,000 for gradient calculation.  
Here SA converged in 1368 iterations or 1,368,000 MC samples, comparable to our 
algorithm (see Table~\ref{Table:Potts}).  Table~\ref{Table:Potts step 
size} shows the first 17 step sizes used by SA and our line search.  The step sizes 
used by our line search are 
initially very small compared to $1/k$, but stay in a range of about $1/300$ to 
$1/3000$.  So, the $1/k$ step size used 
by SA in fact occasionally satisfies our curvature condition when $k$ is large. 

\begin{table}
\caption{The first 17 step sizes used by SA (with step size $1/k$) and our algorithm 
for Example 2.  The step sizes 
used by our algorithm are initially much smaller than $1/k$.}
\begin{center}
\begin{tabular}{rrrrrrrrr}
  \hline
  $k$ & $\alpha_{\textrm{SA}} =1/k$  & $\alpha_{\textrm{Steep}}$ & $\alpha_{\textrm
{CG}}$ \\ 
  \hline
1	&	1.0000	&	0.0029	&	0.0029	\\
2	&	0.5000	&	0.0005	&	0.0005	\\
3	&	0.3333	&	0.0017	&	0.0017	\\
4	&	0.2500	&	0.0013	&	0.0045	\\
5	&	0.2000	&	0.0017	&	0.0007	\\
6	&	0.1667	&	0.0011	&	0.0002	\\
7	&	0.1429	&	0.0021	&	0.0015	\\
8	&	0.1250	&	0.0009	&		\\
9	&	0.1111	&	0.0020	&		\\
10	&	0.1000	&	0.0007	&		\\
11	&	0.0909	&	0.0018	&		\\
12	&	0.0833	&	0.0006	&		\\
13	&	0.0769	&	0.0013	&		\\
14	&	0.0714	&	0.0006	&		\\
15	&	0.0667	&	0.0007	&		\\
16	&	0.0625	&	0.0003	&		\\
17	&	0.0588	&	0.0013	&		\\
  \hline
\end{tabular}
\end{center}
\label{Table:Potts step size}
\end{table}

\subsection{MLE distribution for Potts models}

\citet{Composite} explored a generalization of the pseudo-likelihood approach called 
\textit{composite likelihood} and applied to Potts models; a side note result of their 
analysis is that the MLE distribution is in fact skewed and biased.  This can be 
ascertained directly through the use of MCMCMLE, the advantage of the MCMCMLE 
algorithm here is that we can in fact re-use the same 
MCMC samples.  

If we want to use 100 different observed data sets to estimate our MLE 
distribution (that is, we will approximate MLEs for each of the 100 data sets), and 
we will first need to generate 100 different observed samples.  Then, for each sample 
we will want to MCMC sampling to maximize the log-likelihood ratio, $r( \theta, 
\theta_0)$.  The beauty here is that in fact we can generate MCMC samples only once 
(for a reasonable large size, say 100,000) and then use these to approximate the log-
likelihood ratio.

We applied the Newton algorithm and MCMCMLE (well, Charlie did) to a $32 \times 32$ 
4-color Potts model.  To our surprise, the MLE distribution appeared to be skewed and 
biased:
\begin{align*}
%\theta_{MLE} = (0.004626115, 0.003245121, -0.001108131, 1.06203 )^T
\theta_{MLE} = (0.00463, 0.00325, -0.00111, 1.062 )^T
\end{align*}
with a standard deviation of 0.028 for $\theta_*$ (the sample standard deviation of 
the 455 $\theta$ values we calculated).

So, the mean of the MLEs we calculate is significantly lower than the true value of 
1.098.


%\section{Example: Social Network}
%Use the new \texttt{simulate.formula()} from \texttt{statnet}.
%In this example, we apply our algorithm to a simple social network model for which 
%MCMC-MLE has been shown 
%Social networks are typically modeled as a random network represented by a matrix $X
%$, an $n \times n$ matrix where $n
%$ is the number of actors.
%Each entry $X_{ij}$ in the random matrix $X$ is a random variable representing a 
%relation from actor $i$ to actor $j$, 
%such that:
%\[
%	X_{ij} = 
%	\begin{cases}
%		1 & \text{if a relationship exists \textit{from} actor $i$ \textit{to} actor 
%$j$ (notation: $i \to j$)}\\
%		0 & \text{otherwise}
%	\end{cases}
%	\
%\]
%where $i$ and $j$ take values in $1, \ldots, n$, $i \neq j$, for a network with $n$ actors.  
%Note that $X_{ij}$ take only values of $0$ or $1$, reflecting our restriction on networks to those 
%with dichotomous relations, that is, the relation between a pair of actors is either present or absent.  
%In addition, we do not allow the possibility of $i \to i$ and always denote $X_{ii} = 0$.  
%In the special case that $X_{ij} = X_{ji}$ and thus the matrix $X$ is symmetric, the network is referred to as a 
%\textit{undirected} network or graph.  A network is \textit{directed} if it is not undirected.  
%   1: -0.666     NA 16.520  0.241  0.126   0.012 2288.79100 3770.25800     8.0
%   2: -0.888     NA  1.270  0.019  0.079   0.013   12.88560   54.58208     2.0
%   3: -0.904     NA  1.480  0.003  0.160   0.013    0.06350    0.32258    10.0
%> 
%> # summary
%> cat( "Precision:",cutoff.len, "\n")
%Precision: 0.01 
%> theta.frame <- data.frame( theta.MLE, theta.current )
%> theta.frame
%       theta.MLE theta.current
%edges -0.9071582    -0.9040951
%> cat( "Total iterations:",i.total, "\n")
%Total iterations: 24 
%> cat( "Outer iterations:",i, "\n")
%Outer iterations: 4 
%> cat( "Inner iterations:",i.total - i, "\n")
%Inner iterations: 20 




\section{Example: 9-node network}
Like \citet{Handcock:degeneracy, Rinaldo:2009}, we focus on small networks (9 nodes or 
fewer) with only two or three network statistics.  This is because the number of 
different possible graphs can be enormous---even for an undirected 9-node network, 
there are $2^{{9\choose 2}}$, or about 68 billion different graphs.  Calculating exact 
probabilities requires summations over all graphs, a computation that is possible 
still for 9-node network, but becomes prohibitively expensive as the number of nodes 
increases.  

The choice of possible network statistics in a network model is broad and evolving; 
\citet{introp*,recentp*} describe some of the recent work in this area.  Here, for 
comparison purposes to \citet{Rinaldo:2009}, we focus first on a model with the number 
of edges and triangles as the natural statistics.  A two-dimensional statistic 
naturally lends itself to more easily interpretable figures.  We also use a model with 
a three-dimensional statistic comprising edges, triangles, and two-stars to get a 
greater variety of empirical faces and normal cones.

We do take liberty with two short cuts in our examples to make our analysis cleaner:
\begin{enumerate}
\item We use a perfect Monte Carlo sampler to generate our draws \\
$g(Y_1), \ldots, g(Y_m)$ from the distribution with parameter $\eta$, rather than a 
MCMC sampler. \\
 Although we have replicated the results of the algorithm using the MCMC sampler 
provided in the R package \texttt{ergm} \citep{ergm:R}, we wish to identify here what 
issues would still be present even with a perfect MC sampler, which can be used in 
this small network since the likelihood function can be evaluated.  Improving MCMC 
sampling for ERGMs is an open area of research (SOURCE?); we do not concern ourselves 
with this issue here.

\item In the search for the step length $\alpha_k$ that satisfied the curvature 
condition \eqref{E:curvature}, we solve for the value that sets $\nabla \ell( \eta_k + 
\alpha_k p_k)^T p_k = 0$ using a simple root-finding algorithm.  That is, for a given 
direction $p_k$, we find the step size that maximizes the log likelihood in that 
direction.\\
Ordinarily, a more cumbersome numerical approach is necessary.  
However, here again we use our ability to evaluate the likelihood and thus calculate $
\nabla \ell(\cdot)$ exactly rather than approximate it.  We do not, however, use this 
in other steps of the algorithm that require $\nabla \ell(\cdot)$, such as choosing 
search directions \eqref{E:nabla ell approx}.  

\end{enumerate}
We believe that neither of these undermine the validity of the overall algorithm, 
though they undoubtedly simplify and speed up the process for our examples.

We now return to the examples from Section~\ref{S:Example}.  We describe the relevant 
R functions, which unless otherwise noted are in the \texttt{rcdd} package \citep{rcdd:R}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Exact calculation of normalizing constant}

%%%%% 1/26/11
\subsection{Some Basics}
Why these choices of graphs?  9 nodes is not many at all!

For an undirected graph with $n$-nodes, there are $n \choose 2$ dyads.  For each dyad, 
an edge may be present or absent, so there are $2^{n \choose 2}$ possible graphs to 
consider.\\

\begin{table}[ht]
\caption{Combinatorics for undirected graphs}
\begin{tabular}{ccl}
\hline 
Nodes & Possible Edges & Total Graphs \\ [1ex]
\hline
5 & ${5 \choose 2} = 10$ & $2^{10} = 1024$ \\ [1ex]
6 & ${6 \choose 2} = 15$ & $2^{15} = 32,768$ \\ [1ex]
7 & ${7 \choose 2} = 21$ & $2^{21} = 2,097,152$ \\ [1ex]
8 & ${8 \choose 2} = 28$ & $2^{28} = 268,435,456$ \\ [1ex]
9 & ${9 \choose 2} = 36$ & $2^{36} = 68,719,476,736$ \\ [1ex]
\hline 
\end{tabular}
\end{table}
%%%%%%
So, while a 5-node graph seems manageable, a 9-node graph is already getting difficult 
to handle.  For example, \texttt{as.integer(2\textasciicircum31)} returns \texttt{NA}.  
\textbf{Going forward, we work with the 9-node edge-triangle model}.


For the examples we consider, the sum in \eqref{E:cumulant} can in fact be explicitly 
evaluated.  The sample space of graphs $\YY$ has $2^{36}$, or about 68 billion, sample 
points.  However, we only need to consider the points in the sufficient statistics 
space, $\TT = g(\YY)$, which in the case of the edge-triangle model used for the 9-
node network only has 444 points.  That is,
\begin{align*}
	e^{c(\eta)} = \sum_{y \in \YY} e^{\inner{g(y),\eta} } = 	\sum_{t \in \TT} e^{\inner{t,\eta} } \nu(t)
\end{align*}
where $\nu(t)$ is the frequency of the network statistic $t$ across all $y \in \YY$.  
(This does require $\nu(t)$ to be calculated for all $t \in \TT$, a somewhat expensive 
computation.  However, this calculation need be done only once per model with the 
results saved to file.)

Thus we can evaluate the density function \eqref{E:pdf} and calculate exactly 
probabilities.  In particular, we can calculate exact values for the gradient \eqref
{E:nabla ell},
\begin{align*}
	\nabla \ell (\eta) &= g(\yobs) - \E_\eta g(Y) \\
					  &= g(\yobs) - \sum_{t \in \TT} t P_\eta(T = t) \nu(t).
\end{align*}
WHAT IS $T$?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Convex hull}
Finding the convex hull from a set of points is of course a well-studied problem.  We 
mention it here to describe the sequence of functions we use to find the convex hull.  
Beginning with a large number of MC sample points, say 10,000, we first use the 
\texttt{unique} function in the \texttt{base} package in R to reduce to the distinct 
points in the set.  Then we apply the \texttt{redundant} function in the \texttt{rcdd} 
package to reduce to a linearly independent set, which corresponds to the V-
representation of the convex hull.

Our algorithm utilizes the H-representation of the sample points to determine if $g(\yobs)$ lies on the 
exterior, boundary, or interior of the convex hull of a set of points.  
This requires switching back and forth between the V-representation and 
the H-representation.  
This functionality is provided by the \texttt{scdd} function, which takes as an 
argument the original representation (H or V) and returns the toggled representation.

Either representation can be expressed with rational arithmetic, making equality 
comparisons exact.  This is particularly important when trying to determine the 
location of $g(\yobs)$ relative to the convex hull of a set of points.  The \texttt
{rcdd} package also provides the necessary matrix arithmetic functions to work with 
the rational representation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Two-dimensional sufficient statistic}\label{S:example 2dim}
\begin{figure}[!ht]
\centering
\includegraphics[height=4in,width=4in]{Figures/g9-hull}
\caption{The sample space of the edge and triangle network statistics for the 9-node 
network described in 
Section \ref{S:example 2dim}.  The shading of a point corresponds to the frequency of 
graphs with that network statistic.  
The convex hull of all points is the gray, sail-shaped polytope.  Points on the 
boundary have an 
outlined circle and extreme points are square.}
\label{F:g9-hull}
\end{figure}

The support for the 9-node ERGM with edge and triangle network statistics is depicted 
in Figure \ref{F:g9-hull}.
The MLE for an exponential family model will exist if and only if the observed 
statistic lies in the interior of the convex support $C$, which is the sail-shaped 
polytope in Figure \ref{F:g9-hull}.  For all discrete exponential family models 
including this one, the convex support is polyhedral.  Here, $C$ has six sides and six 
vertices.

\subsubsection{Case: MLE exists}
If the observed data has 29 edges and 47 triangles (or network statistic $(29,47)$), 
and lies in the interior of the convex support as depicted in Figure \ref{F:MC cloud} 
(top), the MLE exists.  
Our algorithm, arbitrarily starting at the natural parameter value of $\eta = (0,0)$, 
generates Monte Carlo samples from the model with this initial parameter value.  As 
the algorithm scales the log likelihood, the cloud of sample points will move towards 
the observed statistic and eventually engulf it.  
When the value for $\eta$ is equal to the MLE, the mean of the MC sample points will 
equal $(29,47)$(see Figure \ref{F:MC cloud} (bottom)).  
\begin{figure}[!ht]
\centering
\includegraphics[height=2.8in,width=2.8in]{Figures/MCsample-far}
\includegraphics[height=2.8in,width=2.8in]{Figures/MCsample-MLE}
\caption{The network statistics for 10,000 Monte Carlo samples generated from models 
with the natural parameter $\eta$ set to $(0,0)$ (top) and the MLE, $(-0.389, 0.418)$ 
(bottom).  The observed data has network statistics of $(29,47)$, depicted by the 
larger point with white outline.  When $\eta$ is the MLE, the observed statistic is 
exactly the mean of the MC sample points generated from the model with this parameter 
value. }
\label{F:MC cloud}
% (-0.3890151, 0.4177752)
\end{figure}
For this problem, the MLE for $\eta$ is found to be
\begin{align*}
\etaMLE = (-0.389, 0.418).
\end{align*}

\subsubsection{Case: MLE does not exist; observed statistic on one-dimensional face}
If the observed data has network statistic $(31,50)$ and lies on the 
boundary of the convex support as depicted in Figure \ref{F:MC face}, the MLE does not 
exist.  To be precise, the observed network statistic $(31,50)$ lies on the interior 
of a line segment on the boundary with end points $(30,44)$ and $(32,56)$. 
Our algorithm begins as before, generating MCsample point clouds to explore the 
sample space, as depicted in Figure \ref{F:MC face}.  Because the sail-shaped convex 
support is not known, the algorithm cannot determine at the outset  that the MLE does 
not exist; it can only generate more sample point clouds as it climbs the log 
likelihood surface, with successive clouds moving towards the observed statistic.
Eventually, the observed statistic will lie exactly on the boundary of a sample cloud.  
When this occurs, the algorithm must 
\begin{enumerate}
\item determine empirically the face, $F$, on which the observed statistic lies in the 
relative interior of,
\item decide if $F$ is in fact the boundary of the convex support $C$.
\end{enumerate}  

The first task can be done using the linear programming functions provided to us in 
the \texttt{rcdd} package.  The second task turns out to be very difficult to do.  
For now, we assume that if a substantial portion of the sample points generated, say 
60\%, land on this empirically determined face $F$, then it is in fact a boundary of 
the convex support $C$.  


In this example, the algorithm has determined empirically that $(30,44)$, $(31,50)$, 
and $(32,56)$ lie on a one-dimensional face, as depicted in Figure \ref{F:MC face} 
(bottom).  If less than 60\% of the sample points land on this empirical face, the 
algorithm continues to sample, trying to get a sample point cloud even closer to the 
observed statistic.  We choose such a high proportion for a cut off to eliminate---or 
at least, greatly reduce---the possibility of misidentifying a boundary.
(We deal later with a case where 100\% of the MC sample points form a face which is 
\emph{not} on the boundary of $C$.)
\begin{figure}[!ht]
\centering
\includegraphics[height=2.7in,width=2.7in]{Figures/MCsample-boundary}
\includegraphics[height=2.7in,width=2.7in]{Figures/MCsample-77face}
\caption{The network statistics for 10,000 Monte Carlo samples for the model with 
observed network statistic $(31,50)$, depicted by the larger point with white 
outline, lying on the boundary of the convex support (top).
In the bottom figure, the algorithm has identified a face defined by $(30,44)$, 
$(31,50)$, and $(32,56)$, marked by triangles in the figure (the triangle for 
$(31,50)$ is not visible since it is the observed statistic).  
Here, 77\% of the MC sample points fall on these three points.  The 
lighter colored polytope is the convex hull of all previously sampled points.
}
\label{F:MC face}
\end{figure}

By identifying the empirical face $F$ on whose interior the observed statistic lies, 
the algorithm has not only concluded that the MLE does not exist in the conventional 
sense, it has also defined $F$ as the convex support for the new limiting conditional 
model, which is also an exponential family.  

The algorithm proceeds to maximize this new exponential family using the same 
iterative approach as before.  The gradient of the LCM log likelihood is approximated 
using \eqref{E:nabla ell approx LCM},
\begin{align*}
	\nabla \ell( \eta )^{LCM} \approx g(\yobs) - \frac{1}{k} \sum_{i=1}^k g(Y_{(k)})
\end{align*}
where $g(Y_{(1)}), \ldots, g(Y_{(k)})$ is the subsample of the MC sample points 
restricted to the empirical face: $(30,44)$, $(31,50)$, and $(32,56)$ in this case.  
The maximizer of this log likelihood, $\etaLCM$, is found to be
\begin{align*}
\etaLCM = (120.9, -20.1).
%(120.91090 -20.12784)
\end{align*}
The LCM, however, is not identifiable, since the support is now only one-dimensional 
compared to two in the original model (EXPLAIN BETTER).  
That is, there must exist a constancy space of this new model, $\Gammalim$, such that 
\begin{align} \label{E:Gammalim}
\ell( \eta + \gamma )^{LCM} = \ell( \eta )^{LCM}
\end{align}
for any $\gamma \in \Gammalim$.

The empirical face $F$ and the observed statistic also define a normal direction, 
\begin{align*}
	\delta = (6,-1),
\end{align*}
which is called a generic direction of recession (GDOR).  Exponential family theory 
states that the log likelihood is a strictly concave function of $\eta$.  For a 
maximizer to exist then, there must be a direction along which the log likelihood 
function increases to $+\infty$.  This direction is exactly the $\delta$ found above, 
and combined with a specific point in the natural parameter space, $\etaLCM$, 
\begin{align} \label{E:GDOR lim}
	\lim_{s \to +\infty} \ell( \etaLCM + s \delta) = \sup_{\eta} \ell(\eta),
\end{align}
where  $\ell(\cdot)$ is the log likelihood of our original model.

The GDOR, $\delta$, of the original model is also a direction of constancy the new 
model.  
Then by \eqref{E:Gammalim} and \eqref{E:GDOR lim}, note that $\ell(\etaLCM + \gamma + 
s \delta)$ goes off to $+\infty$ as $s$ increases.  
In order to construct a one-sided confidence intervals, we need to find the value of 
$s$ for which the probability that the distribution allocates to the event that a 
sample falls on the face of interest is 5\%, that is,
\begin{align*}
P_{\etaLCM + \gamma + s \delta}(g(Y) \in F ) = 0.05.
\end{align*}
Although we cannot evaluate the probability function above, we can generate MC samples 
of $g(Y_1), \ldots, g(Y_m)$ from the distribution with parameter $\etaLCM + \gamma + s 
\delta$ and see for what value of $s$, 5\% of the sample lies in the empirical face we 
found.  

Some numerical work shows that for $\eta = (9.19, -1.51)$, we get 5\% of the MC sample 
on this face.  Or, in terms of non-simultaneous 95\% confidence intervals for the 
components of $\eta$,
\begin{align*}
	[9.19, +\infty)\\
	(-\infty, -1.51],
\end{align*}
where the direction of the interval for the second component is flipped because the 
second component of $\delta$ is negative.

\textbf{Mean value parameters? Are they any more interpretable here?  nice pictures}

%Because our sample space for graphs is still manageable at 68 billion points, we can 
%in fact use numerical optimization methods like trust (CITE?) on the original log 
%likelihood, passing in first and second derivative functions.  Depending on the 
%settings for tolerance, we can get a trust routine to return to what it thinks is an 
%MLE,  
%\begin{align*}
% 	\hat{\eta}_{\textrm{trust}} = (135.6, -22.6),
% \end{align*}
%which are well within our confidence intervals.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Case: MLE does not exist; observed statistic on zero-dimensional face}
If the observed data has network statistic $(27, 27)$, the point is an extreme point 
of the convex support $C$ (it is a square point on the boundary of the sail in Figure~
\ref{F:g9-hull}) and the MLE does not exist.  In this case, the point itself is the 
face with zero-dimension.  The algorithm proceeds as before, and concludes that the 
point $(27,27)$ is the empirical face $F$ and on the boundary of the hull.
In this case, the limiting conditioning model is completely unidentifiable, and thus 
any value for $\eta$ will be a maximizer.  Our particular implementation found that
\begin{align*}
	\etaLCM = (94.0, -20.4 ).
\end{align*}
The normal cone to the observed statistic in this case is two-dimensional, bounded by 
two vectors,
\begin{align*}
	 \{ (3.857,   -1),	(5.667,   -1) \}.
\end{align*}
If we choose the average of these two vectors, $\delta = (4.76, -1)$, and proceed as 
before, then we find 95\% one-sided confidence intervals for $\eta$ of 
\begin{align*}
%14.495152 -3.703202 
	[14.5, +\infty)\\
	(-\infty, -3.7],
\end{align*}

\textbf{MEAN VALUE PARAMETERS?}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Case: MLE exists but observed statistic is very near boundary}
If the observed data has network statistic $(21, 4)$, it is in fact on the interior of 
the convex support and so the MLE exists.  
The approaches of \citet{Handcock:degeneracy} and \citet{Rinaldo:2009} would have 
noted that from a mean value pararmeter perspective, this observed statistic likely 
corresponds to a degenerate distribution. The Shannon entropy function would show this 
point to have extremely small entropy, corresponding to a model that puts most of its 
probability on very few points.

The log likelihood for this model is extremely flat, causing some disagreement among 
optimization routines for MLE estimates, though log likelihood values are nearly 
identical.  Using a trust optimization routine we calculate that 
\begin{align*}
%$(24.44, ?6.65)$ from optim.
\etaMLE = (28.86, -7.76).
\end{align*}
The most problematic aspect of this model for us here, however, is that our algorithm 
concludes---incorrectly, of course---that the MLE does not exist, and proceeds to 
calculate the MLE of an LCM.

How does this happen?

Our algorithm begins in the same manner as described previously.  As the algorithm 
proceeds uphill on the log likelihood function, it will iterate $\eta_k$ to a value 
(for example, $(35.34, -9.56)$) where all 10,000 MC sample points generated from the 
model with this parameter value fall on the six points on the line segment between 
$(20,0)$ and $(25,5)$, as depicted in Figure~\ref{F:MC problem}.  The observed value $
(21,4)$ is one of these six points.
In order for the algorithm to have correctly identified the boundary here and conclude 
that $(21,4)$ was on the interior, the extreme point $(27,27)$ would need to have 
occurred in the MC sample.  However, for the parameter value that we consider, model 
assigns a probability of 0.000032 to this point.  Even the MLE model only assigns a 
probability of about 0.00045 to this point.  So, the extreme point that is critical 
for fully determining the convex support is in fact assigned very low probability by 
the MLE model.

\begin{figure}[!h]
\centering
%%\includegraphics[height=2.4in,width=2.4in]{Figures/MCsample-problem}
\includegraphics[height=4.5in,width=4.5in]{Figures/MCsample-fakeface}
\caption{An observed statistic at $(21,4)$, in the interior of the convex hull but 
close to the boundary.  It is quite feasible to generate 10,000 MC 
samples where all 10,000 points lie on a line that appear to be a one-dimensional 
face, marked by the 
triangles in the figure above.  The lighter colored polytope is the convex hull of all 
previously 
sampled points used to derive this empirical face.}
\label{F:MC problem}
\end{figure}

According to the algorithm, this line segment is a boundary of the convex support on 
which the observed statistic lies on the interior of, and the MLE does not exist.  It 
proceeds as in the first example, and seeks to find the MLE of the LCM,
\begin{align*}
	\etaLCM = (35.38, -9.39),
\end{align*}
and then calculates one-sided confidence intervals for $\eta$.

On first glance this is very troubling: our algorithm arrives at the wrong conclusion 
about the existence of the MLE, and $(35.38, -9.39)$ does not look particularly close 
to the true MLE of $(28.86, -7.76)$.  However, we believe a step back needs to be 
taken and the goal of the analysis reconsidered.  What was the purpose in finding the 
MLE?  In particular, what does one do with these numbers once they are found?

If the end goal is to try to interpret meaning out of these numbers by their sign and  
magnitude (\textbf{a questionable approach?  or at least dangerous?}), then we indeed 
have a problem---our numbers are just wrong.  However, if the MLE is viewed as an 
index into a specific model that assigns the highest probability to the observed data,
then we claim that the model we have found---the LCM with parameter value $\etaLCM$---
is in fact remarkably similar to the original model indexed by the true MLE.  A 
reasonable metric for this comparison is a sum of the absolute difference in 
probabilities assigned to each point in the sample space,
\begin{align*}
	\sum_{y \in \YY} \abs{ P_{\etaMLE}(g(Y) =g(y) ) -  P_{\etaLCM}(g(Y) = g(y))  }.
\end{align*}
The probabilities assigned by each of these models to the six points on the 
empirically determined face is summarized in Table~\ref{T:LCMvsMLE}.

% latex table generated in R 2.11.1 by xtable 1.5-6 package
% Fri Sep 10 13:22:25 2010
\begin{table}[h!] \label{T:LCMvsMLE}
\begin{center}
\caption{Probabilities assigned by LCM model with parameter value $\etaLCM$ and 
original model with parameter value $\etaMLE$ to six points on empirical face.  The 
observed statistic is $(21,4)$.}

\begin{tabular}{rrrrr}
\\  \hline
 & Edges & Triangles & LCM & MLE \\ 
  \hline
1 & 20 & 0 & 0.3414 & 0.3425 \\ 
  2 & 22 & 8 & 0.2019 & 0.2009 \\ 
  3 & 21 & 4 & 0.3914 & 0.3911 \\ 
  4 & 23 & 12 & 0.0566 & 0.0561 \\ 
  5 & 24 & 16 & 0.0081 & 0.0080 \\ 
  6 & 25 & 20 & 0.0005 & 0.0005 \\ 
   \hline
   &  &  & 1.0000 & 0.9990 \\ 
\end{tabular}
\end{center}
\end{table}

Here, the sum of the absolute value of differences on these empirical points is only 
$0.0031$.  Including the additional 0.001 of probability on points that are outside 
the LCM support, this total still only comes to $0.0041$, a difference that would seem 
insignificant for most applications.  

Of course, there may be practical issues: a researcher may want software to simply 
return MLE values to keep around for later analysis.  Here, we are suggesting the 
analysis return LCM MLE values and an LCM model (perhaps in the form of the convex 
support).  The researcher may understandably be confused, especially if he knew in 
advance that the MLE was guaranteed to exist.  However, any analysis (other than the 
parameter value magnitude study) would still work as before, though perhaps not ``out 
of the box".

It may be of interest to note that $\etaLCM$ and $\etaMLE$ index nearly identical 
models in the LCM, with the difference due almost entirely to the lack of 
identifiability of the LCM.  A normal direction to the empirical face is $\delta = 
(4,-1)$, which is a direction of constancy for the LCM (that is, $\delta \in \Gammalim
$).  Then by \eqref{E:Gammalim}, 
\begin{align*}
	\ell(\etaLCM)^{LCM} &= \ell( \etaLCM + \gamma )^{LCM}\\
				 &= 	\ell(\etaLCM + k \, (4,-1))^{LCM}.
\end{align*}
If we had perfect knowledge and chose $k = -1.63$,
\begin{align*}
	\etaLCM  -1.63 \, (4,-1)= (28.86, -7.76) 
\end{align*}
matching the MLE to the significant figures considered.  Thus in this case, $\etaLCM$ 
and $\etaMLE$ index nearly identical models of the LCM.

If we finished the analysis as before and computed one-sided 95\% confidence intervals 
for $\eta$, we get 
\begin{align*}
%14.495152 -3.703202 
	[20.46, +\infty)\\
	(-\infty, -4.85].
\end{align*}
%20.462923 -4.850603 

%\begin{align*}
%	\hat{\theta}_{MLE} &= (28.85685, -7.75672)\\
%	\hat{\theta}_{LCM} &= (35.3831787, -9.387266),
%\end{align*}

%Well, remember that for LCM's we are looking to construct one-sided CIs.  But here, 
%what happens if we go off to infinity in this supposed direction of recession?  The 
%log-likelihood will eventually dip back down!  So, we can constructed two-sided CI's, 
%I think.  But, my calculations got me something that seems pointlessly wide: 
%\begin{align*}
% (3.503179,  -1.417266 )\\
% (71.22318,  -18.34727 ).
%\end{align*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Three-dimensional sufficient statistic}

In order to increase the complexity of the problem yet still have the ``truth" for 
comparison, we also considered 7-node graph with network statistics edges, two-stars, 
and triangles, a classic model in the literature first suggested by \citet{Frank:
1986}.  Since then it has been criticized for its problematic behavior by \citet
[really? check this]{GOF}, precisely related to the issue of non-existence MLEs (or 
degeneracy???).

The algorithm proceeds in exactly the same way, the difference now being that the 
empirical face may have as many as two dimensions instead of one.  This makes for a 
more interesting variety of constancy spaces for the LCM.  We only consider cases here 
that add a notably different flavor than the two-dimensional case.

\subsubsection{Observed value, $y_{obs}$, is on two-dimensional face}
\subsubsection{Observed value, $y_{obs}$, is on one-dimensional face}
\subsubsection{MLE does not exist; observed statistic on two-dimensional face but not 
fully discoverd}

Set $y_{obs} = (14, 8, 43).$
This point is on the boundary, which is a 2-dim face.

The MC sample, however, does not cover the entire face.  This is a new scenario, but 
it should not be a problem.  Those points on the actual face that are not included are 
simply points of low probability.

Only issue outstanding with this is how long it takes to find the LCM MLE.  Having a 
surprisingly hard time with this.  Question: is it doing any worse than when we 
started with a 2-dim sample space?

\section{Example: \textit{e. coli}}
\section{Example: Faux Magnolia High School}
\citet{advancesp*,statnet-tutorial} utilize a adolescent friendship network data set 
of 1,461 students in grade 7--12 derived from the National Longitudinal Study of 
Adolescent Health.  The data set, which \citeauthor{statnet-tutorial} refer to as Faux 
Magnolia High School, is a model-based simulation from the original data set, where 
the simulation is necessitated to maintain confidentiality.

\chapter{Discussion}
We have presented a simple line search algorithm for finding the MLE of a regular 
exponential family when the MLE 
exists.  The algorithm avoids the trial and error experimentation of tuning parameters 
and starting points commonly associated with optimization routines
not invented by optimization specialists.  Our algorithm is modeled after algorithms 
discussed in optimization textbooks \citep{Fletcher,NW,Sun:2006},
all of which are safeguarded to ensure rapid automatic convergence.
%Because it only relies on first order derivatives, this approach avoids problems with 
%near-singular Fisher information 
%matrices that plague methods like Newton-Raphson.  The reliant on a curvature 
%condition for step size makes it less 
%sensitive to poor initial values that are problematic for MCMC-MLE and  SA in 
practice.

Convergence is guaranteed when the gradient can be calculated exactly.  Even when the 
gradient cannot be calculated 
exactly and is only estimable via MCMC, the algorithm is still useful in practice, as 
demonstrated by the Ising model 
example.  We have also described a way to construct and use confidence intervals to 
make convergence highly probable.

The algorithm can be computationally demanding.  When the current iteration approaches 
the solution, the 
curvature condition for step size becomes more difficult to satisfy and the method may 
require several iterations of 
MCMC sampling and perhaps an increase in MCMC sample size.  Eventual increase in MCMC 
sample size is unavoidable,
because the achievable accuracy is inversely proportional to the square root of the 
MCMC sample size, as in all Monte Carlo.
Thus we believe the best use of this algorithm is in combination with other faster 
methods like MCMC-MLE \citep{Geyer:1992}
or Newton-Raphson safeguarded by our line search algorithm.  Our 
algorithm should be used from ``long range'', when one has no good intuition for an 
initial value and is concerned about 
picking one that is far from the MLE.  The switch between types of search direction 
(steepest ascent, conjugate gradient,
or Newton) within our algorithm or the switch to another algorithm (such as MCMC-MLE 
\citep{Geyer:1992})
need not require manual intervention.  When used in combination in this
manner, we do not think the confidence intervals are necessary as the curvature 
condition is quite easily satisfied 
when the current iteration is far from the MLE.

One way to improve performance is to use conjugate gradient search directions rather 
than steepest ascent.  In our 
examples, this reduced the number of iterations by over 25\%.  However, in other 
problems we tried with different 
dimensionality, this performance varied significantly and it appears that no guarantee 
can be made about quantity of 
improvement in performance, though in all cases we examined, it never did worse.  This 
is no surprise, because the
necessity of ``preconditioning'' for good performance of the conjugate gradient 
algorithm is well known (but no
good ``preconditioner'' is available for maximum likelihood in exponential families).

There are several outstanding issues.  Most notably, we have not showed convergence of 
the algorithm when the gradient 
is approximated via MCMC.  This is a more difficult theoretical problem and is the 
motivation for stochastic 
approximation research.  
Further work is necessary to determine if one can adapt our restrictive curvature 
condition \eqref{E:Wolfe-mod} to the 
approach of \citet{Andrieu:2005} or \citet{Liang:2010} in MCMC stochastic 
approximation.  

Another remaining issue is the stopping criteria: what value should be chosen for $
\epsilon$ in the exit condition
$\lVert  \nabla \ell( \eta_k ) \rVert < \epsilon$?  Because the value of $\lVert  
\nabla \ell( \eta_k ) \rVert$ can only 
be approximated via MCMC, one cannot be certain if this condition is actually 
satisfied.  Here again, the switch to 
another methodology may be appropriate, though at least in our Ising model example, 
our use of 10,000 for the MCMC 
sample size and 0.005 for $\epsilon$ were successful in obtaining a reasonable 
parameter estimate. 

 A final remaining issue is estimation of Monte Carlo error of the estimates.  Here 
too we recommend switching to another
algorithm at the end.  The MCMC-MLE procedure gives accurate error estimates \citep
{Geyer:1994}.
For very small steps these are essentially the same as the Monte Carlo error of a 
single unsafeguarded Newton-Raphson step,
so the method in \citep{Geyer:1994} can be used for either.

%A natural extension of this algorithm is to the case where the MLE may not exist.  
%This occurs with positive probability for discrete state space exponential families and 
%is a practical concern when estimating parameters \citep{Rinaldo:2009, Geyer:gdor}.  
%In such instances, the concave log likelihood continues to increase as $\eta \to \infty$ along 
%certain directions of recession.  Our algorithm can still be applied to such a setting to climb the 
%log likelihood until the gradient approaches zero and help identify the directions of recession. 




% References don't have to be double spaced either
\setstretch{1.3}
\bibliographystyle{ims}
%\bibliographystyle{imsart-nameyear}
\bibliography{References}
%\bibliography{/Users/saipuck/Tako/THESIS/References}


% text in appendices may be single spaced, if desired
\setstretch{1.3} % to 1.3 spacing
\appendix
\chapter{Proofs} \label{Section:Proofs}
Our algorithm minimizes the objective function $f$ by performing repeated one-
dimensional updates.  We need the 
following lemma to transfer global properties of the objective function to the 
objective function restricted to a 
search direction.

%%%%%%%%%%% BEGIN LEMMA %%%%%%%%%%%%%%
\begin{lemma} \label{Lemma:f min} 
Suppose a function $f:\RR^n \to \RR$ is proper, lower semicontinuous, and strictly 
convex.  Then the minimum for $f$ 
exists and is unique if and only if every nonempty level set $\lev_{\leq \alpha} f$ is 
bounded.
\end{lemma}

%%%%%%%%%%% PROOF - LEMMA %%%%%%%%%%%%%%

\begin{proof}[Proof of Lemma~\ref{Lemma:f min}]
Assume every non-empty level set is bounded.  Then by Theorem~1.9 in \citet
{Rockafellar}, the minimum of $f$ is finite 
and thus exists.  By strict convexity, this minimum is also unique.

Now assume the minimum for $f$ exists, denoted by $\min f$.  By assumption, the level 
set $\lev_{\leq \min f} f$ 
contains exactly one point.  By Corollary~8.7.1 in \citet{Rockafellar:1970}, the level 
sets $\lev_{\leq \alpha} f$ are 
bounded for every $\alpha$.  
\end{proof}

%%%%%%%%%%% PROOF - LINE SEARCH %%%%%%%%%%%%%%
\begin{proof}[Proof of Theorem~\ref{Thm:Line Search}]
The objective function $f$ is bounded below, strictly convex, and lower semicontinuous 
by assumption, and so by Lemma~
\ref{Lemma:f min}, the global minimum exists.  Then by Lemma~\ref{Lemma:f min}, all 
level sets of type $\lev_{\leq a} f$, $a \in \RR$ are bounded in $\RR^n$.  Restricting the set to be along a search 
direction $p_k$ maintains the 
boundedness of these sets.  By Lemma~\ref{Lemma:f min} again, the minimum in this 
restriction exists and is unique.     

Then, unless $\nabla f( x_k ) = 0$ in which case $x_k$ is already the solution, for 
each $k$, we can uniquely define $\alpha_{c_k}$ and $\alpha_{min_k}$ as follows: 
\begin{align}
%	\theta_k &= \cos^{-1} \left( \frac{ -\nabla f_k^T p_k }{ ||\nabla f_k|| \, ||
%p_k||} \right) \label{E:cosine} \\
	\nabla f( x_k + \alpha_{c_k} p_k)^T p_k &= c \nabla f(x_k)^T p_k \label{E:alphac} \\
	\nabla f( x_k + \alpha_{min_k} p_k)^T p_k &= 0. \label{E:alphamin} 
\end{align}
The point $\alpha_{c_k}$ is uniquely defined because it is the minimizer of 
$\alpha \mapsto f( x_k + \alpha p_k) - \alpha c \nabla f( x_k )^T p_k$.
These values appear on the $\alpha$-axis in Figure \ref{F:Wolfe-mod}.
%%%%%%%%%%% FIGURE %%%%%%%%%%%%%%
\begin{figure}
\centering
\scalebox{.4}{\input{Figures/Wolfe-mod.pdf_t}}
\caption{The acceptable region for $\alpha$ according to the curvature condition 
\eqref{E:Wolfe-mod} when restricting 
$f$ to direction $p_k$.}
\label{F:Wolfe-mod}
\end{figure}

%These values are illustrated on the $\alpha$-axis in Figure \ref{F:Wolfe-mod}.  
%Equation \eqref{E:alphamin} defines $\alpha_{min_k}$ to be the step size that would make the 
%gradient at $x_{k+1}$ equal to zero and hence minimizes $f(x_{k+1})$, equation \eqref{E:alphac} 
%defines \alpha_{c_k} to be the step size that would make the gradient at $x_{k+1}$ equal to 

By the strict convexity of $f$ and Theorem~2.14 in \citet{Rockafellar}, 
\begin{align}
	f( x_k + \alpha_{c_k} p_k ) &< f(x_k) +  \bigl[ \nabla f(x_k + \alpha_{c_k} p_k) 
\bigr]^T \alpha_{c_k} p_k. \notag 
\\
	\intertext{Applying \eqref{E:alphac} to the right hand side of the above gives}
	f( x_k + \alpha_{c_k} p_k ) &< f(x_k) + \alpha_{c_k} c \nabla f(x_k)^T p_k. \label
{E:b-less-a}
	\end{align}	
(See points $a$ and $b$ in Figure \ref{F:Wolfe-mod}).

The subproblem $\alpha \mapsto f(x_k + \alpha p_k)$ is strictly convex and hence 
monotonically decreasing at $\alpha_k$ 
such that $\alpha_{c_k} \leq \alpha_k \leq \alpha_{min_k}$ (in Figure \ref{F:Wolfe-
mod}, see points $b$ and $c$).  That 
is,
\begin{align}
	f( x_k + \alpha_{min}p_k) &\leq f( x_k + \alpha_k p_k) \leq f( x_k + \alpha_{c_k} 
p_k). \label{E:f-sandwich}
\end{align}
	
Combining the second inequality of \eqref{E:f-sandwich} with \eqref{E:b-less-a}, we 
have	
\begin{align}
	f( x_k + \alpha_k p_k ) &< f(x_k) + \alpha_{c_k} c \nabla f(x_k)^T p_k,  \label
{E:decrease}
	\intertext{which can be rearranged as}
	f(x_k)-f( x_k + \alpha_k p_k ) &>  -\alpha_{c_k} c \nabla f(x_k)^T p_k. \label
{E:f-lb}
\end{align}
This last inequality \eqref{E:f-lb} expresses a lower bound for the amount of decrease 
in our objective function at 
each step (the right-hand side is positive since $\nabla f(x_k)^T p_k < 0$ by 
assumption that $p_k$ is a descent 
direction).  It is this lower bound that we will use to cover the distance to the 
minimum of the objective function.  

We now turn our attention to \eqref{E:alphac}.  Define $x_{c_k} = x_k + \alpha_{c_k} 
p_k$.  Then
\begin{align}
	\nabla f( x_{c_k} )^T p_k &= c \nabla f(x_k)^T p_k. \notag
\end{align}
Subtracting $\nabla f(x_k)^T p_k$ from both sides gives
\begin{align}
	\left( \nabla f( {x_{c_k}} ) - \nabla f(x_k) \right )^T p_k &= ( c - 1 ) \nabla f
(x_k)^T p_k.  \label{E:c-1}
\end{align}

%\textbf{NEW: SAI 12/05/10}\\
%Since we are considering a finite state space for $| \nabla^2 \ell(\eta) | \leq K$ for some constant K for all $\eta$ 
%\textbf{By Theorems 9.2 and 9.7 in \citet{Rockafellar}, since $\nabla^2 f(x)$ is assumed to be finite, 
%$\nabla f(x)$ is Lipschitz continuous relative to the convex set $\RR^n$.}

By Corollary~25.5.1 in \citet{Rockafellar:1970}, since $f$ is convex and 
differentiable on the open convex set $\NN$, 
it is actually continuously differentiable on $\NN$.  It is then Lipschitz 
continuously differentiable relative to any 
compact subset of $\NN$. 

Applying this to the compact level set $\lev_{\leq f(x_k)} f$, which is contained in $
\NN$ by assumption, there exists 
a constant $L < \infty$ such that
	\begin{align}
		|| \nabla f(x) - \nabla f(\tilde{x}) || \leq L || x - \tilde{x} || \quad \text
{for all $x, \tilde{x} \in \lev_
{\leq f(x_0)} f$}. \label{E:Lipschitz}
	\end{align} 

Applying \eqref{E:Lipschitz} to $x_{c_k}$ and $x_k$, we have
\begin{align}
|| \nabla f(x_{c_k}) - \nabla f(x_k) || &\leq L || x_{c_k} - x_k || \notag
\intertext{or}
|| \nabla f(x_{c_k}) - \nabla f(x_k) || &\leq L || \alpha_{c_k} p_k ||. \notag	
\end{align}

Multiplying both sides by $\lVert p_k \rVert$ gives
\begin{align}
|| \nabla f(x_{c_k}) - \nabla f(x_k) || \cdot ||p_k || &\leq \alpha_{c_k} L || p_k ||
^2 \notag \\
\intertext{and by Cauchy-Schwarz this implies}
( \nabla f(x_{c_k}) - \nabla f(x_k) )^T p_k & \leq || \nabla f(x_{c_k}) - \nabla f
(x_k) || \cdot ||p_k || \label
{E:from-Lipschitz} \\ 
	&\leq \alpha_{c_k} L || p_k ||^2. \notag
\end{align}
Substituting \eqref{E:c-1} into the left-hand side of this last inequality \eqref
{E:from-Lipschitz} gives
\begin{align}
( c - 1 ) \nabla f(x_k)^T p_k &\leq \alpha_{c_k} L || p_k ||^2 \notag\\
\intertext{or}
-\alpha_{c_k} &\leq \frac{( 1 - c )}{L} \frac{ \nabla f(x_k)^T p_k}{ || p_k ||^2}. 
\label{E:-alpha}
\end{align}

%%%%%%
%%%%%%
Write out the first $k+1$ inequalities of \eqref{E:f-lb}:
\begin{align}
\begin{split}
	f( x_1 ) &< f(x_0) + \alpha_{c_0} c \nabla f(x_0)^T p_0 \\
	f( x_2 ) &< f(x_1) + \alpha_{c_1} c \nabla f(x_1)^T p_1  \\
	\ldots  \\
	f( x_{k} ) &< f(x_{k-1}) + \alpha_{c_{k-1}} c \nabla f(x_{k-1})^T p_{k-1}  \\
	f( x_{k+1} ) &< f(x_k) + \alpha_{c_k} c \nabla f(x_k)^T p_k 
\end{split}
	\label{E:to telescope}
\end{align}
Telescoping the right-hand side of \eqref{E:to telescope},
\begin{align*}
	f( x_{k+1} ) &< f(x_0) + c \sum_{j=0}^{k} \alpha_{c_j} \nabla f(x_j)^T p_j. \notag
\end{align*}
Noting that $\nabla f(x_j)^T p_j < 0$, we can substitute our upper bound \eqref{E:-
alpha} for $-\alpha_{c_j}$ in the 
right-hand side above,
\begin{align}
	f( x_{k+1} ) &< f(x_0) - c \sum_{j=0}^{k} \frac{( 1 - c )}{L} 
	\frac{ \nabla f(x_j)^T p_j}{ || p_j ||^2 } \nabla f(x_j)^T p_j \notag \\
	\intertext{which simplies to}
	f( x_{k+1} ) &< f(x_0) - c \sum_{j=0}^{k} \frac{( 1 - c )}{L} 
	\frac{ (\nabla f(x_j)^T p_j)^2}{ || p_j ||^2 }. 
\notag
\end{align}

Because $f(x)$ is bounded below by assumption, there exists some $M < \infty$ such 
that $f(x_0) - f(x_{k+1}) < M$ for 
all $k$. Then rearranging the above yields,

\begin{align*}
	\frac{c( 1 - c )}{L} \sum_{j=0}^{k}   \frac{ ( \nabla f(x_j)^T p_j )^2}{ || p_j ||^2 } &< M < \infty.
 \end{align*}
The angle $\theta_j$ between the search direction $p_k$ and steepest descent direction 
$-\nabla f_k$ can be expressed 
by $\cos \theta_j = \frac{ -\nabla f(x_j)^T p_j}{||\nabla f_j|| \cdot || p_j||}$.  
Substituting this into the equation 
above and taking $k \to \infty$,
\begin{align*}
	\frac{c( 1 - c )}{L} \sum_{j=0}^{\infty}  \cos^2 \theta_j ||\nabla f(x_j)||^2 &< \infty.
\end{align*}
Since $0 < c < 1$,
\begin{align}
	\sum_{j=0}^{\infty}  \cos^2 \theta_j ||\nabla f(x_j)||^2 &< \infty. \label{E:Z's}
\end{align}

The convergent series in \eqref{E:Z's} implies that 
\begin{align*}
	\cos^2 \theta_k || \nabla f(x_k) ||^2 &\to 0 \text{ as } k \to \infty.
\end{align*}
With the additional restriction on the search direction $p_k$ such that $\cos \theta_k \geq \delta > 0$ for some choice 
of $\delta$, for all choices of $k$, we get the desired convergence result of
\begin{align*}
	\lim_{k \to \infty} || \nabla f(x_k) || &= 0.
\end{align*}
\end{proof}
%%%%%%%%%%% END PROOF %%%%%%%%%%%%%%
The inequality \eqref{E:Z's} has been referred to as \emph{Zoutendijk's condition} 
\citep{NW}, though we arrive at this 
result via different assumptions.












\newpage
\section{Proof of Exponential family log likelihood maximization}
\begin{proof}[Proof of Theorem~\ref{Thm:log like max}]
Let $f(\cdot)$ represent the negative log likelihood $- \ell(\cdot)$, the objective 
function to be minimized.  We proceed from the perspective of a minimization of a 
function $f(\cdot)$ since this is the convention in the optimization literature \citep
{NW,Rockafellar}.  \citet{Okabayashi:longrange} prove a special case when the minimum 
exists, and this proof mimics that one.

The negative log likelihood function $-\ell(\cdot)$ is strictly convex by 
\eqref{E:nabla2 ell}, and continuous since it is infinitely differentiable by LEHMAN.

It is bounded below by the negative LCM by Corollary CHARLIE.

The objective function $f$ is bounded below, strictly convex, and lower semicontinuous 
by assumption, and so by Lemma~
\ref{Lemma:f min}, the global minimum exists.  
Then by Lemma~\ref{Lemma:f min}, all level sets of type $\lev_{\leq a} f$, $a \in \RR$ are bounded in $\RR^n$.  Restricting the set to be along a search 
direction $p_k$ maintains the 
boundedness of these sets.  By Lemma~\ref{Lemma:f min} again, the minimum in this 
restriction exists and is unique.     

Then, unless $\nabla f( x_k ) = 0$ in which case $x_k$ is already the solution, for 
each $k$, we can uniquely define $
\alpha_{c_k}$ and $\alpha_{min_k}$ as follows: 
\begin{align}
%	\theta_k &= \cos^{-1} \left( \frac{ -\nabla f_k^T p_k }{ ||\nabla f_k|| \, ||
%p_k||} \right) \label{E:cosine} \\
	\nabla f( x_k + \alpha_{c_k} p_k)^T p_k &= c \nabla f(x_k)^T p_k \label{E:alphac} 
\\
	\nabla f( x_k + \alpha_{min_k} p_k)^T p_k &= 0. \label{E:alphamin} 
\end{align}
The point $\alpha_{c_k}$ is uniquely defined because it is the minimizer of $\alpha 
\mapsto f( x_k + \alpha p_k) - 
\alpha c \nabla f( x_k )^T p_k$.
These values appear on the $\alpha$-axis in Figure \ref{F:Wolfe-mod}.
%%%%%%%%%%% FIGURE %%%%%%%%%%%%%%
\begin{figure}
\centering
\scalebox{.4}{\input{Figures/Wolfe-mod.pdf_t}}
\caption{The acceptable region for $\alpha$ according to the curvature condition 
\eqref{E:Wolfe-mod} when restricting 
$f$ to direction $p_k$.}
\label{F:Wolfe-mod}
\end{figure}

%These values are illustrated on the $\alpha$-axis in Figure \ref{F:Wolfe-mod}.  
%Equation \eqref{E:alphamin} defines $\alpha_{min_k}$ to be the step size that would 
%make the 
%gradient at $x_{k+1}$ equal to zero and hence minimizes $f(x_{k+1})$, equation \eqref
%{E:alphac} 
%defines \alpha_{c_k} to be the step size that would make the gradient at $x_{k+1}$ 
%equal to 

By the strict convexity of $f$ and Theorem~2.14 in \citet{Rockafellar}, 
\begin{align}
	f( x_k + \alpha_{c_k} p_k ) &< f(x_k) +  \bigl[ \nabla f(x_k + \alpha_{c_k} p_k) 
\bigr]^T \alpha_{c_k} p_k. \notag 
\\
	\intertext{Applying \eqref{E:alphac} to the right hand side of the above gives}
	f( x_k + \alpha_{c_k} p_k ) &< f(x_k) + \alpha_{c_k} c \nabla f(x_k)^T p_k. 
	\label{E:b-less-a}
	\end{align}	
(See points $a$ and $b$ in Figure \ref{F:Wolfe-mod}).

The subproblem $\alpha \mapsto f(x_k + \alpha p_k)$ is strictly convex and hence 
monotonically decreasing at $\alpha_k$ 
such that $\alpha_{c_k} \leq \alpha_k \leq \alpha_{min_k}$ (in Figure \ref{F:Wolfe-mod}, see points $b$ and $c$).  That is,
\begin{align}
	f( x_k + \alpha_{min}p_k) &\leq f( x_k + \alpha_k p_k) \leq f( x_k + \alpha_{c_k} p_k). \label{E:f-sandwich}
\end{align}
	
Combining the second inequality of \eqref{E:f-sandwich} with \eqref{E:b-less-a}, we 
have	
\begin{align}
	f( x_k + \alpha_k p_k ) &< f(x_k) + \alpha_{c_k} c \nabla f(x_k)^T p_k,  
	\label{E:decrease}
	\intertext{which can be rearranged as}
	f(x_k)-f( x_k + \alpha_k p_k ) &>  -\alpha_{c_k} c \nabla f(x_k)^T p_k. 
	\label{E:f-lb}
\end{align}
This last inequality \eqref{E:f-lb} expresses a lower bound for the amount of decrease 
in our objective function at 
each step (the right-hand side is positive since $\nabla f(x_k)^T p_k < 0$ by 
assumption that $p_k$ is a descent 
direction).  It is this lower bound that we will use to cover the distance to the 
minimum of the objective function.  

We now turn our attention to \eqref{E:alphac}.  Define $x_{c_k} = x_k + \alpha_{c_k} p_k$.  Then
\begin{align}
	\nabla f( x_{c_k} )^T p_k &= c \nabla f(x_k)^T p_k. \notag
\end{align}
Subtracting $\nabla f(x_k)^T p_k$ from both sides gives
\begin{align}
	\left( \nabla f( {x_{c_k}} ) - \nabla f(x_k) \right )^T p_k &= ( c - 1 ) 
	\nabla f(x_k)^T p_k.  \label{E:c-1}
\end{align}

%\textbf{NEW: SAI 1/17/11}\\
\textbf{
By \eqref{E:nabla2 ell}, $\nabla^2 \ell(\eta)$ is bounded for finite state space $g(\YY)$, which is true by assumption.  Thus $| \nabla^2 f(x) | \leq K$ for some 
constant K for all $x$. 
Then by Theorems 9.2 and 9.7 in \citet{Rockafellar}, 
%since $\nabla^2 f(x)$ is assumed to be finite, 
$\nabla f(x)$ is Lipschitz continuous relative to the convex set $\RR^n$.}

%By Corollary~25.5.1 in \citet{Rockafellar:1970}, since $f$ is convex and 
%differentiable on the open convex set $\NN$, 
%it is actually continuously differentiable on $\NN$.  It is then Lipschitz 
%continuously differentiable relative to any 
%compact subset of $\NN$. 

Applying this to the compact level set $\lev_{\leq f(x_k)} f$, 
%which is contained in $\NN$ by assumption, 
there exists a constant $L < \infty$ such that
	\begin{align}
		|| \nabla f(x) - \nabla f(\tilde{x}) || \leq L || x - \tilde{x} || \quad \text
{for all $x, \tilde{x} \in \lev_
{\leq f(x_0)} f$}. \label{E:Lipschitz}
	\end{align} 

Applying \eqref{E:Lipschitz} to $x_{c_k}$ and $x_k$, we have
\begin{align}
|| \nabla f(x_{c_k}) - \nabla f(x_k) || &\leq L || x_{c_k} - x_k || \notag
\intertext{or}
|| \nabla f(x_{c_k}) - \nabla f(x_k) || &\leq L || \alpha_{c_k} p_k ||. \notag	
\end{align}

Multiplying both sides by $\lVert p_k \rVert$ gives
\begin{align}
	|| \nabla f(x_{c_k}) - \nabla f(x_k) || \cdot ||p_k || &\leq \alpha_{c_k} L || p_k ||^2 
	\notag \\
\intertext{and by Cauchy-Schwarz this implies}
	( \nabla f(x_{c_k}) - \nabla f(x_k) )^T p_k & \leq || 
	\nabla f(x_{c_k}) - \nabla f(x_k) || \cdot ||p_k || \label{E:from-Lipschitz} \\ 
	&\leq \alpha_{c_k} L || p_k ||^2. \notag
\end{align}
Substituting \eqref{E:c-1} into the left-hand side of this last inequality 
\eqref{E:from-Lipschitz} gives
\begin{align}
( c - 1 ) \nabla f(x_k)^T p_k &\leq \alpha_{c_k} L || p_k ||^2 \notag\\
\intertext{or}
-\alpha_{c_k} &\leq \frac{( 1 - c )}{L} \frac{ \nabla f(x_k)^T p_k}{ || p_k ||^2}. 
\label{E:-alpha}
\end{align}

%%%%%%
%%%%%%
Write out the first $k+1$ inequalities of \eqref{E:f-lb}:
\begin{align}
\begin{split}
	f( x_1 ) &< f(x_0) + \alpha_{c_0} c \nabla f(x_0)^T p_0 \\
	f( x_2 ) &< f(x_1) + \alpha_{c_1} c \nabla f(x_1)^T p_1  \\
	\ldots  \\
	f( x_{k} ) &< f(x_{k-1}) + \alpha_{c_{k-1}} c \nabla f(x_{k-1})^T p_{k-1}  \\
	f( x_{k+1} ) &< f(x_k) + \alpha_{c_k} c \nabla f(x_k)^T p_k 
\end{split}
	\label{E:to telescope}
\end{align}
Telescoping the right-hand side of \eqref{E:to telescope},
\begin{align*}
	f( x_{k+1} ) &< f(x_0) + c \sum_{j=0}^{k} \alpha_{c_j} \nabla f(x_j)^T p_j. \notag
\end{align*}
Noting that $\nabla f(x_j)^T p_j < 0$, we can substitute our upper bound 
\eqref{E:-alpha} for $-\alpha_{c_j}$ in the right-hand side above,
\begin{align}
	f( x_{k+1} ) &< f(x_0) - c \sum_{j=0}^{k} \frac{( 1 - c )}{L} 
	\frac{\nabla f(x_j)^T p_j}{ || p_j ||^2 } \nabla f(x_j)^T p_j \notag \\
	\intertext{which simplies to}
	f( x_{k+1} ) &< f(x_0) - c \sum_{j=0}^{k} \frac{( 1 - c )}{L} 
	\frac{ (\nabla f(x_j)^T p_j)^2}{ || p_j ||^2 }. 
\notag
\end{align}

Because $f(x)$ is bounded below by assumption, there exists some $M < \infty$ such 
that $f(x_0) - f(x_{k+1}) < M$ for 
all $k$. Then rearranging the above yields,

\begin{align*}
	\frac{c( 1 - c )}{L} \sum_{j=0}^{k}   
	\frac{ ( \nabla f(x_j)^T p_j )^2}{ || p_j ||^2 } &< M < \infty.
 \end{align*}
The angle $\theta_j$ between the search direction $p_k$ and steepest descent direction 
$-\nabla f_k$ can be expressed 
by $\cos \theta_j = \frac{ -\nabla f(x_j)^T p_j}{||\nabla f_j|| \cdot || p_j||}$.  
Substituting this into the equation 
above and taking $k \to \infty$,
\begin{align*}
	\frac{c( 1 - c )}{L} \sum_{j=0}^{\infty}  \cos^2 \theta_j ||\nabla f(x_j)||^2 &< \infty.
\end{align*}
Since $0 < c < 1$,
\begin{align}
	\sum_{j=0}^{\infty}  \cos^2 \theta_j ||\nabla f(x_j)||^2 &< \infty. \label{E:Z's}
\end{align}

The convergent series in \eqref{E:Z's} implies that 
\begin{align*}
	\cos^2 \theta_k || \nabla f(x_k) ||^2 &\to 0 \text{ as } k \to \infty.
\end{align*}
With the additional restriction on the search direction $p_k$ such that $\cos \theta_k 
\geq \delta > 0$ for some choice 
of $\delta$, for all choices of $k$, we get the desired convergence result of
\begin{align*}
	\lim_{k \to \infty} || \nabla f(x_k) || &= 0.
\end{align*}

\end{proof}


%%%%%%%%%%% BEGIN PROOF - Line Search Works  %%%%%%%%%%%%%%
Theorem 3.1 shows that the gradient of the objective function converges to 0.  The 
proof for Theorem 3.2 is concerned 
with the conditions for mapping this convergence to the convergence of the iterated 
parameter estimates $\eta_k$ to the 
unique MLE.  In particular, the mapping from $\eta_k$ to the gradient must be globally 
invertible.

\begin{proof}[Proof of Theorem~\ref{Thm:Line Search works}]

The Fisher information for a regular exponential family is non-singular by \eqref
{E:FI} and thus invertible.  If we 
consider the map defined by
\begin{align*}
	h(\eta) = \nabla c(\eta)
\end{align*}
where $c$ is the cumulant function \eqref{E:cumulant}, its first derivative matrix is
\begin{align}
	\nabla h(\eta) = \nabla^2 c(\eta) = I(\eta) \label{E:nabla h eta}
\end{align}
which is again non-singular.  Since this is true for any $\eta$, by the inverse 
function theorem, $h$ is everywhere 
locally invertible.

In fact, $h$ is globally invertible. For any $\mu$ in the range of $h$, consider the 
function
\begin{align*}
	q(\eta) = \mu^T\eta - c(\eta).
\end{align*}
Since $\nabla^2 q(\eta) = - I(\eta)$ by \eqref{E:nabla h eta}, $q$ is strictly 
concave.  Therefore, a maximizer for $q$, call it $\hat{\eta}$, is unique if it exists and satisfies the first-order condition
\begin{align*}
	\nabla q( \hat{\eta} ) = 0.
\end{align*}
This in turn implies that
\begin{align*}
	\mu - h(\hat{\eta}) = 0
\end{align*} 
or
\begin{align*}
	\mu = h( \hat{\eta} ). \label{E:eta hat}
\end{align*}
Because of the assumption that $\mu$ is in the range of $h$, this means that 
$\hat{\eta}$ in fact exists, and by the 
strict concavity of $q$, is unique.  This implies that $h$ must be one-to-one and 
hence globally invertible.


Since $c$ is infinitely differentiable by Theorem~2.7.1 in \citet{TSH}, so is $h$, and 
by the inverse function theorem, 
so is $h^{-1}$ (even if we do not know the form of $h^{-1}$).  The first derivative of 
$h^{-1}$ can be expressed as
\begin{align*}
	\nabla h^{-1}(\mu) = \left [ \nabla h(\eta) \right ]^{-1} = \left [ I(\eta) 
\right ]^{-1}
\end{align*}
when $\mu = h(\eta)$ and is thus non-singular everywhere, including at the MLE of 
$\eta$, $\etaMLE$.

Thus our algorithm, which concludes that $ || \nabla \ell( \eta_k) ||  = || g(y) - h
(\eta_k) || \to 0$, implies that 
\begin{align*}
	\mu_k = h(\eta_k) \to g(y), 
\end{align*}
or
\begin{align*}
	h^{-1}(\mu_k)  \to h^{-1}\left (g(y) \right),
\end{align*}
or
\begin{align*}
	\eta_k  \to  \etaMLE.
\end{align*}

\end{proof}
%%%%%%%%%%% END PROOF %%%%%%%%%%%%%%

%\chapter{Proofs of Chapter \ref{sec:gibbs} Results}\label{sec:app1}
%\input{GibbsProofs}
%
%\chapter{Proofs of Chapter \ref{sec:examples} Results}\label{sec:app2}
%\input{ExampleProofs}




\end{document}